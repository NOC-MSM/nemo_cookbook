{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#getting-started","title":"Getting Started","text":"<p>Welcome to the documentation for the NEMO Cookbook </p>"},{"location":"#what-is-the-nemo-cookbook","title":"What is the NEMO Cookbook?","text":"<p>NEMO Cookbook is a collection of recipes for performing reproducible analyses of the Nucleus for European Modelling of the Ocean (NEMO) ocean general circulation model outputs.</p> <p>Our aim is to provide Python implementations of the post-processing &amp; analysis functions available in CDFTOOLS alongside new diagnostics (e.g., surface-forced water mass transformation), which are compatible with generalised vertical coordinate systems (e.g., MEs).</p>"},{"location":"#nemodatatree","title":"NEMODataTree","text":"<p>NEMO Cookbook utilises the <code>NEMODataTree</code> object, which is an extension of the <code>xarray.DataTree</code> and an alternative to the xgcm grid object.</p> <p><code>NEMODataTree</code> enables users to:</p> <ul> <li> <p>Store output variables defined on NEMO T/U/V/W grids using the model\u2019s native (i, j, k) curvilinear coordinate system.</p> </li> <li> <p>Analyse parent, child and grandchild domains of nested configurations using a single DataTree.</p> </li> <li> <p>Pre-process model outputs (i.e., removing ghost points and generating t/u/v/f masks without needing a mesh_mask file).</p> </li> <li> <p>Perform scalar (e.g., gradient) and vector (e.g., divergence, curl) operations as formulated in NEMO.</p> </li> <li> <p>Calculate grid-aware diagnostics, including masked &amp; binned statistics.</p> </li> <li> <p>Perform vertical grid coordinate transformations via conservative interpolation. </p> </li> </ul> <p>Each recipe in the NEMO Cookbook uses <code>NEMODataTree</code> to leverage xarray, flox &amp; dask libraries to calculate a diagnostic with NEMO ocean model outputs.</p>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<p>Users are recommended to installing NEMO Cookbook into a new virtual environment via GitHub:</p> <pre><code>pip install git+https://github.com/NOC-MSM/nemo_cookbook.git\n</code></pre> <p>Alternatively, users can clone the latest version of the nemo_cookbook repository using Git:</p> <pre><code>git clone git@github.com:NOC-MSM/nemo_cookbook.git\n</code></pre> <p>Then, install the dependencies in a new conda virtual environment and pip install NEMO Cookbook in editable mode:</p> <pre><code>cd nemo_cookbook\n\nconda env create -f environment.yml\nconda activate env_nemo_cookbook\n\npip install -e .\n</code></pre> Helpful Tip... <ul> <li>We strongly recommend setting-up a virtual environment before installing nemo_cookbook with pip.</li> </ul> <p>The simplest way to create a new virtual environment is to use venv:</p> <p><code>sh python3.13 -m venv \"env_nemo_cookbook\"</code></p> <p>Alternatively, using an existing miniconda or miniforge installation:</p> <p><code>sh conda env create -f environment.yml</code></p>"},{"location":"#next-steps","title":"Next Steps...","text":"<ul> <li> <p>To learn more about NEMODataTree, see the User Guide and How To pages - this is an especially starting point for new NEMO users!</p> </li> <li> <p>To get started working with the recipes in the NEMO Cookbook, visit the to Recipes page.</p> </li> <li> <p>For those looking for more detailed documentation, explore the NEMODataTree API.</p> </li> <li> <p>To contribute your own recipes to NEMO Cookbook, see the Contributing page</p> </li> </ul>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":""},{"location":"contributing/#contributing-to-nemo-cookbook","title":"Contributing to NEMO Cookbook","text":"<p>Thank you for your interest in contributing to NEMO Cookbook!</p> <p>We welcome contributions from the community to help us support the reproducible analysis of NEMO model outputs.</p>"},{"location":"contributing/#getting-started","title":"Getting Started","text":"<p>To get started with contributing to NEMO Cookbook, please follow the steps below:</p> <ol> <li>Fork the NEMO Cookbook repository on GitHub.</li> <li>Clone your forked repository to your local machine.</li> <li>Create a new branch for your contribution.</li> <li> <p>Add your new recipe or improvements to the codebase.</p> </li> <li> <p>Follow the NumPy docstring conventions when adding or modifying docstrings.</p> </li> <li> <p>Follow the PEP 8 style guide when writing code.</p> </li> <li> <p>Test your changes thoroughly to ensure they work as expected.</p> </li> <li>Commit your changes with clear and descriptive commit messages.</li> <li>Push your changes to your forked repository.</li> <li>Submit a pull request to the main branch of NEMO Cookbook.</li> </ol>"},{"location":"contributing/#code-guidelines","title":"Code Guidelines","text":"<p>When contributing code to NEMO Cookbook, please adhere to the following guidelines:</p> <ul> <li>Follow the coding style and conventions used in the existing codebase.</li> <li>Write clear and concise code with appropriate comments.</li> <li>Ensure your code is well-tested and does not introduce any regressions.</li> <li>Make sure your recipe is scalable using dask.</li> <li>Add a new .ipynb demonstrating your new recipe.</li> <li>Document any new features or changes in the appropriate sections of the documentation.</li> </ul>"},{"location":"contributing/#bug-reports-and-feature-requests","title":"Bug Reports and Feature Requests","text":"<p>If you find any bugs or have ideas for new features, please open an issue on the NEMO Cookbook GitHub repository.</p> <p>Provide as much detail as possible, including steps to reproduce the issue or a clear description of the desired feature.</p>"},{"location":"contributing/#community-guidelines","title":"Community Guidelines","text":"<p>When participating in the NEMO Cookbook community, please be respectful and considerate towards others. Follow the code of conduct and engage in constructive discussions.</p> <p>We appreciate your contributions and look forward to working together to improve NEMO Cookbook!</p>"},{"location":"examples/","title":"Example NEMODataTrees","text":"<p>In this section, we demonstrate how to construct <code>NEMODataTrees</code> using example global, regional and coupled NEMO ocean sea-ice outputs.</p> <p>Users can also explore the following examples using the <code>example_nemodatatrees.ipynb</code> Jupyter Notebook available in the <code>recipes</code> directory.</p> <p>To get started, let's begin by importing the Python packages we'll be using:</p> <pre><code>import xarray as xr\nimport nemo_cookbook as nc\nfrom nemo_cookbook import NEMODataTree\n</code></pre>"},{"location":"examples/#global-ocean-sea-ice-models","title":"Global Ocean Sea-Ice Models:","text":"<p>1. <code>AGRIF_DEMO</code></p> <p>Let's start by creating a <code>NEMODataTree</code> using example outputs from the global <code>AGRIF_DEMO</code> NEMO reference configuration.</p> <p><code>AGRIF_DEMO</code> is based on the <code>ORCA2_ICE_PISCES</code> reference configuration with the inclusion of 3 online nested domains.</p> <p>Here, we will only consider the 2\u00b0 global parent domain.</p> <p>Further information on this reference configuration can be found here.</p> <p>NEMO Cookbook includes a selection of example NEMO model output datasets accessible via cloud object storage.</p> <p><code>nemo_cookbook.examples.get_filepaths()</code> is a convenience function used to download and generate local filepaths for an available NEMO reference configuration.</p> <pre><code>filepaths = nc.examples.get_filepaths(\"AGRIF_DEMO\")\n\nfilepaths\n</code></pre> <p>The <code>get_filepaths()</code> function will download each of the files to your local machine, returning a dictionary of filepaths for the chosen configuration (<code>AGRIF_DEMO</code>):</p> <pre><code>{'domain_cfg.nc': '/Users/me/Library/Caches/nemo_cookbook/AGRIF_DEMO/domain_cfg.nc',\n '2_domain_cfg.nc': '/Users/me/Library/Caches/nemo_cookbook/AGRIF_DEMO/2_domain_cfg.nc',\n '3_domain_cfg.nc': '/Users/me/Library/Caches/nemo_cookbook/AGRIF_DEMO/3_domain_cfg.nc',\n 'ORCA2_5d_00010101_00010110_grid_T.nc': '/Users/me/Library/Caches/nemo_cookbook/AGRIF_DEMO/ORCA2_5d_00010101_00010110_grid_T.nc',\n ...\n '3_Nordic_5d_00010101_00010110_icemod.nc': '/Users/me/Library/Caches/nemo_cookbook/AGRIF_DEMO/3_Nordic_5d_00010101_00010110_icemod.nc'\n }\n</code></pre> <p>Next, we need to define the <code>paths</code> dictionary, which contains the filepaths corresponding to our global parent domain.</p> <p>We populate the <code>parent</code> dictionary with the filepaths to the <code>domain_cfg</code> and <code>gridT/U/V/W</code> netCDF files produced for the <code>AGRIF_DEMO</code> parent domain. </p> <pre><code>paths = {\"parent\": {\n         \"domain\": filepaths[\"domain_cfg.nc\"],\n         \"gridT\": filepaths[\"ORCA2_5d_00010101_00010110_grid_T.nc\"],\n         \"gridU\": filepaths[\"ORCA2_5d_00010101_00010110_grid_U.nc\"],\n         \"gridV\": filepaths[\"ORCA2_5d_00010101_00010110_grid_V.nc\"],\n         \"gridW\": filepaths[\"ORCA2_5d_00010101_00010110_grid_W.nc\"],\n         \"icemod\": filepaths[\"ORCA2_5d_00010101_00010110_icemod.nc\"]\n        },\n        }\n</code></pre> <p>We can construct a new <code>NEMODataTree</code> called <code>nemo</code> using the <code>.from_paths()</code> constructor.</p> <p>Notice, that we also need to specify that our global parent domain is zonally periodic (<code>iperio=True</code>) and north folding on T-points (<code>nftype = \"T\"</code>) rather than a closed (regional) domain.</p> <pre><code>nemo = NEMODataTree.from_paths(paths, iperio=True, nftype=\"T\")\n\nnemo\n</code></pre> <p>This returns the following <code>xarray.DataTree</code>, where we have truncated the outputs for improved readability:</p> <pre><code>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:               (time_counter: 2, axis_nbounds: 2, ncatice: 5)\n\u2502   ...\n\u2502 \n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:               (time_counter: 2, axis_nbounds: 2, j: 148, i: 180,\n\u2502                                  ncatice: 5, k: 31)\n\u2502       Coordinates:\n\u2502           time_centered         (time_counter) object 16B 0001-01-03 12:00:00 0001-...\n\u2502         * deptht                (k) float32 124B 5.0 15.0 25.0 ... 4.75e+03 5.25e+03\n\u2502           time_instant          (time_counter) object 16B ...\n\u2502           gphit                 (j, i) float64 213kB ...\n\u2502           glamt                 (j, i) float64 213kB ...\n\u2502         * k                     (k) int64 248B 1 2 3 4 5 6 7 ... 25 26 27 28 29 30 31\n\u2502         * j                     (j) int64 1kB 1 2 3 4 5 6 ... 143 144 145 146 147 148\n\u2502         * i                     (i) int64 1kB 1 2 3 4 5 6 ... 175 176 177 178 179 180\n\u2502       Dimensions without coordinates: axis_nbounds\n\u2502       Data variables: (12/87)\n\u2502           time_centered_bounds  (time_counter, axis_nbounds) object 32B 0001-01-01 ...\n\u2502           time_counter_bounds   (time_counter, axis_nbounds) object 32B 0001-01-01 ...\n\u2502           simsk                 (time_counter, j, i) float32 213kB ...\n\u2502           simsk05               (time_counter, j, i) float32 213kB ...\n\u2502           simsk15               (time_counter, j, i) float32 213kB ...\n\u2502           snvolu                (time_counter, j, i) float32 213kB ...\n\u2502           ...                    ...\n\u2502           e1t                   (j, i) float64 213kB ...\n\u2502           e2t                   (j, i) float64 213kB ...\n\u2502           top_level             (j, i) int32 107kB ...\n\u2502           bottom_level          (j, i) int32 107kB ...\n\u2502           tmask                 (k, j, i) bool 826kB False False False ... False False\n\u2502           tmaskutil             (j, i) bool 27kB False False False ... False False\n\u2502       Attributes:\n\u2502           name:         ORCA2_5d_00010101_00010110_icemod\n\u2502           description:  ice variables\n\u2502           title:        ice variables\n\u2502           Conventions:  CF-1.6\n\u2502           timeStamp:    2025-Sep-13 17:44:13 GMT\n\u2502           uuid:         c6c24bd5-1d2b-4d7b-98b5-8d379c94e84b\n\u2502           nftype:       T\n\u2502           iperio:       True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:               (k: 31, axis_nbounds: 2, time_counter: 2, j: 148,\n\u2502                                  i: 180)\n\u2502       ...\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:               (k: 31, axis_nbounds: 2, time_counter: 2, j: 148,\n\u2502                                  i: 180)\n\u2502       ...\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:               (k: 31, axis_nbounds: 2, time_counter: 2, j: 148,\n\u2502                                  i: 180)\n\u2502       ...\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 148, i: 180, k: 31)\n        ...\n</code></pre> <p>2. <code>NOC Near-Present Day eORCA1</code></p> <p>Next, we'll consider monthly-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024. </p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p> <p>The eORCA1 JRA55v1 NPD data are publicly accessible as remote Zarr v2 stores via JASMIN Object Store, so we will use the NEMODataTree <code>.from_datasets()</code> constructor. </p> <pre><code>base_url = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1\"\n\n# Opening domain_cfg:\nds_domain = (xr.open_zarr(f\"{base_url}/domain/domain_cfg\", consolidated=True, chunks={})\n             .squeeze(drop=True)\n             .rename({\"z\": \"nav_lev\"})\n             )\n\n# Opening gridT dataset, including sea surface temperature (\u00b0C) and salinity (g kg-1):\nds_gridT = xr.merge([xr.open_zarr(f\"{base_url}/T1m/{var}\", consolidated=True, chunks={})[var] for var in ['tos_con', 'sos_abs']], compat=\"override\")\n</code></pre> <p>Next, let's create a <code>NEMODataTree</code> from a dictionary of eORCA1 JRA55v1 <code>xarray.Datasets</code>, specifying that our global domain is zonally periodic (<code>iperio=True</code>) and north folding on T-points (<code>nftype = \"F\"</code>).</p> <pre><code>datasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}\n\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</code></pre> <pre><code>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 577)\n\u2502   ...\n\u2502 \n\u251c\u2500\u2500 Group: /gridT\n\u2502   Dimensions:        (time_counter: 577)\n\u2502       Dimensions:        (time_counter: 577, j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           time_centered  (time_counter) datetime64[ns] 5kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           tos_con        (time_counter, j, i) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           sos_abs        (time_counter, j, i) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           e1t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level      (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level   (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502           tmaskutil      (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       ...\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       ...\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       ...\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        ...\n</code></pre>"},{"location":"examples/#regional-ocean-models","title":"Regional Ocean Models:","text":"<p><code>AMM12</code></p> <p>We can also construct a <code>NEMODataTree</code> using outputs from regional NEMO ocean model simulations.</p> <p>Here, we will consider example outputs from the regional <code>AMM12</code> NEMO reference configuration.</p> <p>The AMM, Atlantic Margins Model, is a regional model covering the Northwest European Shelf domain on a regular lat-lon grid at approximately 12km horizontal resolution. <code>AMM12</code> uses the vertical s-coordinates system, GLS turbulence scheme, and tidal lateral boundary conditions using a flather scheme.</p> <p>Further information on this reference configuration can be found here.</p> <pre><code>filepaths = nc.examples.get_filepaths(\"AMM12\")\n\nfilepaths\n</code></pre> <pre><code>{'domain_cfg.nc': '/Users/me/Library/Caches/nemo_cookbook/AMM12/domain_cfg.nc',\n 'AMM12_1d_20120102_20120110_grid_T.nc': '/Users/me/Library/Caches/nemo_cookbook/AMM12/AMM12_1d_20120102_20120110_grid_T.nc',\n 'AMM12_1d_20120102_20120110_grid_U.nc': '/Users/me/Library/Caches/nemo_cookbook/AMM12/AMM12_1d_20120102_20120110_grid_U.nc',\n 'AMM12_1d_20120102_20120110_grid_V.nc': '/Users/me/Library/Caches/nemo_cookbook/AMM12/AMM12_1d_20120102_20120110_grid_V.nc'\n }\n</code></pre> <p>As we showed in the <code>AGRIF_DEMO</code> example, we need to populate the <code>paths</code> dictionary with the <code>domain_cfg</code> and <code>gridT/U/V</code> filepaths corresponding to our regional model domain.</p> <pre><code>paths = {\"parent\": {\n         \"domain\": filepaths[\"domain_cfg.nc\"],\n         \"gridT\": filepaths[\"AMM12_1d_20120102_20120110_grid_T.nc\"],\n         \"gridU\": filepaths[\"AMM12_1d_20120102_20120110_grid_U.nc\"],\n         \"gridV\": filepaths[\"AMM12_1d_20120102_20120110_grid_V.nc\"],\n        },\n        }\n</code></pre> <p>Next, we can construct a new <code>NEMODataTree</code> called <code>nemo</code> using the <code>.from_paths()</code> constructor.</p> <p>Note, we do not actually need to specify that our regional domain is not zonally periodic in this case, given that, by default, <code>iperio=False</code>.</p> <pre><code>nemo = NEMODataTree.from_paths(paths, iperio=False)\n\nnemo\n</code></pre> <pre><code>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:               (time_counter: 8, axis_nbounds: 2)\n\u2502   ...\n\u2502 \n\u251c\u2500\u2500 Group: /gridT\n\u2502   Dimensions:               (time_counter: 8, axis_nbounds: 2)\n\u2502   ...\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:               (time_counter: 8, axis_nbounds: 2, j: 224, i: 198,\n\u2502                                  k: 51)\n\u2502       Coordinates:\n\u2502           time_centered         (time_counter) datetime64[ns] 64B ...\n\u2502           gphit                 (j, i) float64 355kB ...\n\u2502           glamt                 (j, i) float64 355kB ...\n\u2502         * k                     (k) int64 408B 1 2 3 4 5 6 7 ... 45 46 47 48 49 50 51\n\u2502         * j                     (j) int64 2kB 1 2 3 4 5 6 ... 219 220 221 222 223 224\n\u2502         * i                     (i) int64 2kB 1 2 3 4 5 6 ... 193 194 195 196 197 198\n\u2502       Dimensions without coordinates: axis_nbounds\n\u2502       Data variables:\n\u2502           time_centered_bounds  (time_counter, axis_nbounds) datetime64[ns] 128B ...\n\u2502           time_counter_bounds   (time_counter, axis_nbounds) datetime64[ns] 128B ...\n\u2502           tos                   (time_counter, j, i) float32 1MB ...\n\u2502           sos                   (time_counter, j, i) float32 1MB ...\n\u2502           zos                   (time_counter, j, i) float32 1MB ...\n\u2502           e1t                   (j, i) float64 355kB ...\n\u2502           e2t                   (j, i) float64 355kB ...\n\u2502           top_level             (j, i) int32 177kB ...\n\u2502           bottom_level          (j, i) int32 177kB ...\n\u2502           tmask                 (k, j, i) bool 2MB False False False ... False False\n\u2502           tmaskutil             (j, i) bool 44kB False False False ... False False\n\u2502       Attributes:\n\u2502           nftype:   None\n\u2502           iperio:   False\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:               (time_counter: 8, axis_nbounds: 2, j: 224, i: 198,\n\u2502                                  k: 51)\n\u2502       ...\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:               (time_counter: 8, axis_nbounds: 2, j: 224, i: 198,\n\u2502                                  k: 51)\n\u2502       ...\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 224, i: 198, k: 51)\n\u2502       ...\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 224, i: 198, k: 51)\n        ...\n</code></pre>"},{"location":"examples/#nested-global-ocean-sea-ice-models","title":"Nested Global Ocean Sea-Ice Models:","text":"<p><code>AGRIF_DEMO</code></p> <p>Returning to our <code>AGRIF_DEMO</code> NEMO reference configuration, we can also construct a more complex <code>NEMODataTree</code> to store the outputs of the global parent and its child domains in a single data structure.</p> <p>We will make use of the two successively nested domains located in the Nordic Seas, with the finest grid (1/6\u00b0) spanning the Denmark strait. This grandchild domain also benefits from \u201cvertical nesting\u201d, meaning that it has 75 geopotential z-coordinate levels, compared with 31 levels in its parent domain.</p> <pre><code>filepaths = nc.examples.get_filepaths(\"AGRIF_DEMO\")\n</code></pre> <p>Let's start by defining the <code>paths</code> dictionary for the ORCA2 global parent domain and its child and grandchild domains. Notice, that for <code>child</code> and <code>grandchild</code> domains, we must also specify a unique domain number, given that we could include further child or grandchild nests.</p> <pre><code>paths = {\"parent\": {\n        \"domain\": filepaths[\"domain_cfg.nc\"],\n        \"gridT\": filepaths[\"ORCA2_5d_00010101_00010110_grid_T.nc\"],\n        \"gridU\": filepaths[\"ORCA2_5d_00010101_00010110_grid_U.nc\"],\n        \"gridV\": filepaths[\"ORCA2_5d_00010101_00010110_grid_V.nc\"],\n        \"gridW\": filepaths[\"ORCA2_5d_00010101_00010110_grid_W.nc\"],\n        \"icemod\": filepaths[\"ORCA2_5d_00010101_00010110_icemod.nc\"]\n        },\n        \"child\": {\n        \"1\":{\n        \"domain\": filepaths[\"2_domain_cfg.nc\"],\n        \"gridT\": filepaths[\"2_Nordic_5d_00010101_00010110_grid_T.nc\"],\n        \"gridU\": filepaths[\"2_Nordic_5d_00010101_00010110_grid_U.nc\"],\n        \"gridV\": filepaths[\"2_Nordic_5d_00010101_00010110_grid_V.nc\"],\n        \"gridW\": filepaths[\"2_Nordic_5d_00010101_00010110_grid_W.nc\"],\n        \"icemod\": filepaths[\"2_Nordic_5d_00010101_00010110_icemod.nc\"]\n        }},\n        \"grandchild\": {\n        \"2\":{\n        \"domain\": filepaths[\"3_domain_cfg.nc\"],\n        \"gridT\": filepaths[\"3_Nordic_5d_00010101_00010110_grid_T.nc\"],\n        \"gridU\": filepaths[\"3_Nordic_5d_00010101_00010110_grid_U.nc\"],\n        \"gridV\": filepaths[\"3_Nordic_5d_00010101_00010110_grid_V.nc\"],\n        \"gridW\": filepaths[\"3_Nordic_5d_00010101_00010110_grid_W.nc\"],\n        \"icemod\": filepaths[\"3_Nordic_5d_00010101_00010110_icemod.nc\"]\n        }},\n        }\n</code></pre> <p>Next, we need to construct a <code>nests</code> dictionary which contains the properties which define each nested domain. These include:</p> <ul> <li>Unique domain number (mapping properties to entries in our <code>paths</code> directory).</li> <li>Parent domain (to which unique domain does this belong).</li> <li>Zonal periodicity of child / grandchild domain (<code>iperio</code>).</li> <li>Horizontal grid refinement factors (<code>rx</code>, <code>ry</code>).</li> <li>Start (<code>imin</code>, <code>jmin</code>) and end (<code>imax</code>, <code>jmax</code>) grid indices in both directions (i, j) of the parent grid.</li> </ul> <p>The latter information should be copied directly from the <code>AGRIF_FixedGrids.in</code> anicillary file used to define nested domains in NEMO.</p> <p><code>Example AGRIF_FixedGrids.in</code></p> <p>1 (Number of nested domains - parent).</p> <p>121 146 113 133 4 4 4 (imin, imax, jmin, jmax, rx, ry, rt)</p> <p>1 (Number of nested domains - child)</p> <p>20 60 27 60 3 3 3 (imin, imax, jmin, jmax, rx, ry, rt)</p> <p>0 (Number of nested domains - grandchild)</p> <p>Important: we must specify the start and end grid indices using Fortran (1-based) indexes rather than Python (0-based) indexes.</p> <pre><code>nests = {\n    \"1\": {\n    \"parent\": \"/\",\n    \"rx\": 4,\n    \"ry\": 4,\n    \"imin\": 121,\n    \"imax\": 146,\n    \"jmin\": 113,\n    \"jmax\": 133,\n    \"iperio\": False\n    },\n    \"2\": {\n    \"parent\": \"1\",\n    \"rx\": 3,\n    \"ry\": 3,\n    \"imin\": 20,\n    \"imax\": 60,\n    \"jmin\": 27,\n    \"jmax\": 60,\n    \"iperio\": False\n    }\n    }\n</code></pre> <p>Finally, we can construct a new <code>NEMODataTree</code> called <code>nemo</code> using the <code>.from_paths()</code> constructor.</p> <p>Again, we also need to specify that our global parent domain is zonally periodic (<code>iperio=True</code>) and north folding on T-points (<code>nftype = \"T\"</code>) rather than a closed (regional) domain.</p> <p>We can also include additional keyword arguments to pass onto <code>xarray.open_dataset</code> or <code>xr.open_mfdataset</code> when opening NEMO model output files.</p> <pre><code>nemo = NEMODataTree.from_paths(paths=paths, nests=nests, iperio=True, nftype=\"T\", engine=\"netcdf4\")\n\nnemo\n</code></pre> <pre><code>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:               (time_counter: 2, axis_nbounds: 2, ncatice: 5)\n\u2502   ...\n\u2502 \n\u251c\u2500\u2500 Group: /gridT\n\u2502   \u2502   Dimensions:               (time_counter: 2, axis_nbounds: 2, j: 148, i: 180,\n\u2502   \u2502                              ncatice: 5, k: 31)\n\u2502   \u2502   ...\n\u2502   \u2514\u2500\u2500 Group: /gridT/1_gridT\n\u2502       \u2502   Dimensions:               (time_counter: 2, axis_nbounds: 2, j1: 80, i1: 100,\n\u2502       \u2502                              ncatice: 5, k1: 29)\n\u2502       \u2502   ...\n\u2502       \u2514\u2500\u2500 Group: /gridT/1_gridT/2_gridT\n\u2502               Dimensions:               (time_counter: 2, axis_nbounds: 2, j2: 99, i2: 120,\n\u2502                                          ncatice: 5, k2: 60)\n\u2502               ...\n\u251c\u2500\u2500 Group: /gridU\n\u2502   \u2502   Dimensions:               (k: 31, axis_nbounds: 2, time_counter: 2, j: 148,\n\u2502   \u2502                              i: 180)\n\u2502   \u2502   ...\n\u2502   \u2514\u2500\u2500 Group: /gridU/1_gridU\n\u2502       \u2502   Dimensions:               (k1: 29, axis_nbounds: 2, time_counter: 2, j1: 80,\n\u2502       \u2502                              i1: 100)\n\u2502       \u2502   ...\n\u2502       \u2514\u2500\u2500 Group: /gridU/1_gridU/2_gridU\n\u2502               Dimensions:               (k2: 60, axis_nbounds: 2, time_counter: 2, j2: 99,\n\u2502                                          i2: 120)\n\u2502               ...\n\u251c\u2500\u2500 Group: /gridV\n\u2502   \u2502   Dimensions:               (k: 31, axis_nbounds: 2, time_counter: 2, j: 148,\n\u2502   \u2502                              i: 180)\n\u2502   \u2502   ...\n\u2502   \u2514\u2500\u2500 Group: /gridV/1_gridV\n\u2502       \u2502   Dimensions:               (k1: 29, axis_nbounds: 2, time_counter: 2, j1: 80,\n\u2502       \u2502                              i1: 100)\n\u2502       \u2502   ...\n\u2502       \u2514\u2500\u2500 Group: /gridV/1_gridV/2_gridV\n\u2502               Dimensions:               (k2: 60, axis_nbounds: 2, time_counter: 2, j2: 99,\n\u2502                                          i2: 120)\n\u2502               ...\n\u251c\u2500\u2500 Group: /gridW\n\u2502   \u2502   Dimensions:               (k: 31, axis_nbounds: 2, time_counter: 2, j: 148,\n\u2502   \u2502                              i: 180)\n\u2502   \u2502   ...\n\u2502   \u2514\u2500\u2500 Group: /gridW/1_gridW\n\u2502       \u2502   Dimensions:               (k1: 29, axis_nbounds: 2, time_counter: 2, j1: 80,\n\u2502       \u2502                              i1: 100)\n\u2502       \u2502   ...\n\u2502       \u2514\u2500\u2500 Group: /gridW/1_gridW/2_gridW\n\u2502               Dimensions:               (k2: 60, axis_nbounds: 2, time_counter: 2, j2: 99,\n\u2502                                          i2: 120)\n\u2502               ...\n\u2514\u2500\u2500 Group: /gridF\n    \u2502   Dimensions:       (j: 148, i: 180, k: 31)\n    \u2502   ...\n    \u2514\u2500\u2500 Group: /gridF/1_gridF\n        \u2502   Dimensions:       (j1: 80, i1: 100, k1: 29)\n        \u2502   ...\n        \u2514\u2500\u2500 Group: /gridF/1_gridF/2_gridF\n                Dimensions:       (j2: 99, i2: 120, k2: 60)\n                ...\n</code></pre>"},{"location":"examples/#coupled-climate-models","title":"Coupled Climate Models:","text":"<p><code>UKESM1-0-LL</code></p> <p>In addition to ocean-only and ocean sea-ice hindcast simulations (prescribing surface atmospheric forcing), NEMO models are also used as the ocean components in many coupled climate models, including the UK Earth System Model (UKESM) developed jointly by the UK Met Office and Natural Environment Research Council (NERC).</p> <p>Here, we show how to construct a <code>NEMODataTree</code> from the 1\u00b0 global ocean sea-ice component of UKESM1-0-LL included in the sixth Coupled Model Intercomparsion Project (CMIP6) using outputs accessible via the CEDA Archive.</p> <p>Since CMIP6 outputs are processed and formatted according to the CMIP Community Climate Model Output Rewriter (CMOR) software, we will need to include a few additional pre-processing steps to reformat our NEMO model outputs in order to construct a <code>NEMODataTree</code></p> <p>Important: only CMIP model outputs variables stored on their original NEMO ocean model grid (i.e, <code>gn</code>) can be used to construct a <code>NEMODataTree</code></p> <pre><code># Open domain_cfg:\nds_domain_cfg = xr.open_dataset(\"/path/to/MOHC/Ofx/domain_cfg_Ofx_UKESM1.nc\")\n\n# Define time decoder to handle CMIP6 time units:\ntime_decoder = xr.coders.CFDatetimeCoder(use_cftime=True)\n\n# Open potential temperature (\u00b0C) dataset:\nbase_filepath = \"/badc/cmip6/data/CMIP6/CMIP/MOHC/UKESM1-0-LL/historical/r4i1p1f2/Omon/thetao/gn/latest\"\nds_ukesm1_gridT = xr.open_mfdataset(f\"{base_filepath}/thetao_Omon_UKESM1-0-LL_historical_r4i1p1f2_gn_*.nc\",\n                                    data_vars='all',\n                                    decode_times=time_decoder\n                                   )\n\n# Adding mixed layer depth (m) to dataset:\nds_ukesm1_gridT['mlotst'] = xr.open_mfdataset(f\"{base_filepath}/mlotst_Omon_UKESM1-0-LL_historical_r4i1p1f2_gn_*.nc\",\n                                              data_vars='all',\n                                              decode_times=time_decoder\n                                              )['mlotst']\n</code></pre> <p>Now we have defined our <code>domain</code> and <code>gridT</code> datasets, let's define a <code>datasets</code> dictionary ensuring that we rename CMORISED dimensions to be consistent with standard NEMO model outputs.</p> <p>We can then define a <code>NEMODataTree</code> using the <code>.from_datasets()</code> constructor, specifying that our global parent domain is zonally periodic and north-folding on F-points.</p> <pre><code>datasets = {\"parent\": {\n                \"domain\": ds_domain_cfg.rename({'z':'nav_lev'}),\n                \"gridT\": ds_ukesm1_gridT.rename({'time':'time_counter', 'i':'x', 'j':'y', 'lev':'deptht'}),\n                }}\n\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</code></pre>"},{"location":"howto/","title":"How To...","text":""},{"location":"howto/#a-quickstart-guide-to-common-operations-with-nemodatatree","title":"A Quickstart Guide to Common Operations with NEMODataTree","text":"<p>In this section, we describe some of the most common <code>NEMODataTree</code> operations in a concise how-to guide (inspired by the excellent documentation of Icechunk).</p> <p>For more detailed documentation on each of the <code>NEMODataTree</code> methods, user should visit the API.</p>"},{"location":"howto/#create-a-nemodatatree-from-local-files","title":"Create a NEMODataTree from Local Files","text":"<p>We can create a <code>NEMODataTree</code> from a dictionary of paths to local netCDF files using the <code>.from_paths()</code> constructor:</p> <pre><code>paths = {\"parent\": {\n         \"domain\": \"/path/to/domain_cfg.nc\",\n         \"gridT\": \"path/to/*_gridT.nc\",\n         \"gridU\": \"path/to/*_gridV.nc\",\n         \"gridV\": \"path/to/*_gridV.nc\",\n         \"gridW\": \"path/to/*_gridW.nc\",\n         \"icemod\": \"path/to/*_icemod.nc\",\n        },\n        }\n\nNEMODataTree.from_paths(paths, iperio=True, nftype=\"T\")\n</code></pre> <p>In the example above, we consider only a global parent domain, which is zonally periodic (<code>iperio=True</code>) and north-folding on T grid points (<code>nftype=\"T\"</code>). Note, that we are only required to specify paths for one or more NEMO model grid types (e.g., <code>*_gridT.nc</code>).</p>"},{"location":"howto/#create-a-nemodatatree-from-xarraydatasets","title":"Create a NEMODataTree from <code>xarray.Datasets</code>","text":"<p>Alternatively, we can create a <code>NEMODataTree</code> from a dictionary of single or multi-file <code>xarray.Datasets</code>. This is particularly valuable when working with remote NEMO model data or Coupled Model Intercomparison Project (CMIP) outputs which require us to reformat coordinate dimensions (see Example NEMODataTrees).</p> <pre><code>ds_domain = xr.open_zarr(\"https://some_remote_data/domain_cfg.zarr\")\nds_gridT = xr.open_zarr(\"https://some_remote_data/MY_MODEL_gridT.nc\")\n\ndatasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}\n\nnemo = NEMODataTree.from_datasets(datasets=datasets)\n</code></pre> <p>This example would be applicable to the outputs of a regional NEMO model configuration which is neither zonally periodic nor north-folding (by default, <code>iperio=False</code> &amp; <code>nftype=None</code>).</p>"},{"location":"howto/#calculate-grid-cell-areas","title":"Calculate Grid Cell Areas","text":"<p>To calculate the area of a model grid cell face, we can use the <code>.cell_area()</code> method.</p> <p>For example, to compute the horizontal area of cells centered on T grid points in the parent domain:</p> <pre><code>nemo.cell_area(grid=\"/gridT\", dim=\"k\")\n</code></pre> <p>Importantly, the <code>dim</code> argument represents the dimensional orthogonal to the grid cell area to be compute. For T grid points, this results in the following grid cell areas: </p> <code>dim</code> Grid Cell Area <code>i</code> e2t * e3t <code>j</code> e1t * e3t <code>k</code> e1t * e2t"},{"location":"howto/#calculate-grid-cell-volumes","title":"Calculate Grid Cell Volumes","text":"<p>To calculate the volume of model grid cells, we can use the <code>.cell_volume()</code> method.</p> <p>For example, to compute the volume of each grid cell centered on a V grid point in the model parent domain:</p> <pre><code>nemo.cell_volumes(grid=\"/gridV\")\n</code></pre>"},{"location":"howto/#clip-a-nemo-model-grid","title":"Clip a NEMO Model Grid","text":"<p>To clip a given model grid using a geographical bounding box defined by a tuple of the form (<code>lon_min</code>, <code>lon_max</code>, <code>lat_min</code>, <code>lat_max</code>), we can use the <code>.clip_grid()</code> method.</p> <p>For example, to clip the parent T-grid in the bounding box (-80\u00b0E, 0\u00b0E, 40\u00b0N, 80\u00b0N):</p> <pre><code>bbox = (-80, 0, 40, 80)\n\nnemo.clip_grid(grid=\"/gridT\", bbox=bbox)\n</code></pre>"},{"location":"howto/#clip-a-nemo-model-domain","title":"Clip a NEMO Model Domain","text":"<p>To clip all of the model grids of a given NEMO model domain:</p> <pre><code>nemo.clip_domain(dom=\".\", bbox=bbox)\n</code></pre> <p>where <code>dom</code> is the prefix of the chosen NEMO model domain. Note <code>dom=\".\"</code> for the parent domain.</p>"},{"location":"howto/#calculate-horizontal-gradients","title":"Calculate Horizontal Gradients","text":"<p>To calculate the gradient of a scalar variable <code>var</code> along one of the horizontal dimensions (e.g., <code>i</code>, <code>j</code>) of a given NEMO model grid, we can use the <code>.gradient()</code> method.</p> <p>For example, to compute the 'meridional' gradient of sea surface temperature <code>tos_con</code> along the NEMO model parent domain <code>j</code> dimension:</p> <pre><code>nemo.gradient(dom='.', var=\"tos_con\", dim=\"j\")\n</code></pre>"},{"location":"howto/#calculate-vertical-gradients","title":"Calculate Vertical Gradients","text":"<p>To calculate the vertical gradient of a scalar variable <code>var</code> along the <code>k</code> dimension of a given NEMO model grid, we can also use the <code>.gradient()</code> method.</p> <p>For example, to compute the vertical gradient of absolute salinity in our first NEMO model nested child domain:</p> <pre><code>nemo.gradient(dom=\"1\", var=\"so_abs\", dim=\"k\")\n</code></pre>"},{"location":"howto/#calculate-divergence","title":"Calculate Divergence","text":"<p>To calculate the horizontal divergence from the <code>i</code> and <code>j</code> components of a vector field, we can use the <code>.divergence()</code> method.</p> <p>For example, to compute the horizontal divergence from the seawater velocity field in the NEMO model parent domain:</p> <pre><code>nemo.divergence(dom=\".\", vars=[\"uo\", \"vo\"])\n</code></pre> <p>where <code>vars</code> is a list specifying the names of <code>i</code> and <code>j</code> vector components, respectively.</p>"},{"location":"howto/#calculate-curl","title":"Calculate Curl","text":"<p>To calculate the vertical <code>k</code> component of the curl of a horizontal vector field, we can use the <code>.curl()</code> method.</p> <p>For example, to compute the vertical component of the curl of the seawater velocity field in the second NEMO nested child domain:</p> <pre><code>nemo.curl(dom=\"2\", vars=[\"uo\", \"vo\"])\n</code></pre> <p>where, as in the case of <code>.divergence()</code>, the <code>vars</code> argument expects a list of the <code>i</code> anf <code>j</code> components of the vector field, respectively.</p>"},{"location":"howto/#calculate-integrals","title":"Calculate Integrals","text":"<p>To integrate a variable along one or more dimensions of a given NEMO model grid, we can use the <code>.integral()</code> method.</p> <p>For example, to compute the integral of conservative temperature <code>thetao_con</code> along the vertical <code>k</code> dimension in the NEMO model parent domain:</p> <pre><code>nemo.integral(grid=\"/gridT\", var=\"thetao_con\", dims=[\"k\"])\n</code></pre> <p>which will return an <code>xarray.DataArray</code> with one less dimension than <code>thetao_con</code>, in this case <code>k</code> since we have integrated vertically.</p>"},{"location":"howto/#calculate-cumulative-integrals","title":"Calculate Cumulative Integrals","text":"<p>We can also use the <code>.integral()</code> method to calculate cumulative integrals along one or more dimensions of a given NEMO model grid.</p> <p>For example, to calculate the vertical meridional overturning stream function from the meridional velocity <code>vo</code> (zonally integrated meridional velocity accumulated with increasing depth):</p> <pre><code>nemo.integral(grid=\"/gridV\",\n              var=\"vo\",\n              dims=[\"i\", \"k\"], \n              cum_dims=[\"k\"],\n              dir=\"+1\",\n              )\n</code></pre> <p>where <code>dims</code> is a list of the names of all grid dimensions along which integration will be performed, and <code>cum_dims</code> specifies which of the dimensions in <code>dims</code> should be cumulatively integrated.</p> <p>The <code>dir</code> argument is used to define the direction of cumulative integration, where <code>dir = \"+1\"</code> means accumulating along the chosen dimension, such that grid indices are increasing. Conversely, <code>dir = \"-1\"</code> means that cumulative integration is performed after reversing the chosen dimension, such that grid dimensions are decreasing.</p> <p>Note, we can also pass the <code>mask</code> argument to <code>.integral()</code> to mask the variable <code>var</code> prior to performing the integration. </p>"},{"location":"howto/#create-regional-masks-using-polygons","title":"Create Regional Masks using Polygons","text":"<p>To define a regional mask using the geographical coordinates of a closed polygon, we can use the <code>.mask_with_polygon()</code> method:</p> <pre><code>nemo.mask_with_polygon(grid=\"/gridT\", lon_poly, lat_poly)\n</code></pre> <p>where <code>lon_poly</code> and <code>lat_poly</code> are lists or ndarrays containing the longitude and latitude coordinates defining the closed polygon.</p>"},{"location":"howto/#calculate-statistics-for-a-region-masked-using-a-polygon","title":"Calculate Statistics for a Region Masked using a Polygon","text":"<p>To calculate an aggregated statistic from only the model grid cells contained inside a geographical polygon, we can use the <code>.masked_statistic()</code> method.</p> <p>For example, to compute the grid cell area-weighted mean sea surface temperature <code>tos_con</code> for a region enclosed in a polygon defined by <code>lon_poly</code> and <code>lat_poly</code> in a NEMO model nested child domain:</p> <pre><code>nemo.masked_statistic(grid=\"/gridT/1_gridT\",\n                      var=\"tos_con\",\n                      lon_poly,\n                      lat_poly,\n                      statistic=\"weighted_mean\",\n                      dims=[\"i\", \"j\"]\n                      )\n</code></pre> <p>where <code>dims</code> represent the dimensions of the NEMO model grid used for aggregation. In this example, combining <code>statistic=\"weighted_mean\"</code> and <code>dims=[\"i\", \"j\"]</code> is equivalent to computing the mean of variable <code>tos_con</code> using the horizontal cell area of T grid points (i.e., e1t * e2t) as weights.</p>"},{"location":"howto/#calculate-binned-statistics","title":"Calculate Binned Statistics","text":"<p>To calculate aggregated statistics of a variable binned according to the values of one or more variables, we can use the <code>.binned_statistic()</code> method. </p> <p>This is a generalization of a histogram function, enabling the computation of the sum, mean, median, or other statistic of the values assigned to each bin.</p> <p>For example, to compute the mean depth associated with each isopycnal in discrete potential density (<code>sigma0</code>) coordinates:</p> <pre><code>sigma0_bins = np.arange(22, 29.05, 0.05)\n\nnemo.binned_statistic(grid=\"/gridT\",\n                      vars=[\"sigma0\"],\n                      values=\"deptht\",\n                      keep_dims=[\"time_counter\"],\n                      bins=[sigma0_bins],\n                      statistic=\"nanmean\",\n                      )\n</code></pre> <p>where <code>vars</code> is a list of the names of variables to be binned using the bin edges passed to <code>bins</code>, and <code>values</code> is the name of the variable over which the <code>statistic</code> will be performed once values have been grouped into each bin.</p> <p>We can use <code>keep_dims</code> to specify the dimensions of the <code>xarray.DataArray</code> named <code>values</code> to retain. In the example above, using <code>keep_dims=\"time_counter\"</code> will return the average depths of water in each potential density bin for each time-slice of available NEMO model output.</p>"},{"location":"howto/#transform-a-vertical-grid","title":"Transform a Vertical Grid","text":"<p>To transform a variable defined on a given NEMO model vertical grid to a new vertical grid using conservative interpolation, we can use the <code>.transform_vertical_grid()</code> method.</p> <p>For example, if we wanted to transform the conservative temperature variable <code>tos_con</code> defined in a NEMO model parent domain from it's native 75 unevenly-spaced z-levels to regulary spaced z-levels at 200 m intervals:</p> <pre><code>e3t_target = xr.DataArray(np.repeat(200.0, 30), dims=['k_new'])\n\nnemo.transform_vertical_grid(grid='/gridT',\n                             var = 'thetao_con',\n                             e3_new = e3t_target\n                            )\n</code></pre> <p>where <code>e3_new</code> represents the time-invariant vertical grid cell thicknesses defing the vertical grid onto which the variable <code>var</code> will be conservatively interpolated. </p> <p>There are some important points to remember when transforming variables onto new vertical grids with <code>NEMODataTree</code>:</p> <ul> <li> <p>New vertical grid cell thicknesses <code>e3_new</code> must sum to at least the maximum depth of the original vertical grid cell thicknesses (e.g., e3t).</p> </li> <li> <p>Currently, <code>e3_new</code> must be a 1-dimensional <code>xarray.DataArray</code> with dimension 'k_new'.</p> </li> <li> <p>The output <code>xarray.Dataset</code> will contain multi-dimensional <code>xarray.DataArrays</code> for both the vertically remapped variable <code>var(time_counter, k_new, j, i)</code> and the vertical grid cell thicknesses <code>e3t_new(time_counter, k_new, j, i)</code> (updated to explicitly account for partial grid cells above the seafloor).</p> </li> </ul>"},{"location":"nemodatatree/","title":"NEMODataTree","text":""},{"location":"nemodatatree/#nemodatatree","title":"NEMODataTree","text":"<p>Each recipe in the NEMO Cookbook leverages the <code>NEMODataTree</code> object to store NEMO ocean model outputs and to help perform diagnostic calculations.</p> <p>In this User Guide, we provide an introduction to the <code>NEMODataTree</code>, including examples using outputs from the NEMO version 5 <code>AGRIF_DEMO</code> and <code>AMM12</code> reference configurations.</p> <p>For further details on <code>NEMODataTree</code> constructors, properties and computation patterns, users are referred to the API documentation.</p>"},{"location":"nemodatatree/#what-is-a-datatree","title":"What is a DataTree?","text":"<p>Ocean model simulations produce large collections of datasets, including physics, biogeochemistry, and sea ice diagnostics, which are defined on different grids. Moreover, ocean models configuration often include nested domains, where datasets of model diagnostics are produced for each of the parent, child and grandchild domains.</p> <p>Organising these gridded datasets into a single, interpretable data structure has traditionally been a major challenge for researchers when developing their data analysis workflows.</p> <p>This is where the <code>xarray.DataTree</code> comes in.</p> <p>The <code>xarray.DataTree</code> extends the more familiar collection of xarray data structures (e.g., <code>xarray.Dataset</code>) to allow hierarchical grouping of datasets, similar to a local file system. Each <code>xarray.DataTree</code> is composed of a hierarchy of nodes, each containing a separate <code>xarray.Dataset</code>. </p> <pre><code>DataTree('root')\n\u2514\u2500\u2500global\n    \u2514\u2500\u2500 regional_nest\n</code></pre> <p>The root node sits at the top of the DataTree ('/') and each of its child nodes can have children (or sub-groups) of their own. In the example above, the root node has a single child node (<code>global</code>) storing the global domain outputs of an ocean model simulation. This in-turn has a single child node (<code>regional_nest</code>) storing the outputs of a regional nest inside the global domain.</p> <p>We can hence describe each node in a DataTree in terms of the <code>parent</code> to which the node belongs, and its <code>children</code> - child nodes to which it is the parent. The root node is an important exception however, since it has no <code>parent</code> node.</p> <p>To access a node in our DataTree, we use Python's standard dictionary syntax to define the path to the target node in the DataTree as follows:</p> <pre><code>dt['global/regional_nest']\n</code></pre> <p>We can then access the variables stored in the <code>xarray.Dataset</code> associated with a given node as follows:</p> <pre><code>ds['global/regional_nest']['var_name']\n</code></pre> <p>In summary, an <code>xarray.DataTree</code> can help ocean modellers organise complex outputs (nested domains, groups of variables) in a natural, hierarchical way by acting as a container for a collection of related  <code>xarray.Datasets</code>.</p>"},{"location":"nemodatatree/#what-is-a-nemodatatree","title":"What is a NEMODataTree?   |","text":"<p><code>NEMODataTree</code> is an extension of the <code>xarray.DataTree</code> structure designed to store NEMO model output datasets as nodes in a hierarchical tree.</p>"},{"location":"nemodatatree/#nemo-model-grid","title":"NEMO Model Grid","text":"<p>The NEMO Ocean Engine (Madec et al., 2024) solves the Primitive Equations using the traditional, centred second-order finite difference approximation.</p> <p>Variables are spatially discretised using a 3-dimensional Arakawa \u201cC\u201d grid (Mesinger and Arakawa, 1976), consisting of cells centred on scalar points T (e.g. temperature, salinity, density, and horizontal divergence).</p> <p>Vector points (u, v, w) are defined at the centre of each cell face. The relative and planetary vorticity, \u03b6 and f, are defined at f points, which are located at the centre of each vertical edge.</p> <p>In NEMO, the ocean mesh (i.e. the position of all the scalar and vector points) is defined in terms of a set of orthogonal curvilinear grid indices (i, j, k), such that geographical coordinates are given as functions of these grid indices (i.e., \u03bb(j, i), \u03c6(j, i), z(k)).</p> <p>All grid-points on the ocean mesh are located at integer or integer and a half values of (i, j, k) as shown below:</p> Grid Type Grid Indices <code>T</code> (i, j, k) <code>U</code> (i + 1/2, j, k) <code>V</code> (i, j + 1/2, k) <code>W</code> (i, j, k + 1/2) <code>F</code> (i + 1/2, j + 1/2, k) <p>For each type of grid-point, three grid scale factors are defined... </p> <ul> <li>Horizontal scale factors (e1, e2)</li> <li>Vertical scale factor (e3)</li> </ul> <p>...such that the volume of a given type of grid cell is given by (e1<sub>k</sub> e2<sub>k</sub> e3<sub>k</sub>), where k is the grid point type. Similarly, the horizontal grid cell area is given by (e1<sub>k</sub> e2<sub>k</sub>).</p> <p>For more information on the spatial discretisation of variables in NEMO, see Chapter 3 of the NEMO Reference Manual.</p>"},{"location":"nemodatatree/#nemo-outputs","title":"NEMO Outputs","text":"<p>Although many experienced researchers will be familiar with the typical output format of NEMO model simulations, we provide a brief summary below for new users.</p> <p>NEMO model simulations write time-averaged diagnostics to output files in netCDF4 format using an external I/O library and server named XIOS.</p> <p>Typically, separate netCDF files are produced at each time-averaging interval (e.g., monthly) for groups of variables located at the same type of grid points. This results in the following types of netCDF files:</p> <ul> <li> <p><code>...grid_T.nc</code>  scalar variables (e.g., conservative temperature &amp; absolute salinity) defined at the centre of each model grid cell.</p> </li> <li> <p><code>...grid_U.nc</code>  vector variables (e.g., zonal seawater velocity) defined at the centre of each eastern grid cell face.</p> </li> <li> <p><code>...grid_V.nc</code>  vector variables (e.g., meridional seawater velocity) defined at the centre of each northern grid cell face.</p> </li> <li> <p><code>...grid_W.nc</code>  vector variables (e.g., vertical seawater velocity) defined at the centre of each bottom grid cell face.</p> </li> <li> <p><code>...grid_F.nc</code>  vector variables (e.g., relative vorticity) defined at the centre of each vertical edge.</p> </li> </ul> <p>Often global scalar diagnostics (e.g., global mean temperature) are also produced, resulting in a further type of netCDF file:</p> <ul> <li><code>...scalar.nc</code>  1-dimensional scalar variables calculated by aggregating a variable defined on the model T grid.</li> </ul> <p>When the NEMO ocean engine is coupled to a sea ice model (e.g., SI3), netCDF files will also be produced for sea ice variables using the following suffix:</p> <ul> <li><code>...icemod.nc</code>  sea ice variables (e.g., sea ice concetration) defined at the centre of each model grid cell.</li> </ul>"},{"location":"nemodatatree/#defining-a-simple-nemodatatree","title":"Defining a Simple NEMODataTree","text":"<p>For a typical NEMO model configuration, consisting of a global parent domain coupled to a sea ice model, we can define a simple <code>DataTree</code>:</p> <pre><code>&lt;xarray.DataTree 'nemo'&gt;\nGroup: /\n\u251c\u2500\u2500 Group: /gridT\n\u251c\u2500\u2500 Group: /gridU\n\u251c\u2500\u2500 Group: /gridV\n\u251c\u2500\u2500 Group: /gridW\n\u2514\u2500\u2500 Group: /gridF\n</code></pre> <p>where the <code>gridT</code> child node contains time series of scalar variables stored in the <code>...grid_T.nc</code> files in a single <code>xarray.Dataset</code> and so on.</p>"},{"location":"nemodatatree/#domain-variables","title":"Domain Variables","text":"<p>Importantly, a <code>NEMODataTree</code> does not need a <code>domain</code> node to store the grid scale factors and masks associated with each model domain. </p> <p>Why?</p> <p>This is because domain variables are assigned to their respective grid nodes during pre-processing (e.g., horizontal grid scale factors <code>e1t</code> and <code>e2t</code> are stored in <code>gridT</code> etc.).</p>"},{"location":"nemodatatree/#dimensions-coordinates","title":"Dimensions &amp; Coordinates","text":"<p>Typically, the netCDF files output by NEMO model simulations have dimensions (<code>depth{k}</code>, <code>y</code>, <code>x</code>), where k is the grid point type.</p> <p>During the construction of a NEMODataTree, these coordinate dimensions are transformed into the NEMO model grid indices (i, j, k) according to the Table included in the NEMO Model Grid section above. This has two important implications:</p> <ol> <li> <p>The <code>xarray.Datasets</code> stored in each grid node share the same coordinate dimension names (<code>i</code>, <code>j</code>, <code>k</code>), but are staggered according to where variables are position on the NEMO model grid.</p> </li> <li> <p>All grid indices use Fortran (1-based) indexing consistent with their definition in the original NEMO model code.</p> </li> </ol> <p>In practice, this means that a variable defined at the first T-point will be at (<code>i=1</code>, <code>j=1</code>), whereas a variable located at the first U-point will be at (<code>i=1.5</code>, <code>j=1</code>). This approach was chosen to ensure users encounter alignment errors when attempting to calculate diagnostics using variables defined on different grids. Instead, scalar or vector variables should be interpolated onto the desired grid before computation.</p> <p>A further practical implication is that users should always use <code>.sel()</code> to subset data variables according to their grid indices on the NEMO ocean mesh.</p>"},{"location":"nemodatatree/#summary","title":"Summary","text":"<p>Below we summarise the steps required to define a <code>NEMODataTree</code> from a collection of output netCDF files:</p> <p>Steps to Define a NEMODataTree</p> <ol> <li> <p>For each type of netCDF output, open all available files as a single <code>xarray.Dataset</code> using <code>xarray.open_mfdataset()</code>.</p> </li> <li> <p>Add domain variables stored in the domain_cfg.nc file to the each grid dataset (e.g., <code>e1t</code>, <code>e2t</code> are added to <code>gridT</code>).</p> </li> <li> <p>Add / calculate masks for each grid type (e.g., <code>tmask</code> is added to <code>gridT</code>).</p> </li> <li> <p>Redefine the <code>dims</code> and <code>coords</code> of each grid dataset to use <code>i</code>, <code>j</code>, <code>k</code> as used to define the semi-discrete equations in NEMO.</p> </li> <li> <p>Assemble the <code>xarray.DataTree</code> using a dictionary of processed NEMO model grid datasets.</p> </li> </ol> <p>The steps above highlight that the <code>NEMODataTree</code> is simply a specific case of the more general <code>xarray.DataTree</code> structure.</p>"},{"location":"nemodatatree/#defining-a-nested-nemodatatree","title":"Defining a Nested NEMODataTree","text":"<p>For a nested NEMO model configuration, including a parent, child and grandchild domain, we can define a more complex <code>NEMODataTree</code>:</p> <pre><code>&lt;xarray.DataTree 'nemo'&gt;\nGroup: /\n\u251c\u2500\u2500 Group: /gridT\n|   \u2514\u2500\u2500 Group: /gridU/1_gridU\n|       \u2514\u2500\u2500 Group: /gridU/1_gridU/2_gridU\n\u251c\u2500\u2500 Group: /gridU\n|   \u2514\u2500\u2500 Group: /gridU/1_gridU\n|       \u2514\u2500\u2500 Group: /gridU/1_gridU/2_gridU\n\u251c\u2500\u2500 Group: /gridV\n|   \u2514\u2500\u2500 Group: /gridV/1_gridV\n|       \u2514\u2500\u2500 Group: /gridV/1_gridV/2_gridV\n\u251c\u2500\u2500 Group: /gridW\n|   \u2514\u2500\u2500 Group: /gridW/1_gridW\n|       \u2514\u2500\u2500 Group: /gridW/1_gridW/2_gridW\n\u2514\u2500\u2500 Group: /gridF\n    \u2514\u2500\u2500 Group: /gridF/1_gridF\n        \u2514\u2500\u2500 Group: /gridF/1_gridF/2_gridF\n</code></pre> <p>where each parent grid node (e.g., <code>gridT</code>) has a corresponding child grid node (e.g., <code>1_gridT</code>), which itself has a corresponding child (grandchild) node (e.g., <code>2_gridT</code>).</p>"},{"location":"nemodatatree/#domain-variables_1","title":"Domain Variables","text":"<p>Nested child / grandchild domain variables are also assigned to their respective grid nodes during pre-processing (e.g., horizontal grid scale factors <code>e1t</code> and <code>e2t</code> are stored in <code>gridT</code> etc.).</p>"},{"location":"nemodatatree/#dimensions-coordinates_1","title":"Dimensions &amp; Coordinates","text":"<p>To ensure that the dimensions of nested child / grandchild domains are distinct from their parent, a prefix is added to all grid indices and associated geographical coordinate variables.</p> <p>The prefix corresponds to the unique domain number used to identify each child and grandchild domain during the construction the <code>NEMODataTree</code>. Hence, in the example above, the child grid node <code>1_gridT</code> will have NEMO model grid indices (<code>i1</code>, <code>j1</code>, <code>k1</code>) and associated coordinates <code>1_glamt(j1, i1)</code>, <code>1_gphit(j1, i1)</code> etc.</p>"},{"location":"nemodatatree/#summary_1","title":"Summary","text":"<p>In summary, defining a <code>NEMODataTree</code> for a nested configuration includes two important additional steps:</p> <p>Steps to Define a NEMODataTree</p> <ol> <li> <p>For each type of netCDF output, open all available files as a single <code>xarray.Dataset</code> using <code>xarray.open_mfdataset()</code>.</p> </li> <li> <p>Add domain variables stored in the domain_cfg.nc file to the each grid dataset (e.g., <code>e1t</code>, <code>e2t</code> are added to <code>gridT</code>).</p> </li> <li> <p>Add / calculate masks for each grid type (e.g., <code>tmask</code> is added to <code>gridT</code>).</p> </li> <li> <p>Redefine the <code>dims</code> and <code>coords</code> of each grid dataset to use <code>i{dom}</code>, <code>j{dom}</code>, <code>k{dom}</code> as used to define the semi-discrete equations in NEMO, where dom is the unique domain number.</p> </li> <li> <p>Clip nested child domains to remove ghost points along the boundaries &amp; add a mapping from the parent grid indices to the child grid indices to the <code>coords</code>.</p> </li> <li> <p>Assemble dictionaries of processed NEMO model grid datasets for each of the parent, child and grandchild domains.</p> </li> <li> <p>Assemble the <code>xarray.DataTree</code> using a nested dictionary of NEMO model domains.</p> </li> </ol>"},{"location":"recipe_barotropic_sf/","title":"Barotropic Stream Functions","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport xarray as xr\nfrom nemo_cookbook import NEMODataTree\n\nimport cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\nimport cartopy.feature as cfeature\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import xarray as xr from nemo_cookbook import NEMODataTree  import cartopy.crs as ccrs import matplotlib.pyplot as plt import cartopy.feature as cfeature  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x3286767b0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[2]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})\n             .rename({'z': 'nav_lev'})\n             .squeeze(drop=True)\n             )\nds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})              .rename({'z': 'nav_lev'})              .squeeze(drop=True)              ) ds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})  ds_domain Out[2]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (y: 331, x: 360, nav_lev: 75)\nDimensions without coordinates: y, x, nav_lev\nData variables: (12/54)\n    e1t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2v            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bottom_level   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2u            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bathy_metry    (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (nav_lev) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   float64 8B dask.array&lt;chunksize=(), meta=np.ndarray&gt;\n    top_level      (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we need to import the meridional velocity and vertical grid cell thicknesses stored at V-points in a single dataset.</p> <p>Typically, NEMO model outputs defined on V-grid points are stored together in netCDF files. In this case, you can replace <code>xr.merge()</code> with a single call to xarray's <code>open_dataset()</code> function passing the file path to your <code>_gridV.nc</code> file(s).</p> In\u00a0[3]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/V1y\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\")\n\nds_gridV\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/V1y\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\")  ds_gridV Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 4GB\nDimensions:        (depthv: 75, y: 331, x: 360, time_counter: 49)\nCoordinates:\n  * depthv         (depthv) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n  * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\nDimensions without coordinates: y, x\nData variables:\n    e3v            (time_counter, depthv, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    vo             (time_counter, depthv, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean (interval: 3600 s)\n    interval_operation:  3600 s\n    interval_write:      1 yr\n    long_name:           V-cell thickness\n    online_operation:    average\n    standard_name:       cell_thickness\n    units:               m</pre> In\u00a0[4]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain, \"gridV\": ds_gridV}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain, \"gridV\": ds_gridV}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[4]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 49)\n\u2502   Coordinates:\n\u2502       time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502     * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level     (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level  (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           tmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           umaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:        (time_counter: 49, k: 75, j: 331, i: 360)\n\u2502       Coordinates:\n\u2502         * depthv         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphiv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e3v            (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           vo             (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           e1v            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502           vmaskutil      (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           cell_methods:        time: mean (interval: 3600 s)\n\u2502           interval_operation:  3600 s\n\u2502           interval_write:      1 yr\n\u2502           long_name:           V-cell thickness\n\u2502           online_operation:    average\n\u2502           standard_name:       cell_thickness\n\u2502           units:               m\n\u2502           nftype:              F\n\u2502           iperio:              True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n            fmaskutil     (j, i) bool 119kB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> In\u00a0[5]: Copied! <pre>atlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"})\n\nbsf_atl = nemo.integral(grid=\"/gridV\",\n                        var=\"vo\",\n                        dims=[\"k\", \"i\"], \n                        cum_dims=[\"i\"],\n                        dir=\"+1\",\n                        mask=atlmask\n                        )\n\nbsf_atl\n</pre> atlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"})  bsf_atl = nemo.integral(grid=\"/gridV\",                         var=\"vo\",                         dims=[\"k\", \"i\"],                          cum_dims=[\"i\"],                         dir=\"+1\",                         mask=atlmask                         )  bsf_atl Out[5]: <pre>&lt;xarray.DataArray 'vo' (time_counter: 49, j: 331, i: 360)&gt; Size: 47MB\ndask.array&lt;nancumsum, shape=(49, 331, 360), dtype=float64, chunksize=(1, 331, 360), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n    time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    gphiv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    glamv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n  * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n  * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360</pre> <p>Notice that the resulting DataArray includes a dask array, so we haven't actually computed the barotropic stream function yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[6]: Copied! <pre># Compute barotropic stream function in Sverdrups [1 Sv = 1E6 m3/s]:\nbsf_atl = 1E-6 * bsf_atl.compute()\n\nbsf_atl\n</pre> # Compute barotropic stream function in Sverdrups [1 Sv = 1E6 m3/s]: bsf_atl = 1E-6 * bsf_atl.compute()  bsf_atl Out[6]: <pre>&lt;xarray.DataArray 'vo' (time_counter: 49, j: 331, i: 360)&gt; Size: 47MB\narray([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        ...,\n        [ 0.        ,  0.        ,  0.        , ..., -0.93092196,\n         -0.93092196, -0.93092196],\n        [ 0.        ,  0.        ,  0.        , ..., -0.93177347,\n         -0.93177347, -0.93177347],\n        [ 0.        ,  0.        ,  0.        , ..., -0.93259213,\n         -0.93259213, -0.93259213]],\n\n       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n...\n        [ 0.        ,  0.        ,  0.        , ..., -0.87334578,\n         -0.87334578, -0.87334578],\n        [ 0.        ,  0.        ,  0.        , ..., -0.87397618,\n         -0.87397618, -0.87397618],\n        [ 0.        ,  0.        ,  0.        , ..., -0.87391507,\n         -0.87391507, -0.87391507]],\n\n       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        ...,\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ]]], shape=(49, 331, 360))\nCoordinates:\n  * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n    time_centered  (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n    gphiv          (j, i) float64 953kB -84.16 -84.16 -84.16 ... 50.23 50.01\n    glamv          (j, i) float64 953kB 73.5 74.5 75.5 76.5 ... 73.0 73.0 73.0\n  * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n  * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360</pre> In\u00a0[8]: Copied! <pre># -- Create a figure with an orthographic (globe) projection -- #\nfig = plt.figure(figsize=(7, 7))\nproj = ccrs.Orthographic(central_longitude=-25, central_latitude=35)\nax = plt.axes(projection=proj)\nax.coastlines(resolution='110m', linewidth=0.8)\nax.add_feature(cfeature.LAND, facecolor='0.1', edgecolor='0.1', linewidth=0.2, zorder=4)\nax.gridlines(draw_labels=False, dms=True, x_inline=False, y_inline=False)\n\n# Plot eORCA1 JRA55v1 time-mean barotropic stream function:\nc_parent = ax.pcolormesh(bsf_atl.glamv, bsf_atl.gphiv, bsf_atl.mean(dim='time_counter'),\n                         transform=ccrs.PlateCarree(),\n                         cmap=\"RdBu_r\", shading=\"auto\",\n                         vmin=-30, vmax=30,\n                         zorder=1)\n\n# Plot eORCA1 JRA55v1 time-mean barotropic stream function contours:\nplt.contour(bsf_atl.glamv, bsf_atl.gphiv, bsf_atl.mean(dim='time_counter'),\n            levels=8, colors='k', linewidths=1,\n            transform=ccrs.PlateCarree(),\n            zorder=2)\n\n# Add colorbar with label:\ncb = plt.colorbar(c_parent, orientation=\"horizontal\", pad=0.05, shrink=0.7)\ncb.set_label(\"Barotropic Stream Function (Sv)\", fontsize=11)\n</pre> # -- Create a figure with an orthographic (globe) projection -- # fig = plt.figure(figsize=(7, 7)) proj = ccrs.Orthographic(central_longitude=-25, central_latitude=35) ax = plt.axes(projection=proj) ax.coastlines(resolution='110m', linewidth=0.8) ax.add_feature(cfeature.LAND, facecolor='0.1', edgecolor='0.1', linewidth=0.2, zorder=4) ax.gridlines(draw_labels=False, dms=True, x_inline=False, y_inline=False)  # Plot eORCA1 JRA55v1 time-mean barotropic stream function: c_parent = ax.pcolormesh(bsf_atl.glamv, bsf_atl.gphiv, bsf_atl.mean(dim='time_counter'),                          transform=ccrs.PlateCarree(),                          cmap=\"RdBu_r\", shading=\"auto\",                          vmin=-30, vmax=30,                          zorder=1)  # Plot eORCA1 JRA55v1 time-mean barotropic stream function contours: plt.contour(bsf_atl.glamv, bsf_atl.gphiv, bsf_atl.mean(dim='time_counter'),             levels=8, colors='k', linewidths=1,             transform=ccrs.PlateCarree(),             zorder=2)  # Add colorbar with label: cb = plt.colorbar(c_parent, orientation=\"horizontal\", pad=0.05, shrink=0.7) cb.set_label(\"Barotropic Stream Function (Sv)\", fontsize=11)"},{"location":"recipe_barotropic_sf/#description","title":"Description\u00b6","text":"<p>This recipe shows how to calculate the barotropic stream function for the North Atlantic Ocean using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_barotropic_sf/#background","title":"Background\u00b6","text":"<p>The barotropic stream function is routinely used to characterise the large-scale ocean circulation $\\psi_{xy}$ and can be defined using the meridional velocity field at time $t$ as follows:</p> <p>$$\\Psi_{xy}(\\lambda, \\phi, t) = \\int_{x_w}^{x} \\int_{-H}^{\\eta} v(\\lambda, \\phi, z, t) \\ dz \\ dx$$</p> <p>where the meridional velocity $v(\\lambda, \\phi, z, t)$ is first integrated from the sea surface $\\eta$ to the seafloor $-H$ before being accumulated zonally from the western ($x_w$) to the eastern ($x_e$) boundary of our model domain.</p>"},{"location":"recipe_barotropic_sf/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_barotropic_sf/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 JRA-55 model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_barotropic_sf/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_barotropic_sf/#calculating-the-barotropic-stream-function","title":"Calculating the Barotropic Stream Function\u00b6","text":"<p>Now we have constructed our <code>NEMODataTree</code>, let's calculate the time-mean barotropic stream function.</p> <p>$$\\psi_{xy}(t) = \\sum_{i^{*}=1}^{i} \\sum_{k} (e_{1v} . e_{3v}(t) . v(t))$$</p> <p>In this example, our eORCA1 model uses $z^{*}$ vertical coordinates, so we will use the <code>integral()</code> method to perform integration along the $i$ and $k$ dimensions of the NEMO model grid. The resulting 2-dimensional barotropic stream function represents the depth-integrated volume transport in the Atlantic Ocean.</p>"},{"location":"recipe_barotropic_sf/#visualising-the-time-mean-barotropic-stream-function","title":"Visualising the time-mean barotropic stream function\u00b6","text":"<p>Finally, let's visualise the results by plotting the time-mean barotropic stream function for the North Atlantic basin:</p>"},{"location":"recipe_extract_osnap/","title":"Extracting Hydrographic Sections","text":"In\u00a0[1]: Copied! <pre># -- Import Python packages -- #\nimport gsw\nimport glob\nimport numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\n\n# -- Import nemo_cookbook tools -- #\nfrom nemo_cookbook import extract_section, compute_section_moc_tracer\n</pre> # -- Import Python packages -- # import gsw import glob import numpy as np import xarray as xr import matplotlib.pyplot as plt  # -- Import nemo_cookbook tools -- # from nemo_cookbook import extract_section, compute_section_moc_tracer In\u00a0[2]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': '/dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/',\n                 'local_directory': '/dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/'\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=5, threads_per_worker=2, memory_limit='8GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': '/dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/',                  'local_directory': '/dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/'                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=5, threads_per_worker=2, memory_limit='8GB') client = Client(cluster) client Out[2]: Client <p>Client-22a26652-2424-11f0-8b84-b49691b90a4c</p> Connection method: Cluster object Cluster type: distributed.LocalCluster Dashboard:  http://127.0.0.1:8787/status Cluster Info LocalCluster <p>ef40b5a3</p> Dashboard: http://127.0.0.1:8787/status Workers: 5                  Total threads: 10                  Total memory: 37.25 GiB                  Status: running Using processes: True Scheduler Info Scheduler <p>Scheduler-845acd3e-0e3d-4cf2-b0b0-889785eacc5f</p> Comm: tcp://127.0.0.1:40485                      Workers: 0                       Dashboard: http://127.0.0.1:8787/status Total threads: 0                      Started: Just now                      Total memory: 0 B                      Workers Worker: 0 Comm:  tcp://127.0.0.1:46787                          Total threads:  2                          Dashboard:  http://127.0.0.1:33445/status Memory:  7.45 GiB                          Nanny:  tcp://127.0.0.1:40901                          Local directory:  /dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/dask-scratch-space/worker-s4warua8                          Worker: 1 Comm:  tcp://127.0.0.1:39001                          Total threads:  2                          Dashboard:  http://127.0.0.1:38883/status Memory:  7.45 GiB                          Nanny:  tcp://127.0.0.1:40711                          Local directory:  /dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/dask-scratch-space/worker-v_yjhntm                          Worker: 2 Comm:  tcp://127.0.0.1:38097                          Total threads:  2                          Dashboard:  http://127.0.0.1:36691/status Memory:  7.45 GiB                          Nanny:  tcp://127.0.0.1:41353                          Local directory:  /dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/dask-scratch-space/worker-q871rtsh                          Worker: 3 Comm:  tcp://127.0.0.1:33449                          Total threads:  2                          Dashboard:  http://127.0.0.1:36367/status Memory:  7.45 GiB                          Nanny:  tcp://127.0.0.1:39237                          Local directory:  /dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/dask-scratch-space/worker-k9nkn7yy                          Worker: 4 Comm:  tcp://127.0.0.1:39877                          Total threads:  2                          Dashboard:  http://127.0.0.1:33387/status Memory:  7.45 GiB                          Nanny:  tcp://127.0.0.1:40583                          Local directory:  /dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/dask-scratch-space/worker-v4gtywm2                          In\u00a0[3]: Copied! <pre># Define path to domain_cfg data:\ndomain_dir = \"/dssgfs01/scratch/npd/simulations/Domains/eORCA1\"\nfpath_domain = f\"{domain_dir}/domain_cfg.nc\"\n\n# Define directory path to model data:\ndata_dir = \"/dssgfs01/scratch/npd/simulations/eORCA1_ERA5_v1\"\n# Define list of file names for NEMO grids:\nfpaths_gridT = sorted(glob.glob(f\"{data_dir}/eORCA1_ERA5_1y_grid_T_*.nc\"))\nfpaths_gridU = sorted(glob.glob(f\"{data_dir}/eORCA1_ERA5_1y_grid_U_*.nc\"))\nfpaths_gridV = sorted(glob.glob(f\"{data_dir}/eORCA1_ERA5_1y_grid_V_*.nc\"))\n</pre> # Define path to domain_cfg data: domain_dir = \"/dssgfs01/scratch/npd/simulations/Domains/eORCA1\" fpath_domain = f\"{domain_dir}/domain_cfg.nc\"  # Define directory path to model data: data_dir = \"/dssgfs01/scratch/npd/simulations/eORCA1_ERA5_v1\" # Define list of file names for NEMO grids: fpaths_gridT = sorted(glob.glob(f\"{data_dir}/eORCA1_ERA5_1y_grid_T_*.nc\")) fpaths_gridU = sorted(glob.glob(f\"{data_dir}/eORCA1_ERA5_1y_grid_U_*.nc\")) fpaths_gridV = sorted(glob.glob(f\"{data_dir}/eORCA1_ERA5_1y_grid_V_*.nc\")) In\u00a0[4]: Copied! <pre># Define S3 URL to OSNAP gridded observational data in JASMIN Object Store:\nurl = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/ocean-obs/OSNAP/OSNAP_gridded_2014_2020/\"\nds_osnap = xr.open_zarr(url, zarr_format=3, consolidated=True)\n\n# Define observation coordinates defining the OSNAP array:\nosnap_lons = np.concatenate([ds_osnap['LONGITUDE'].values[::2], np.array([ds_osnap['LONGITUDE'].values[-1]])])\nosnap_lats = np.concatenate([ds_osnap['LATITUDE'].values[::2], np.array([ds_osnap['LATITUDE'].values[-1]])])\n</pre> # Define S3 URL to OSNAP gridded observational data in JASMIN Object Store: url = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/ocean-obs/OSNAP/OSNAP_gridded_2014_2020/\" ds_osnap = xr.open_zarr(url, zarr_format=3, consolidated=True)  # Define observation coordinates defining the OSNAP array: osnap_lons = np.concatenate([ds_osnap['LONGITUDE'].values[::2], np.array([ds_osnap['LONGITUDE'].values[-1]])]) osnap_lats = np.concatenate([ds_osnap['LATITUDE'].values[::2], np.array([ds_osnap['LATITUDE'].values[-1]])]) In\u00a0[5]: Copied! <pre># Extract the OSNAP section from the NEMO model data:\nds_osnap = extract_section(section_lon=osnap_lons,\n                           section_lat=osnap_lats,\n                           domain_path=fpath_domain,\n                           t_paths=fpaths_gridT,\n                           u_paths=fpaths_gridU,\n                           v_paths=fpaths_gridV,\n                           var_map={'temp':'thetao_con', 'sal':'so_abs'},\n                           uv_eiv=True, # Include eddy-induced velocities.\n                           )\n</pre> # Extract the OSNAP section from the NEMO model data: ds_osnap = extract_section(section_lon=osnap_lons,                            section_lat=osnap_lats,                            domain_path=fpath_domain,                            t_paths=fpaths_gridT,                            u_paths=fpaths_gridU,                            v_paths=fpaths_gridV,                            var_map={'temp':'thetao_con', 'sal':'so_abs'},                            uv_eiv=True, # Include eddy-induced velocities.                            ) <p>Let's explore the structure of our model-defined OSNAP array data:</p> In\u00a0[6]: Copied! <pre>print(ds_osnap)\n</pre> print(ds_osnap) <pre>&lt;xarray.Dataset&gt; Size: 7MB\nDimensions:                (depth: 75, time_counter: 49, station: 66)\nCoordinates:\n  * depth                  (depth) float32 300B 0.5058 1.556 ... 5.902e+03\n  * time_counter           (time_counter) datetime64[ns] 392B 1976-07-02 ... ...\n  * station                (station) int64 528B 0 1 2 3 4 5 ... 61 62 63 64 65\n    longitude              (station) float64 528B -56.8 -55.78 ... -9.802 -8.703\n    latitude               (station) float64 528B 52.19 52.26 ... 56.76 56.69\nData variables:\n    velocity               (time_counter, depth, station) float32 970kB nan ....\n    eddy_induced_velocity  (time_counter, depth, station) float32 970kB nan ....\n    dz                     (time_counter, depth, station) float32 970kB nan ....\n    dx                     (station) float64 528B 6.946e+04 ... 6.715e+04\n    volume_transport       (time_counter, depth, station) float64 2MB nan ......\n    temp                   (time_counter, depth, station) float32 970kB nan ....\n    sal                    (time_counter, depth, station) float32 970kB nan ....\nAttributes:\n    units:               m/s\n    online_operation:    average\n    interval_operation:  1 yr\n    interval_write:      1 yr\n    cell_methods:        time: mean\n</pre> In\u00a0[7]: Copied! <pre># Calculate potential density referenced to the sea surface using the Gibbs Sea Water Toolbox:\nds_osnap['sigma0'] = gsw.sigma0(SA=ds_osnap['sal'], CT=ds_osnap['temp'])\n\n# Plot the time-mean potential density alomng the OSNAP section:\nds_osnap['sigma0'].mean(dim='time_counter').plot(yincrease=False)\nplt.ylim([3800, 0])\n</pre> # Calculate potential density referenced to the sea surface using the Gibbs Sea Water Toolbox: ds_osnap['sigma0'] = gsw.sigma0(SA=ds_osnap['sal'], CT=ds_osnap['temp'])  # Plot the time-mean potential density alomng the OSNAP section: ds_osnap['sigma0'].mean(dim='time_counter').plot(yincrease=False) plt.ylim([3800, 0]) Out[7]: <pre>(3800.0, 0.0)</pre> In\u00a0[8]: Copied! <pre># Define potential density bins:\nsigma0_bins = np.arange(21, 28.2, 0.01)\n\n# Compute Total OSNAP diapycnal overturning stream function:\nds_osnap['moc_total'] = compute_section_moc_tracer(ds=ds_osnap,\n                                                   tracer_name='sigma0',\n                                                   tracer_bins=sigma0_bins,\n                                                   dir='-1',\n                                                   mask=None,\n                                                   )\n\nprint(ds_osnap)\n</pre> # Define potential density bins: sigma0_bins = np.arange(21, 28.2, 0.01)  # Compute Total OSNAP diapycnal overturning stream function: ds_osnap['moc_total'] = compute_section_moc_tracer(ds=ds_osnap,                                                    tracer_name='sigma0',                                                    tracer_bins=sigma0_bins,                                                    dir='-1',                                                    mask=None,                                                    )  print(ds_osnap) <pre>&lt;xarray.Dataset&gt; Size: 9MB\nDimensions:                (depth: 75, time_counter: 49, station: 66,\n                            sigma0_bins: 719)\nCoordinates:\n  * depth                  (depth) float32 300B 0.5058 1.556 ... 5.902e+03\n  * time_counter           (time_counter) datetime64[ns] 392B 1976-07-02 ... ...\n  * station                (station) int64 528B 0 1 2 3 4 5 ... 61 62 63 64 65\n    longitude              (station) float64 528B -56.8 -55.78 ... -9.802 -8.703\n    latitude               (station) float64 528B 52.19 52.26 ... 56.76 56.69\n  * sigma0_bins            (sigma0_bins) float64 6kB 28.19 28.18 ... 21.02 21.01\nData variables:\n    velocity               (time_counter, depth, station) float32 970kB nan ....\n    eddy_induced_velocity  (time_counter, depth, station) float32 970kB nan ....\n    dz                     (time_counter, depth, station) float32 970kB nan ....\n    dx                     (station) float64 528B 6.946e+04 ... 6.715e+04\n    volume_transport       (time_counter, depth, station) float64 2MB nan ......\n    temp                   (time_counter, depth, station) float32 970kB nan ....\n    sal                    (time_counter, depth, station) float32 970kB nan ....\n    sigma0                 (time_counter, depth, station) float64 2MB nan ......\n    moc_total              (time_counter, sigma0_bins) float64 282kB 0.0 ... 0.0\nAttributes:\n    units:               m/s\n    online_operation:    average\n    interval_operation:  1 yr\n    interval_write:      1 yr\n    cell_methods:        time: mean\n</pre> In\u00a0[9]: Copied! <pre># Determine station indexes for OSNAP East section:\nstation_OWest_OEast = ds_osnap.station.where(ds_osnap.longitude &lt;= -44).max()\n\n# OSNAP East diapycnal overturning stream function:\nmask_OEast = ds_osnap.station &gt;= station_OWest_OEast\nds_osnap['moc_east'] = compute_section_moc_tracer(ds=ds_osnap,\n                                                  tracer_name='sigma0',\n                                                  tracer_bins=sigma0_bins,\n                                                  dir='-1',\n                                                  mask=mask_OEast,\n                                                  )\n\n# OSNAP West diapycnal overturning stream function:\nmask_OWest = ds_osnap.station &lt; station_OWest_OEast\nds_osnap['moc_west'] = compute_section_moc_tracer(ds=ds_osnap,\n                                                  tracer_name='sigma0',\n                                                  tracer_bins=sigma0_bins,\n                                                  dir='-1',\n                                                  mask=mask_OWest,\n                                                  )\n\nprint(ds_osnap)\n</pre> # Determine station indexes for OSNAP East section: station_OWest_OEast = ds_osnap.station.where(ds_osnap.longitude &lt;= -44).max()  # OSNAP East diapycnal overturning stream function: mask_OEast = ds_osnap.station &gt;= station_OWest_OEast ds_osnap['moc_east'] = compute_section_moc_tracer(ds=ds_osnap,                                                   tracer_name='sigma0',                                                   tracer_bins=sigma0_bins,                                                   dir='-1',                                                   mask=mask_OEast,                                                   )  # OSNAP West diapycnal overturning stream function: mask_OWest = ds_osnap.station &lt; station_OWest_OEast ds_osnap['moc_west'] = compute_section_moc_tracer(ds=ds_osnap,                                                   tracer_name='sigma0',                                                   tracer_bins=sigma0_bins,                                                   dir='-1',                                                   mask=mask_OWest,                                                   )  print(ds_osnap) <pre>&lt;xarray.Dataset&gt; Size: 10MB\nDimensions:                (depth: 75, time_counter: 49, station: 66,\n                            sigma0_bins: 719)\nCoordinates:\n  * depth                  (depth) float32 300B 0.5058 1.556 ... 5.902e+03\n  * time_counter           (time_counter) datetime64[ns] 392B 1976-07-02 ... ...\n  * station                (station) int64 528B 0 1 2 3 4 5 ... 61 62 63 64 65\n    longitude              (station) float64 528B -56.8 -55.78 ... -9.802 -8.703\n    latitude               (station) float64 528B 52.19 52.26 ... 56.76 56.69\n  * sigma0_bins            (sigma0_bins) float64 6kB 28.19 28.18 ... 21.02 21.01\nData variables:\n    velocity               (time_counter, depth, station) float32 970kB nan ....\n    eddy_induced_velocity  (time_counter, depth, station) float32 970kB nan ....\n    dz                     (time_counter, depth, station) float32 970kB nan ....\n    dx                     (station) float64 528B 6.946e+04 ... 6.715e+04\n    volume_transport       (time_counter, depth, station) float64 2MB nan ......\n    temp                   (time_counter, depth, station) float32 970kB nan ....\n    sal                    (time_counter, depth, station) float32 970kB nan ....\n    sigma0                 (time_counter, depth, station) float64 2MB nan ......\n    moc_total              (time_counter, sigma0_bins) float64 282kB 0.0 ... 0.0\n    moc_east               (time_counter, sigma0_bins) float64 282kB 0.0 ... 0.0\n    moc_west               (time_counter, sigma0_bins) float64 282kB 0.0 ... 0.0\nAttributes:\n    units:               m/s\n    online_operation:    average\n    interval_operation:  1 yr\n    interval_write:      1 yr\n    cell_methods:        time: mean\n</pre> In\u00a0[10]: Copied! <pre># Plot time-mean diapycnal overturning stream function along the OSNAP section:\nds_osnap['moc_total'].mean(dim='time_counter').plot(label='Total', lw=2)\nds_osnap['moc_east'].mean(dim='time_counter').plot(label='OEast', lw=2)\nds_osnap['moc_west'].mean(dim='time_counter').plot(label='OWest', lw=2)\nplt.legend()\n</pre> # Plot time-mean diapycnal overturning stream function along the OSNAP section: ds_osnap['moc_total'].mean(dim='time_counter').plot(label='Total', lw=2) ds_osnap['moc_east'].mean(dim='time_counter').plot(label='OEast', lw=2) ds_osnap['moc_west'].mean(dim='time_counter').plot(label='OWest', lw=2) plt.legend() Out[10]: <pre>&lt;matplotlib.legend.Legend at 0x7f53ddc49400&gt;</pre> In\u00a0[11]: Copied! <pre># Shutdown Dask Local Cluster:\nclient.close()\nclient.shutdown()\n</pre> # Shutdown Dask Local Cluster: client.close() client.shutdown()"},{"location":"recipe_extract_osnap/#description","title":"Description\u00b6","text":"<p>Recipe showing how to extract the Overturning in the Subpolar North Atlantic (OSNAP) trans-basin hydrographic section using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using ERA-5 climatologically adjusted atmospheric forcing from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_extract_osnap/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_extract_osnap/#preparing-nemo-model-data","title":"Preparing NEMO Model Data\u00b6","text":"<p>Let's begin by defining the paths to our <code>domain_cfg.nc</code> file and our annual-mean velocity and tracer (conservative temperature &amp; absolute salinity) outputs.</p>"},{"location":"recipe_extract_osnap/#preparing-osnap-coordinates","title":"Preparing OSNAP Coordinates\u00b6","text":"<p>Next, we will prepare geographical (lat, lon) coordinates defining the Overturning in the Subpolar North Atlantic (OSNAP) array from the JASMIN Object Store.</p> <p>In this example, the eORCA1 grid is coarser than the OSNAP gridded observational product, so we upsample the (lon, lat) coordinates defining the array and then concatenate the final coordinates to ensure we do not exclude any model grid cells near the Scottish Shelf.</p>"},{"location":"recipe_extract_osnap/#extracting-the-osnap-array-as-a-continuous-hydrographic-section","title":"Extracting the OSNAP array as a continuous hydrographic section\u00b6","text":"<p>Now all our input variables are ready, let's extract the OSNAP array from our NEMO model output...</p> <p>The <code>extract_section()</code> function accepts the latitude and longitude coordinates defining the hydrographic section as ndarrays.</p> <p>In contrast to other functions in the nemo_cookbook, we pass the file paths to the domain, T, U &amp; V-grid NEMO model outputs rather than xarray Datasets. This is becase each dataset will be pre-processed behind the scenes to load only the data comprising the model-defined section.</p> <p>The <code>var_map</code> argument accepts a dictionary, mapping the expected variable names ['uo', 'uo_eiv', 'vo', 'vo_eiv', 'temp', 'sal', 'e1v', 'e2u', 'e3u', 'e3v'] to their corresponding names in the NEMO model output provided. In the example below, expected variables 'temp' and 'sal' are mapped to 'thetao_con' and 'so_abs', respectively.</p>"},{"location":"recipe_extract_osnap/#visualising-potential-density-along-the-osnap-array","title":"Visualising potential density along the OSNAP array\u00b6","text":"<p>Next, let's calculate the potential density (referenced to the sea surface) &amp; visualise our results by plotting the time-mean potential density along the OSNAP array:</p>"},{"location":"recipe_extract_osnap/#calculating-meridional-overturning-stream-functions-along-the-osnap-array","title":"Calculating Meridional Overturning Stream Functions along the OSNAP array\u00b6","text":"<p>Finally, let's calculate the meridional overturning stream function in potential density coordinates along the OSNAP array using the <code>.compute_section_moc_tracer()</code> function:</p>"},{"location":"recipe_masked_stats/","title":"Regional Masked Statistics","text":"In\u00a0[\u00a0]: Copied! <pre># -- Import required packages -- #\nimport numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import numpy as np import xarray as xr import matplotlib.pyplot as plt from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[\u00a0]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain/domain_cfg\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = xr.open_zarr(domain_filepath, consolidated=True, chunks={})\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain/domain_cfg\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = xr.open_zarr(domain_filepath, consolidated=True, chunks={})  ds_domain <p>Next, we will import the sea surface temperature and sea surface salinity stored at T-points in a single dataset.</p> <p>Typically, NEMO model outputs defined on T-grid points are stored together in netCDF files. In this case, you can replace <code>xr.merge()</code> with a single call to xarray's <code>open_dataset()</code> function passing the file path to your <code>_gridT.nc</code> file(s).</p> In\u00a0[\u00a0]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1m\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['tos_con', 'sos_abs']], compat=\"override\")\n\nds_gridT\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1m\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['tos_con', 'sos_abs']], compat=\"override\")  ds_gridT In\u00a0[\u00a0]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain.rename({\"z\": \"nav_lev\"}), \"gridT\": ds_gridT}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain.rename({\"z\": \"nav_lev\"}), \"gridT\": ds_gridT}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo In\u00a0[\u00a0]: Copied! <pre># Define bounding box (lon_min, lon_max, lat_min, lat_max)\nbbox = (-80, 10, 20, 70)\n\n# Clip eORCA1 model T-grid to bounding box:\nnemo.clip_grid(grid='/gridT', bbox=bbox)\n\n# Plotting time-mean sea surface temperature for the regional sub-domain:\nnemo['/gridT']['tos_con'].mean(dim='time_counter').plot()\n</pre> # Define bounding box (lon_min, lon_max, lat_min, lat_max) bbox = (-80, 10, 20, 70)  # Clip eORCA1 model T-grid to bounding box: nemo.clip_grid(grid='/gridT', bbox=bbox)  # Plotting time-mean sea surface temperature for the regional sub-domain: nemo['/gridT']['tos_con'].mean(dim='time_counter').plot() In\u00a0[\u00a0]: Copied! <pre>nemo\n</pre> nemo In\u00a0[\u00a0]: Copied! <pre># Open OSNAP gridded observations dataset: \nds_osnap = xr.open_zarr(\"https://noc-msm-o.s3-ext.jc.rl.ac.uk/ocean-obs/OSNAP/OSNAP_Gridded_TSV_201408_202006_2023\")\n\n# Define a closed polygon which includes both the OSNAP West &amp; East arrays:\nlon_poly = np.concatenate([ds_osnap['LONGITUDE'].values, np.array([ds_osnap['LONGITUDE'][-1], ds_osnap['LONGITUDE'][0]])])\nlat_poly = np.concatenate([ds_osnap['LATITUDE'].values, np.array([ds_osnap['LATITUDE'][0], ds_osnap['LATITUDE'][0]])])\n</pre> # Open OSNAP gridded observations dataset:  ds_osnap = xr.open_zarr(\"https://noc-msm-o.s3-ext.jc.rl.ac.uk/ocean-obs/OSNAP/OSNAP_Gridded_TSV_201408_202006_2023\")  # Define a closed polygon which includes both the OSNAP West &amp; East arrays: lon_poly = np.concatenate([ds_osnap['LONGITUDE'].values, np.array([ds_osnap['LONGITUDE'][-1], ds_osnap['LONGITUDE'][0]])]) lat_poly = np.concatenate([ds_osnap['LATITUDE'].values, np.array([ds_osnap['LATITUDE'][0], ds_osnap['LATITUDE'][0]])]) <p>Now we have defined our polygon, we can use the <code>mask_with_polygon()</code> method to return the boolean mask classifying whether NEMO model grid points are inside (True) or outside (False) the polygon</p> In\u00a0[\u00a0]: Copied! <pre># Masking T-grid using polygon coordinates:\nmask_spg = nemo.mask_with_polygon(grid='/gridT', lon_poly=lon_poly, lat_poly=lat_poly)\n\n# Plotting SPG polygon sub-domain:\nplt.figure()\nplt.pcolormesh(nemo['/gridT']['glamt'], nemo['/gridT']['gphit'], nemo['/gridT']['tos_con'].mean(dim='time_counter'), cmap='RdBu_r')\nplt.plot(lon_poly, lat_poly, color='0.1', lw=2)\nplt.colorbar(label='Sea Surface Temperature (\u00b0C)')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n# Plotting time-mean sea surface temperature for the SPG polygon sub-domain:\nplt.figure()\nplt.pcolormesh(nemo['/gridT']['glamt'], nemo['/gridT']['gphit'], nemo['/gridT']['tos_con'].mean(dim='time_counter').where(mask_spg), cmap='RdBu_r')\nplt.plot(lon_poly, lat_poly, color='0.1', lw=2)\nplt.colorbar(label='Sea Surface Temperature (\u00b0C)')\nplt.xlabel('Longitude')\nplt.xlim([-70, 5])\nplt.ylabel('Latitude')\nplt.ylim([40, 70])\nplt.show()\n</pre> # Masking T-grid using polygon coordinates: mask_spg = nemo.mask_with_polygon(grid='/gridT', lon_poly=lon_poly, lat_poly=lat_poly)  # Plotting SPG polygon sub-domain: plt.figure() plt.pcolormesh(nemo['/gridT']['glamt'], nemo['/gridT']['gphit'], nemo['/gridT']['tos_con'].mean(dim='time_counter'), cmap='RdBu_r') plt.plot(lon_poly, lat_poly, color='0.1', lw=2) plt.colorbar(label='Sea Surface Temperature (\u00b0C)') plt.xlabel('Longitude') plt.ylabel('Latitude') plt.show()  # Plotting time-mean sea surface temperature for the SPG polygon sub-domain: plt.figure() plt.pcolormesh(nemo['/gridT']['glamt'], nemo['/gridT']['gphit'], nemo['/gridT']['tos_con'].mean(dim='time_counter').where(mask_spg), cmap='RdBu_r') plt.plot(lon_poly, lat_poly, color='0.1', lw=2) plt.colorbar(label='Sea Surface Temperature (\u00b0C)') plt.xlabel('Longitude') plt.xlim([-70, 5]) plt.ylabel('Latitude') plt.ylim([40, 70]) plt.show() In\u00a0[\u00a0]: Copied! <pre># Calculating the area weighted-mean sea surface temperature in the SPG region:\nsst_wmean = nemo.masked_statistic(grid=\"/gridT\",\n                                  var=\"tos_con\",\n                                  lon_poly=lon_poly,\n                                  lat_poly=lat_poly,\n                                  statistic=\"weighted_mean\",\n                                  dims=[\"i\", \"j\"]\n                                  )\n\nsst_wmean.plot(lw=1, color='0.1', alpha=0.3)\nsst_wmean.rolling(time_counter=12, center=True).mean().plot(lw=3, color='0.1')\nplt.title('Area Weighted Mean SST for SPG Region', fontsize=12, fontweight='bold')\nplt.xlabel('Time', fontsize=12)\nplt.ylabel('Sea Surface Temperature (\u00b0C)', fontsize=12)\n</pre> # Calculating the area weighted-mean sea surface temperature in the SPG region: sst_wmean = nemo.masked_statistic(grid=\"/gridT\",                                   var=\"tos_con\",                                   lon_poly=lon_poly,                                   lat_poly=lat_poly,                                   statistic=\"weighted_mean\",                                   dims=[\"i\", \"j\"]                                   )  sst_wmean.plot(lw=1, color='0.1', alpha=0.3) sst_wmean.rolling(time_counter=12, center=True).mean().plot(lw=3, color='0.1') plt.title('Area Weighted Mean SST for SPG Region', fontsize=12, fontweight='bold') plt.xlabel('Time', fontsize=12) plt.ylabel('Sea Surface Temperature (\u00b0C)', fontsize=12)"},{"location":"recipe_masked_stats/#description","title":"Description\u00b6","text":"<p>This recipe shows how to calculate statistics for regional sub-domains using monthly-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_masked_stats/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_masked_stats/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 JRA-55 model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_masked_stats/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_masked_stats/#defining-a-regional-sub-domain-using-a-bounding-box","title":"Defining a Regional Sub-Domain using a Bounding Box\u00b6","text":"<p>Now we have constructed our <code>NEMODataTree</code>, let's start by defining a regional sub-domain using a geographical bounding box.</p> <p>By using the <code>clip_grid()</code> method, we permanently modify the size of the specfied grid stored in our NEMODataTree.</p> <p>Alternatively, we can use <code>clip_domain()</code> to clip all of the grids associated with a given NEMO model domain to a given bounding box.</p>"},{"location":"recipe_masked_stats/#defining-a-regional-sub-domain-using-a-polygon","title":"Defining a Regional Sub-Domain using a Polygon\u00b6","text":"<p>Next, let's define a more complex regional sub-domain by constructing a mask using a polygon. Since we have already clipped the T-grid of our NEMODataTree parent domain, we will define a polygon comprised of longitude-latitude coordinates within this region.</p> <p>We will use the Overturning in the Subpolar North Atlantic Program (OSNAP) observational array coordinates made available via the JASMIN Object Store to construct a polygon enclosing the North Atlantic subpolar gyre.</p>"},{"location":"recipe_masked_stats/#calculating-statistics-for-a-regional-sub-domain","title":"Calculating statistics for a Regional Sub-Domain\u00b6","text":"<p>Finally, let's use our North Atlantic subpolar gyre polygon to calculate statistics for this regional sub-domain of the eORCA1 model.</p> <p>Given a closed polygon, we can use the <code>masked_statistic()</code> method to calculate statistics of a specified variable in the masked sub-domain</p>"},{"location":"recipe_moc_tracer/","title":"Meridional Overturning - Tracer Space","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport gsw\nimport numpy as np\nimport xarray as xr\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import gsw import numpy as np import xarray as xr from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x16c1996a0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[6]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})\nds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={}) ds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})  ds_domain Out[6]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (t: 1, y: 331, x: 360, z: 75)\nDimensions without coordinates: t, y, x, z\nData variables: (12/54)\n    e1t            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2v            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    bottom_level   (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2t            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2u            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    bathy_metry    (t, y, x) float32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (z) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   (t) float64 8B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    top_level      (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we need to import the conservative temperature and absolute salinity stored at T-points in a single dataset.</p> <p>Typically, NEMO model outputs defined on T-grid points are stored together in netCDF files. In this case, you can replace <code>xr.merge()</code> with a single call to xarray's <code>open_dataset()</code> function passing the file path to your <code>_gridT.nc</code> file(s).</p> In\u00a0[3]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['thetao_con', 'so_abs']], compat=\"override\")\nds_gridT = ds_gridT.sel(time_counter=slice(\"1976-01\", \"2023-12\"))\n\n# Calculate potential density anomaly referenced to the sea surface (kg/m3):\nds_gridT['sigma0'] = gsw.density.sigma0(CT=ds_gridT['thetao_con'], SA=ds_gridT['so_abs'])\nds_gridT['sigma0'].name = 'sigma0'\n\nds_gridT\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['thetao_con', 'so_abs']], compat=\"override\") ds_gridT = ds_gridT.sel(time_counter=slice(\"1976-01\", \"2023-12\"))  # Calculate potential density anomaly referenced to the sea surface (kg/m3): ds_gridT['sigma0'] = gsw.density.sigma0(CT=ds_gridT['thetao_con'], SA=ds_gridT['so_abs']) ds_gridT['sigma0'].name = 'sigma0'  ds_gridT Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 7GB\nDimensions:        (deptht: 75, y: 331, x: 360, time_counter: 48)\nCoordinates:\n  * deptht         (deptht) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n  * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\nDimensions without coordinates: y, x\nData variables:\n    thetao_con     (time_counter, deptht, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    so_abs         (time_counter, deptht, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    sigma0         (time_counter, deptht, y, x) float64 3GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean\n    interval_operation:  1 yr\n    interval_write:      1 yr\n    long_name:           sea_water_conservative_temperature\n    online_operation:    average\n    standard_name:       sea_water_conservative_temperature\n    units:               degC</pre> <p>Next, we need to import the meridional velocity and vertical grid cell thicknesses stored at V-points in a single dataset.</p> <p>Typically, NEMO model outputs defined on V-grid points are stored together in netCDF files. In this case, you can replace <code>xr.merge()</code> with a single call to xarray's <code>open_dataset()</code> function passing the file path to your <code>_gridV.nc</code> file(s).</p> In\u00a0[4]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/V1y\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\")\nds_gridV = ds_gridV.sel(time_counter=slice(\"1976-01\", \"2023-12\"))\n\nds_gridV\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/V1y\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\") ds_gridV = ds_gridV.sel(time_counter=slice(\"1976-01\", \"2023-12\"))  ds_gridV Out[4]: <pre>&lt;xarray.Dataset&gt; Size: 3GB\nDimensions:        (depthv: 75, y: 331, x: 360, time_counter: 48)\nCoordinates:\n  * depthv         (depthv) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n  * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\nDimensions without coordinates: y, x\nData variables:\n    e3v            (time_counter, depthv, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    vo             (time_counter, depthv, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean (interval: 3600 s)\n    interval_operation:  3600 s\n    interval_write:      1 yr\n    long_name:           V-cell thickness\n    online_operation:    average\n    standard_name:       cell_thickness\n    units:               m</pre> In\u00a0[5]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain.rename({\"z\": \"nav_lev\"}), \"gridT\": ds_gridT, \"gridV\": ds_gridV}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain.rename({\"z\": \"nav_lev\"}), \"gridT\": ds_gridT, \"gridV\": ds_gridV}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[5]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 48)\n\u2502   Coordinates:\n\u2502       time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502     * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:        (time_counter: 48, k: 75, j: 331, i: 360)\n\u2502       Coordinates:\n\u2502         * deptht         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           thetao_con     (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           so_abs         (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           sigma0         (time_counter, k, j, i) float64 3GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           e1t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level      (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level   (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:        (time_counter: 48, k: 75, j: 331, i: 360)\n\u2502       Coordinates:\n\u2502         * depthv         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphiv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e3v            (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           vo             (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           e1v            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           cell_methods:        time: mean (interval: 3600 s)\n\u2502           interval_operation:  3600 s\n\u2502           interval_write:      1 yr\n\u2502           long_name:           V-cell thickness\n\u2502           online_operation:    average\n\u2502           standard_name:       cell_thickness\n\u2502           units:               m\n\u2502           nftype:              F\n\u2502           iperio:              True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> In\u00a0[7]: Copied! <pre># Define Atlantic Ocean basin mask:\natlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"}).astype(bool)\n\n# Add meridional volume transport [m3/s] to NEMO V-grid - meridional velocity [m/s] * area of meridional grid cell face [m2]:\nnemo['/gridV']['volume_transport'] = (nemo['/gridV']['vo'] * nemo.cell_area(grid='/gridV', dim='j'))\n\n# Transform potential density from NEMO T-grid to V-grid using linear interpolation:\nnemo['/gridV']['sigma0'] = nemo.transform_scalar_to(grid='/gridT', var='sigma0', to='V')\n</pre> # Define Atlantic Ocean basin mask: atlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"}).astype(bool)  # Add meridional volume transport [m3/s] to NEMO V-grid - meridional velocity [m/s] * area of meridional grid cell face [m2]: nemo['/gridV']['volume_transport'] = (nemo['/gridV']['vo'] * nemo.cell_area(grid='/gridV', dim='j'))  # Transform potential density from NEMO T-grid to V-grid using linear interpolation: nemo['/gridV']['sigma0'] = nemo.transform_scalar_to(grid='/gridT', var='sigma0', to='V') In\u00a0[8]: Copied! <pre># Define potential density bins [kg /m3]:\nsigma0_bins = np.arange(22, 29, 0.01)\n\n# Compute meridional volume transport in latitude-potential density coords\nvt_sigma0_atl = nemo.binned_statistic(grid=\"/gridV\",\n                                      vars=[\"sigma0\"],\n                                      values=\"volume_transport\",\n                                      keep_dims=[\"time_counter\", \"j\"],\n                                      bins=[sigma0_bins],\n                                      statistic=\"nansum\",\n                                      mask=atlmask\n                                      )\n\nvt_sigma0_atl\n</pre> # Define potential density bins [kg /m3]: sigma0_bins = np.arange(22, 29, 0.01)  # Compute meridional volume transport in latitude-potential density coords vt_sigma0_atl = nemo.binned_statistic(grid=\"/gridV\",                                       vars=[\"sigma0\"],                                       values=\"volume_transport\",                                       keep_dims=[\"time_counter\", \"j\"],                                       bins=[sigma0_bins],                                       statistic=\"nansum\",                                       mask=atlmask                                       )  vt_sigma0_atl Out[8]: <pre>&lt;xarray.DataArray 'volume_transport' (time_counter: 48, j: 331, sigma0_bins: 699)&gt; Size: 89MB\ndask.array&lt;reshape, shape=(48, 331, 699), dtype=float64, chunksize=(48, 331, 699), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time_counter  (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-0...\n  * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n  * sigma0_bins   (sigma0_bins) float64 6kB 22.01 22.02 22.03 ... 28.98 28.99</pre> <p>Notice that the resulting DataArray includes a dask array, so we haven't actually computed the diapycnal overturning yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[9]: Copied! <pre># Compute diapycnal overturning stream function in Sverdrups [1 Sv = 1E6 m3/s]:\n# Here, we accumulate diapycnal volume transports from the lightest to the densest\n# isopycnal surface.\nmoc_sigma0_atl = 1E-6 * vt_sigma0_atl.cumsum(dim='sigma0_bins').compute()\nmoc_sigma0_atl.name = 'moc_sigma0_atl'\n\nmoc_sigma0_atl\n</pre> # Compute diapycnal overturning stream function in Sverdrups [1 Sv = 1E6 m3/s]: # Here, we accumulate diapycnal volume transports from the lightest to the densest # isopycnal surface. moc_sigma0_atl = 1E-6 * vt_sigma0_atl.cumsum(dim='sigma0_bins').compute() moc_sigma0_atl.name = 'moc_sigma0_atl'  moc_sigma0_atl <pre>OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n</pre> Out[9]: <pre>&lt;xarray.DataArray 'moc_sigma0_atl' (time_counter: 48, j: 331, sigma0_bins: 699)&gt; Size: 89MB\narray([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        ...,\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.30921961e-01, -9.30921961e-01, -9.30921961e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.45353998e-01, -9.45353998e-01, -9.45353998e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n\n       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n...\n         -9.51691358e-01, -9.51691358e-01, -9.51691358e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.57064748e-01, -9.57064748e-01, -9.57064748e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n\n       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        ...,\n        [-1.24457492e-03, -1.24457492e-03, -1.24457492e-03, ...,\n         -9.02882356e-01, -9.02882356e-01, -9.02882356e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.11390452e-01, -9.11390452e-01, -9.11390452e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n      shape=(48, 331, 699))\nCoordinates:\n  * time_counter  (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-0...\n  * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n  * sigma0_bins   (sigma0_bins) float64 6kB 22.01 22.02 22.03 ... 28.98 28.99</pre> In\u00a0[10]: Copied! <pre>moc_sigma0_atl.mean(dim='time_counter').plot(y='sigma0_bins', yincrease=False)\n</pre> moc_sigma0_atl.mean(dim='time_counter').plot(y='sigma0_bins', yincrease=False) Out[10]: <pre>&lt;matplotlib.collections.QuadMesh at 0x16d016ba0&gt;</pre>"},{"location":"recipe_moc_tracer/#description","title":"Description\u00b6","text":"<p>This recipe shows how to calculate the Atlantic Meridional Overturning Circulation (AMOC) stream function in potential density-coordinates using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_moc_tracer/#background","title":"Background\u00b6","text":"<p>The diapycnal overturning stream function is routinely used to characterise the strength and structure of the AMOC in density-space (e.g., $\\sigma_{0}$ or $\\sigma{2}$) as a function of latitude $\\phi$ and can be defined at time $t$ as follows:</p> <p>$$\\Psi_{\\sigma_{0}}(\\phi, \\sigma_{0}, t) = \\int_{x_w}^{x_e} \\int_{z(\\lambda, \\phi, \\sigma_{0})}^{\\eta} v(\\lambda, \\phi, z', t) \\ dz' \\ dx$$</p> <p>where the meridional velocity $v(\\lambda, \\phi, z, t)$ is first accumulated vertically from the sea surface $\\eta$ to a specified isopycnal depth $z(\\lambda, \\phi, \\sigma_{0})$ (decreasing downward) before being integrated zonally between the western $x_w$ and eastern $x_e$ boundaries of the basin.</p>"},{"location":"recipe_moc_tracer/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_moc_tracer/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 NEMO model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_moc_tracer/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and T- &amp; V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_moc_tracer/#calculating-the-amoc-diapycnal-overturning-stream-function","title":"Calculating the AMOC diapycnal overturning stream function\u00b6","text":"<p>Now we have constructed our <code>NEMODataTree</code>, let's calculate the diapycnal overturning stream function.</p>"},{"location":"recipe_moc_tracer/#visualising-the-time-mean-amoc-diapycnal-overturning-stream-function","title":"Visualising the time-mean AMOC diapycnal overturning stream function\u00b6","text":"<p>Finally, let's visualise the results by plotting the time-mean Atlantic Meridional Overturning stream function in potential density-coordinates:</p>"},{"location":"recipe_moc_z/","title":"Meridional Overturning - Depth Space","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport xarray as xr\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import xarray as xr from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x177f49010&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[4]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})\nds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={}) ds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})  ds_domain Out[4]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (t: 1, y: 331, x: 360, z: 75)\nDimensions without coordinates: t, y, x, z\nData variables: (12/54)\n    e1t            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2v            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    bottom_level   (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2t            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2u            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    bathy_metry    (t, y, x) float32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (z) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   (t) float64 8B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    top_level      (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we need to import the meridional velocity and vertical grid cell thicknesses stored at V-points in a single dataset.</p> <p>Typically, NEMO model outputs defined on V-grid points are stored together in netCDF files. In this case, you can replace <code>xr.merge()</code> with a single call to xarray's <code>open_dataset()</code> function passing the file path to your <code>_gridV.nc</code> file(s).</p> In\u00a0[5]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/V1y\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\")\n\nds_gridV\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/V1y\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\")  ds_gridV Out[5]: <pre>&lt;xarray.Dataset&gt; Size: 4GB\nDimensions:        (depthv: 75, y: 331, x: 360, time_counter: 49)\nCoordinates:\n  * depthv         (depthv) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n  * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\nDimensions without coordinates: y, x\nData variables:\n    e3v            (time_counter, depthv, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    vo             (time_counter, depthv, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean (interval: 3600 s)\n    interval_operation:  3600 s\n    interval_write:      1 yr\n    long_name:           V-cell thickness\n    online_operation:    average\n    standard_name:       cell_thickness\n    units:               m</pre> In\u00a0[6]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain.rename({\"z\": \"nav_lev\"}), \"gridV\": ds_gridV}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain.rename({\"z\": \"nav_lev\"}), \"gridV\": ds_gridV}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[6]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 49)\n\u2502   Coordinates:\n\u2502       time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502     * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level     (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level  (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:        (time_counter: 49, k: 75, j: 331, i: 360)\n\u2502       Coordinates:\n\u2502         * depthv         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphiv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e3v            (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           vo             (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           e1v            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           cell_methods:        time: mean (interval: 3600 s)\n\u2502           interval_operation:  3600 s\n\u2502           interval_write:      1 yr\n\u2502           long_name:           V-cell thickness\n\u2502           online_operation:    average\n\u2502           standard_name:       cell_thickness\n\u2502           units:               m\n\u2502           nftype:              F\n\u2502           iperio:              True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> In\u00a0[7]: Copied! <pre>atlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"})\n\nmoc_z_atl = nemo.integral(grid=\"/gridV\",\n                          var=\"vo\",\n                          dims=[\"i\", \"k\"], \n                          cum_dims=[\"k\"],\n                          dir=\"+1\",\n                          mask=atlmask\n                          )\n\nmoc_z_atl\n</pre> atlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"})  moc_z_atl = nemo.integral(grid=\"/gridV\",                           var=\"vo\",                           dims=[\"i\", \"k\"],                            cum_dims=[\"k\"],                           dir=\"+1\",                           mask=atlmask                           )  moc_z_atl Out[7]: <pre>&lt;xarray.DataArray 'vo' (time_counter: 49, k: 75, j: 331)&gt; Size: 10MB\ndask.array&lt;nancumsum, shape=(49, 75, 331), dtype=float64, chunksize=(1, 25, 331), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n  * depthv         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n    time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n  * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n  * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5</pre> <p>Notice that the resulting DataArray includes a dask array, so we haven't actually computed the vertical overturning yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[8]: Copied! <pre># Compute vertical overturning stream function in Sverdrups [1 Sv = 1E6 m3/s]:\nmoc_z_atl = 1E-6 * moc_z_atl.compute()\n\nmoc_z_atl\n</pre> # Compute vertical overturning stream function in Sverdrups [1 Sv = 1E6 m3/s]: moc_z_atl = 1E-6 * moc_z_atl.compute()  moc_z_atl Out[8]: <pre>&lt;xarray.DataArray 'vo' (time_counter: 49, k: 75, j: 331)&gt; Size: 10MB\narray([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -5.93256017e-03, -5.98465019e-03, -4.70669708e-03],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -1.23823036e-02, -1.24593425e-02, -9.82934168e-03],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -1.93505099e-02, -1.93588036e-02, -1.51586968e-02],\n        ...,\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.30921961e-01, -9.31773471e-01, -9.32592128e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.30921961e-01, -9.31773471e-01, -9.32592128e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.30921961e-01, -9.31773471e-01, -9.32592128e-01]],\n\n       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.31946621e-03, -9.62942149e-03, -1.12506309e-02],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -1.87225095e-02, -1.92967880e-02, -2.25915142e-02],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -2.81349402e-02, -2.89098083e-02, -3.37560596e-02],\n...\n         -8.73345777e-01, -8.73976184e-01, -8.73915069e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -8.73345777e-01, -8.73976184e-01, -8.73915069e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -8.73345777e-01, -8.73976184e-01, -8.73915069e-01]],\n\n       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        ...,\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n      shape=(49, 75, 331))\nCoordinates:\n  * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n  * depthv         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n    time_centered  (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n  * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n  * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5</pre> In\u00a0[10]: Copied! <pre>moc_z_atl.mean(dim='time_counter').plot(y='depthv', yincrease=False)\n</pre> moc_z_atl.mean(dim='time_counter').plot(y='depthv', yincrease=False) Out[10]: <pre>&lt;matplotlib.collections.QuadMesh at 0x32cf60cd0&gt;</pre>"},{"location":"recipe_moc_z/#description","title":"Description\u00b6","text":"<p>This recipe shows how to calculate the Atlantic Meridional Overturning Circulation (AMOC) stream function in depth-coordinates using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_moc_z/#background","title":"Background\u00b6","text":"<p>The vertical overturning stream function is routinely used to characterise the strength and structure of the AMOC in depth-space as a function of latitude $\\phi$ and can be defined at time $t$ as follows:</p> <p>$$\\Psi_{z}(\\phi, z, t) = \\int_{z}^{\\eta} \\int_{x_w}^{x_e} v(\\lambda, \\phi, z, t) \\ dx \\ dz$$</p> <p>where the meridional velocity $v(\\lambda, \\phi, z, t)$ is first integrated zonally between the western $x_w$ and eastern $x_e$ boundaries of the basin before being accumulated vertically from the sea surface $\\eta$ to a specified depth $z(\\lambda, \\phi)$ (decreasing downward).</p>"},{"location":"recipe_moc_z/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_moc_z/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 JRA-55 model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_moc_z/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_moc_z/#calculating-the-amoc-vertical-overturning-stream-function","title":"Calculating the AMOC vertical overturning stream function\u00b6","text":"<p>Now we have constructed our <code>NEMODataTree</code>, let's calculate the vertical overturning stream function.</p> <p>In this example, our eORCA1 model uses $z^{*}$ vertical coordinates, so using <code>integral()</code>, which supports integration along the $i$, $j$, $k$ dimensions of the NEMO model grid, is appropriate. However, this would not be the case if using a NEMO model with geopotential / terrain-following coordinates.**</p>"},{"location":"recipe_moc_z/#visualising-the-time-mean-amoc-vertical-overturning-stream-function","title":"Visualising the time-mean AMOC vertical overturning stream function\u00b6","text":"<p>Finally, let's visualise the results by plotting the time-mean Atlantic Meridional Overturning stream function in depth-coordinates:</p>"},{"location":"recipe_sfwmt_sigma0/","title":"Surface-Forced Water Mass Transformation","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport gsw\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nimport matplotlib.pyplot as plt\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import gsw import numpy as np import pandas as pd import xarray as xr import matplotlib.pyplot as plt from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x1764b3cb0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[2]: Copied! <pre># Open IHO World Seas polygons from GitHub as Pandas DataFrame:\nIHO_World_Seas_filepath = \"https://raw.githubusercontent.com/NOC-MSM/nemo_cookbook/main/docs/docs/assets/data/World_Seas_IHO_v3_polygons.parquet\"\n\ndf_IHO_World_Seas = pd.read_parquet(IHO_World_Seas_filepath)\ndf_IHO_World_Seas\n</pre> # Open IHO World Seas polygons from GitHub as Pandas DataFrame: IHO_World_Seas_filepath = \"https://raw.githubusercontent.com/NOC-MSM/nemo_cookbook/main/docs/docs/assets/data/World_Seas_IHO_v3_polygons.parquet\"  df_IHO_World_Seas = pd.read_parquet(IHO_World_Seas_filepath) df_IHO_World_Seas Out[2]: ID Name MRGID Longitudes Latitudes 0 0 Rio de La Plata 4325 [[-54.943023652717045, -54.978746687192626, -5... [[-34.947906883078645, -34.97439280639835, -35... 1 1 Bass Strait 4366 [[149.90464234356938, 149.9049998519617, 149.9... [[-37.54324781853184, -37.54805552943908, -37.... 2 2 Great Australian Bight 4276 [[143.53250818354263, 143.54855731580784, 143.... [[-38.855345058560204, -38.89580867390668, -38... 3 3 Tasman Sea 4365 [[159.03333000000018, 159.03983414634163, 159.... [[-29.999999999999986, -30.043495934959335, -3... 4 4 Mozambique Channel 4261 [[43.38217926066437, 43.426910578414024, 43.47... [[-11.370205640977488, -11.374667237992885, -1... ... ... ... ... ... ... 96 96 Laccadive Sea 4269 [[79.19056582495296, 79.20560240772511, 79.205... [[9.28162992038466, 9.280296445224849, 9.28018... 97 97 Skagerrak 2379 [[10.66160702664314, 10.662945270907699, 10.66... [[59.91287636715083, 59.910394549469004, 59.90... 98 98 Norwegian Sea 2353 [[16.72106314339885, 16.78890655530549, 16.856... [[76.5645473926769, 76.50603497544391, 76.4475... 99 99 Ligurian Sea 3363 [[9.834412487214706, 9.835301503777828, 9.8349... [[44.0485148685363, 44.04729517147973, 44.0472... 100 100 Gulf of Guinea 4286 [[8.975150969002156, 8.974166710829394, 8.9742... [[-0.935921075698605, -0.9360325715092586, -0.... <p>101 rows \u00d7 5 columns</p> In\u00a0[3]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain/domain_cfg\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = xr.open_zarr(domain_filepath, consolidated=True, chunks={})\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain/domain_cfg\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = xr.open_zarr(domain_filepath, consolidated=True, chunks={})  ds_domain Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (t: 1, y: 331, x: 360, z: 75)\nDimensions without coordinates: t, y, x, z\nData variables: (12/54)\n    e1t            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2v            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    bottom_level   (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2t            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2u            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    bathy_metry    (t, y, x) float32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (z) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   (t) float64 8B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    top_level      (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we need to import the sea surface temperature and salinity and net surface heat and freshwater fluxes stored at T-points in a single dataset.</p> In\u00a0[4]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['tos_con', 'sos_abs', 'hfds', 'sowaflup']], compat=\"override\")\n\nds_gridT\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['tos_con', 'sos_abs', 'hfds', 'sowaflup']], compat=\"override\")  ds_gridT Out[4]: <pre>&lt;xarray.Dataset&gt; Size: 93MB\nDimensions:        (y: 331, x: 360, time_counter: 48)\nCoordinates:\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n  * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\nDimensions without coordinates: y, x\nData variables:\n    tos_con        (time_counter, y, x) float32 23MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    sos_abs        (time_counter, y, x) float32 23MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    hfds           (time_counter, y, x) float32 23MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    sowaflup       (time_counter, y, x) float32 23MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean (interval: 3600 s)\n    interval_operation:  3600 s\n    interval_write:      1 yr\n    long_name:           sea_surface_conservative_temperature\n    online_operation:    average\n    standard_name:       sea_surface_temperature\n    units:               degC</pre> In\u00a0[5]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/I1y\"\n\n# Construct NEMO model grid dataset, including sea ice concentration:\nds_icemod = xr.open_zarr(f\"{output_dir}/siconc\", consolidated=True, chunks={})[\"siconc\"].to_dataset()\n\nds_icemod\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/I1y\"  # Construct NEMO model grid dataset, including sea ice concentration: ds_icemod = xr.open_zarr(f\"{output_dir}/siconc\", consolidated=True, chunks={})[\"siconc\"].to_dataset()  ds_icemod Out[5]: <pre>&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:        (y: 331, x: 360, time_counter: 48)\nCoordinates:\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n  * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\nDimensions without coordinates: y, x\nData variables:\n    siconc         (time_counter, y, x) float32 23MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;</pre> <p>Next, let's calculate the surface potential density anomaly referenced to the sea surface alongside the thermal expansion and haline contraction coefficients of seawater.</p> In\u00a0[6]: Copied! <pre># Calculate potential density anomaly referenced to the sea surface (kg/m3):\nds_gridT['sigma0'] = gsw.density.sigma0(CT=ds_gridT['tos_con'], SA=ds_gridT['sos_abs'])\nds_gridT['sigma0'].name = 'sigma0'\n\n# Calculate thermal expansion coefficient at sea surface:\nds_gridT['alpha'] = gsw.density.alpha(SA=ds_gridT['sos_abs'], CT=ds_gridT['tos_con'], p=0)\nds_gridT['alpha'].name = 'alpha'\n\n# Calculate haline contraction coefficient at sea surface:\nds_gridT['beta'] = gsw.density.beta(SA=ds_gridT['sos_abs'], CT=ds_gridT['tos_con'], p=0)\nds_gridT['beta'].name = 'beta'\n</pre> # Calculate potential density anomaly referenced to the sea surface (kg/m3): ds_gridT['sigma0'] = gsw.density.sigma0(CT=ds_gridT['tos_con'], SA=ds_gridT['sos_abs']) ds_gridT['sigma0'].name = 'sigma0'  # Calculate thermal expansion coefficient at sea surface: ds_gridT['alpha'] = gsw.density.alpha(SA=ds_gridT['sos_abs'], CT=ds_gridT['tos_con'], p=0) ds_gridT['alpha'].name = 'alpha'  # Calculate haline contraction coefficient at sea surface: ds_gridT['beta'] = gsw.density.beta(SA=ds_gridT['sos_abs'], CT=ds_gridT['tos_con'], p=0) ds_gridT['beta'].name = 'beta' In\u00a0[7]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain.rename({\"z\": \"nav_lev\"}), \"gridT\": ds_gridT, \"icemod\": ds_icemod}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain.rename({\"z\": \"nav_lev\"}), \"gridT\": ds_gridT, \"icemod\": ds_icemod}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[7]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 48)\n\u2502   Coordinates:\n\u2502       time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502     * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:        (time_counter: 48, j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables: (12/13)\n\u2502           siconc         (time_counter, j, i) float32 23MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           tos_con        (time_counter, j, i) float32 23MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           sos_abs        (time_counter, j, i) float32 23MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           hfds           (time_counter, j, i) float32 23MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           sowaflup       (time_counter, j, i) float32 23MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           sigma0         (time_counter, j, i) float64 46MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           ...             ...\n\u2502           beta           (time_counter, j, i) float64 46MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           e1t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level      (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level   (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphiv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e1v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> <p>Now, we will use the IHO World Seas polygons to extract the Labrador Sea from the eORCA1 model domain.</p> In\u00a0[8]: Copied! <pre># Define IHO World Seas Labrador Sea polygon:\nlon_poly = df_IHO_World_Seas[df_IHO_World_Seas['Name'] == 'Labrador Sea']['Longitudes'].item()[0]\nlat_poly = df_IHO_World_Seas[df_IHO_World_Seas['Name'] == 'Labrador Sea']['Latitudes'].item()[0]\n\n# Define boolean mask for Labrador Sea:\nmask = nemo.mask_with_polygon(grid='/gridT', lon_poly=lon_poly, lat_poly=lat_poly)\n</pre> # Define IHO World Seas Labrador Sea polygon: lon_poly = df_IHO_World_Seas[df_IHO_World_Seas['Name'] == 'Labrador Sea']['Longitudes'].item()[0] lat_poly = df_IHO_World_Seas[df_IHO_World_Seas['Name'] == 'Labrador Sea']['Latitudes'].item()[0]  # Define boolean mask for Labrador Sea: mask = nemo.mask_with_polygon(grid='/gridT', lon_poly=lon_poly, lat_poly=lat_poly) In\u00a0[9]: Copied! <pre># Plotting Labrador Sea sub-domain:\nplt.figure()\nplt.pcolormesh(nemo['/gridT']['glamt'], nemo['/gridT']['gphit'], nemo['/gridT']['tos_con'].where(mask).mean(dim='time_counter'), cmap='RdBu_r')\nplt.plot(lon_poly, lat_poly, color='0.1', lw=2)\nplt.colorbar(label='Sea Surface Temperature (\u00b0C)')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.xlim([-80, 0])\nplt.ylim([45, 65])\n</pre> # Plotting Labrador Sea sub-domain: plt.figure() plt.pcolormesh(nemo['/gridT']['glamt'], nemo['/gridT']['gphit'], nemo['/gridT']['tos_con'].where(mask).mean(dim='time_counter'), cmap='RdBu_r') plt.plot(lon_poly, lat_poly, color='0.1', lw=2) plt.colorbar(label='Sea Surface Temperature (\u00b0C)') plt.xlabel('Longitude') plt.ylabel('Latitude') plt.xlim([-80, 0]) plt.ylim([45, 65])  <pre>/var/folders/z2/j_dr250s42x34hk63_rp4bm80000gq/T/ipykernel_26648/2396791886.py:3: UserWarning: The input coordinates to pcolormesh are interpreted as cell centers, but are not monotonically increasing or decreasing. This may lead to incorrectly calculated cell edges, in which case, please supply explicit cell edges to pcolormesh.\n  plt.pcolormesh(nemo['/gridT']['glamt'], nemo['/gridT']['gphit'], nemo['/gridT']['tos_con'].where(mask).mean(dim='time_counter'), cmap='RdBu_r')\n</pre> Out[9]: <pre>(45.0, 65.0)</pre> In\u00a0[10]: Copied! <pre># Define specific heat capacity of sea water [J kg-1 K-1]:\ncp0 = 3991.86795711963\n\n# Add sea surface density fluxes due to heat and freshwater fluxes to T-grid of NEMODataTree:\nnemo['/gridT']['f_hf'] = -(nemo['/gridT']['alpha'] / cp0) * nemo['/gridT']['hfds']\nnemo['/gridT']['f_fw'] = nemo['/gridT']['beta'] * (nemo['/gridT']['sos_abs'] / (1 - nemo['/gridT']['sos_abs'])) * nemo['/gridT']['sowaflup']\n</pre> # Define specific heat capacity of sea water [J kg-1 K-1]: cp0 = 3991.86795711963  # Add sea surface density fluxes due to heat and freshwater fluxes to T-grid of NEMODataTree: nemo['/gridT']['f_hf'] = -(nemo['/gridT']['alpha'] / cp0) * nemo['/gridT']['hfds'] nemo['/gridT']['f_fw'] = nemo['/gridT']['beta'] * (nemo['/gridT']['sos_abs'] / (1 - nemo['/gridT']['sos_abs'])) * nemo['/gridT']['sowaflup'] In\u00a0[11]: Copied! <pre># Define potential density bins [kg m-3]:\nsigma0_bins = np.arange(22, 29.05, 0.05)\ndsigma0 = 0.05\n\n# Compute surface forced water mass transformation across each surface T-grid cell [m3 s-1].\nnemo['gridT']['sfwmt'] = (1 / dsigma0) * (nemo['/gridT']['f_hf'] + nemo['/gridT']['f_fw']) * nemo.cell_area(grid='/gridT', dim='k')\n\n# Compute total surface-force water mass transformation in discrete potential density coords:\nsfwmt_sigma0_atl = nemo.binned_statistic(grid=\"/gridT\",\n                                         vars=[\"sigma0\"],\n                                         values=\"sfwmt\",\n                                         keep_dims=[\"time_counter\"],\n                                         bins=[sigma0_bins],\n                                         statistic=\"nansum\",\n                                         mask=mask\n                                         )\n\nsfwmt_sigma0_atl\n</pre> # Define potential density bins [kg m-3]: sigma0_bins = np.arange(22, 29.05, 0.05) dsigma0 = 0.05  # Compute surface forced water mass transformation across each surface T-grid cell [m3 s-1]. nemo['gridT']['sfwmt'] = (1 / dsigma0) * (nemo['/gridT']['f_hf'] + nemo['/gridT']['f_fw']) * nemo.cell_area(grid='/gridT', dim='k')  # Compute total surface-force water mass transformation in discrete potential density coords: sfwmt_sigma0_atl = nemo.binned_statistic(grid=\"/gridT\",                                          vars=[\"sigma0\"],                                          values=\"sfwmt\",                                          keep_dims=[\"time_counter\"],                                          bins=[sigma0_bins],                                          statistic=\"nansum\",                                          mask=mask                                          )  sfwmt_sigma0_atl Out[11]: <pre>&lt;xarray.DataArray 'sfwmt' (time_counter: 48, sigma0_bins: 140)&gt; Size: 54kB\ndask.array&lt;reshape, shape=(48, 140), dtype=float64, chunksize=(48, 140), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time_counter  (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-0...\n  * sigma0_bins   (sigma0_bins) float64 1kB 22.02 22.08 22.12 ... 28.93 28.98</pre> <p>Notice that the resulting DataArray includes a dask array, so we haven't actually computed the surface-forced water mass transformation yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[12]: Copied! <pre># Compute diapycnal surface-forced water mass transformation in Sverdrups [1 Sv = 1E6 m3/s]:\nsfwmt_sigma0_atl = (sfwmt_sigma0_atl / 1E6).compute()\nsfwmt_sigma0_atl.name = 'sfwmt_sigma0_atl'\n\nsfwmt_sigma0_atl\n</pre> # Compute diapycnal surface-forced water mass transformation in Sverdrups [1 Sv = 1E6 m3/s]: sfwmt_sigma0_atl = (sfwmt_sigma0_atl / 1E6).compute() sfwmt_sigma0_atl.name = 'sfwmt_sigma0_atl'  sfwmt_sigma0_atl <pre>OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n</pre> Out[12]: <pre>&lt;xarray.DataArray 'sfwmt_sigma0_atl' (time_counter: 48, sigma0_bins: 140)&gt; Size: 54kB\narray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], shape=(48, 140))\nCoordinates:\n  * time_counter  (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-0...\n  * sigma0_bins   (sigma0_bins) float64 1kB 22.02 22.08 22.12 ... 28.93 28.98</pre> In\u00a0[13]: Copied! <pre>sfwmt_sigma0_atl.plot(y='sigma0_bins', yincrease=False)\n</pre> sfwmt_sigma0_atl.plot(y='sigma0_bins', yincrease=False) Out[13]: <pre>&lt;matplotlib.collections.QuadMesh at 0x327284a50&gt;</pre>"},{"location":"recipe_sfwmt_sigma0/#description","title":"Description\u00b6","text":"<p>This recipe shows how to calculate the surface-forced water mass transformation in potential density-coordinates using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_sfwmt_sigma0/#background","title":"Background\u00b6","text":"<p>The surface-forced diapycnal water mass transformation is used to quantify the volume flux across isopycnal outcrops due to surface buoyancy fluxes and can be defined at time $t$ as follows:</p> <p>First, we computing the surface density flux due to the fluxes of heat $Q_H$ (W m-2) and freshwater $Q_{FW}$ (kg m-2 s-1) at the sea surface following Speer and Tziperman (1992):</p> <p>$$f(\\lambda, \\phi, t) = -\\frac{\\alpha}{c_{p}} Q_{H}(\\lambda, \\phi, t) + \\beta \\frac{S(\\lambda, \\phi, t)}{1 - S(\\lambda, \\phi, t)} Q_{FW}(\\lambda, \\phi, t)$$</p> <p>where $\\alpha$ is the thermal expansion coefficient, $\\beta$ is the haline contraction coefficient, $c_p$ is the specific heat capacity of seawater and $S$ is the sea surface salinity. Notably, a positive surface density flux (i.e., $f(\\lambda, \\phi, t)$ &gt; 0 kg m\u22122 s\u22121) represents an increase in sea surface density.</p> <p>We then calculate the surface-forced diapycnal water mass transformation $H(\\sigma^{*}, t)$ across an outcropping isopycnal surface by integrating the surface density flux over the area of each surface density outcrop $\\sigma^{*}$:</p> <p>$$H(\\sigma^{*}, t) = \\frac{1}{\\Delta \\sigma} \\int \\int f(\\lambda, \\phi, t) \\ \\Pi(\\sigma^{*}(\\lambda, \\phi, t)) \\ \\ dx \\ dy$$</p> <p>where the $\\Pi(\\sigma^{*}(\\lambda, \\phi, t))$ operator is 1 when $|\\sigma^{*}(\\lambda, \\phi, t) - \\sigma| \\leq \\frac{\\Delta \\sigma}{2}$ and 0 elsewhere.</p>"},{"location":"recipe_sfwmt_sigma0/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_sfwmt_sigma0/#accessing-iho-world-seas-polygons","title":"Accessing IHO World Seas polygons\u00b6","text":"<p>Let's begin by loading the polygons defining the IHO World Seas regions.</p>"},{"location":"recipe_sfwmt_sigma0/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 NEMO model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_sfwmt_sigma0/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Using our outputs, let's create a NEMODataTree to store our domain and T- &amp; V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_sfwmt_sigma0/#calculating-surface-forced-water-mass-transformation","title":"Calculating surface-forced water mass transformation\u00b6","text":"<p>Now we have constructed our <code>NEMODataTree</code>, let's calculate the diapycnal surface-forced water mass trasformation from the surface density flux due to surface heat and freshwater fluxes.</p>"},{"location":"recipe_sfwmt_sigma0/#visualising-the-time-mean-surface-forced-diapycnal-overturning-stream-function","title":"Visualising the time-mean surface-forced diapycnal overturning stream function\u00b6","text":"<p>Finally, let's visualise the results by plotting the time-mean surface-forced overturning stream function in potential density-coordinates for the Atlantic Ocean:</p>"},{"location":"recipe_transform_vertical_coords/","title":"Vertical Coordinate Transformation","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport numpy as np\nimport xarray as xr\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import numpy as np import xarray as xr from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x300a91010&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[2]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain/domain_cfg\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = xr.open_zarr(domain_filepath, consolidated=True, chunks={})\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain/domain_cfg\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = xr.open_zarr(domain_filepath, consolidated=True, chunks={})  ds_domain Out[2]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (t: 1, y: 331, x: 360, z: 75)\nDimensions without coordinates: t, y, x, z\nData variables: (12/54)\n    e1t            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2v            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    bottom_level   (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2t            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2u            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    bathy_metry    (t, y, x) float32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (z) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   (t) float64 8B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    top_level      (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we need to import the sea water conservative temperature and absolute salinity stored at T-points in a single dataset.</p> In\u00a0[3]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"\n\n# Construct NEMO model grid dataset, including seawater conservative temperature (C) and absolute salinity (g/kg):\nds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={'deptht': 75})[var] for var in ['thetao_con', 'e3t']], compat=\"override\")\n\n# Subsetting the time_counter dimension: \nds_gridT = ds_gridT.sel(time_counter=slice('2000-01', '2010-12'))\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"  # Construct NEMO model grid dataset, including seawater conservative temperature (C) and absolute salinity (g/kg): ds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={'deptht': 75})[var] for var in ['thetao_con', 'e3t']], compat=\"override\")  # Subsetting the time_counter dimension:  ds_gridT = ds_gridT.sel(time_counter=slice('2000-01', '2010-12')) In\u00a0[4]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain.rename({\"z\": \"nav_lev\"}), \"gridT\": ds_gridT}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain.rename({\"z\": \"nav_lev\"}), \"gridT\": ds_gridT}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[4]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 11)\n\u2502   Coordinates:\n\u2502       time_centered  (time_counter) datetime64[ns] 88B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502     * time_counter   (time_counter) datetime64[ns] 88B 2000-07-02 ... 2010-07-0...\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:        (time_counter: 11, k: 75, j: 331, i: 360)\n\u2502       Coordinates:\n\u2502         * deptht         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 88B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           thetao_con     (time_counter, k, j, i) float32 393MB dask.array&lt;chunksize=(1, 75, 331, 360), meta=np.ndarray&gt;\n\u2502           e3t            (time_counter, k, j, i) float32 393MB dask.array&lt;chunksize=(1, 75, 331, 360), meta=np.ndarray&gt;\n\u2502           e1t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level      (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level   (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphiv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e1v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> <p>By examining the vertical profile &amp; the size of the <code>k</code> grid coordinate variable, we can see that our eORCA1 configuration has 75 unevenly-spaced z*-coordinate levels.</p> In\u00a0[5]: Copied! <pre># Plot an example time-mean vertical conservative temperature profile in the subpolar North Atlantic:\nnemo['/gridT']['thetao_con'].isel(i=260, j=260, time_counter=0).plot(y='deptht', ylim=(3600, 0), marker='o')\n\n# Size of the vertical coordinate dimension:\nprint(nemo['/gridT']['k'].size)\n</pre> # Plot an example time-mean vertical conservative temperature profile in the subpolar North Atlantic: nemo['/gridT']['thetao_con'].isel(i=260, j=260, time_counter=0).plot(y='deptht', ylim=(3600, 0), marker='o')  # Size of the vertical coordinate dimension: print(nemo['/gridT']['k'].size) <pre>75\n</pre> In\u00a0[6]: Copied! <pre># Define our target vertical grid coordinate:\ne3t_target = xr.DataArray(np.repeat(200.0, 30), dims=['k_new'])\n\ne3t_target\n</pre> # Define our target vertical grid coordinate: e3t_target = xr.DataArray(np.repeat(200.0, 30), dims=['k_new'])  e3t_target Out[6]: <pre>&lt;xarray.DataArray (k_new: 30)&gt; Size: 240B\narray([200., 200., 200., 200., 200., 200., 200., 200., 200., 200., 200.,\n       200., 200., 200., 200., 200., 200., 200., 200., 200., 200., 200.,\n       200., 200., 200., 200., 200., 200., 200., 200.])\nDimensions without coordinates: k_new</pre> In\u00a0[7]: Copied! <pre># Transform eORCA1 3-dimensional conservative temperature field to new vertical coordinate system:\nds_k_transform = nemo.transform_vertical_grid(grid = '/gridT',\n                                              var = 'thetao_con',\n                                              e3_new = e3t_target\n                                              )\n\nds_k_transform\n</pre> # Transform eORCA1 3-dimensional conservative temperature field to new vertical coordinate system: ds_k_transform = nemo.transform_vertical_grid(grid = '/gridT',                                               var = 'thetao_con',                                               e3_new = e3t_target                                               )  ds_k_transform Out[7]: <pre>&lt;xarray.Dataset&gt; Size: 631MB\nDimensions:        (time_counter: 11, j: 331, i: 360, k_new: 30)\nCoordinates:\n  * time_counter   (time_counter) datetime64[ns] 88B 2000-07-02 ... 2010-07-0...\n    time_centered  (time_counter) datetime64[ns] 88B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n  * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n  * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n    deptht_new     (k_new) float64 240B 200.0 400.0 600.0 ... 5.8e+03 6e+03\nDimensions without coordinates: k_new\nData variables:\n    thetao_con     (time_counter, k_new, j, i) float64 315MB dask.array&lt;chunksize=(1, 30, 331, 360), meta=np.ndarray&gt;\n    e3t_new        (time_counter, j, i, k_new) float64 315MB dask.array&lt;chunksize=(1, 331, 360, 30), meta=np.ndarray&gt;</pre> <p>Notice that the output above returns a Dataset containing two DataArrays: the vertically remapped conservative temperature <code>thetao_con</code> and the vertical grid cell thicknesses <code>e3t_out</code> (accounting for partial grid cell at the sea floor).</p> <p>Since both of these DataArrays contain dask arrays, we haven't actually computed anything yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[8]: Copied! <pre>ds_k_transform = ds_k_transform.compute()\n</pre> ds_k_transform = ds_k_transform.compute() In\u00a0[9]: Copied! <pre># Plot our original time-mean vertical conservative temperature profile in the subpolar North Atlantic:\nnemo['/gridT']['thetao_con'].isel(i=260, j=260, time_counter=0).plot(y='deptht', ylim=(3600, 0), marker='o', color='dodgerblue')\n\n# Plot our vertically transformed time-mean vertical conservative temperature profile in the subpolar North Atlantic:\nds_k_transform['thetao_con'].isel(i=260, j=260, time_counter=0).plot(y='deptht_new', ylim=(3600, 0), marker='o', color='coral')\n</pre> # Plot our original time-mean vertical conservative temperature profile in the subpolar North Atlantic: nemo['/gridT']['thetao_con'].isel(i=260, j=260, time_counter=0).plot(y='deptht', ylim=(3600, 0), marker='o', color='dodgerblue')  # Plot our vertically transformed time-mean vertical conservative temperature profile in the subpolar North Atlantic: ds_k_transform['thetao_con'].isel(i=260, j=260, time_counter=0).plot(y='deptht_new', ylim=(3600, 0), marker='o', color='coral') Out[9]: <pre>[&lt;matplotlib.lines.Line2D at 0x30ff7b890&gt;]</pre> <p>We can also verify that the product of the vertical grid cell thickness (m) and conservative temperature (C) is conserved following the transformation.</p> <p>Note that we need to transform all variables to a consistent <code>dtype</code> (in this case float64) before making the comparison.</p> In\u00a0[10]: Copied! <pre># Calculate the sum of the product of the transformed conservative temperature and cell thickness at our example location:\nprint((ds_k_transform['thetao_con'].isel(time_counter=0, i=260, j=260).astype(np.float64) * ds_k_transform['e3t_new'].isel(time_counter=0, i=260, j=260).astype(np.float64)).sum().compute())\n\n# Calculate the sum of the product of the original conservative temperature and cell thickness at our example location:\nprint((nemo['/gridT']['thetao_con'].isel(time_counter=0, i=260, j=260).astype(np.float64) * nemo['/gridT']['e3t'].isel(time_counter=0, i=260, j=260).astype(np.float64)).sum().compute())\n</pre> # Calculate the sum of the product of the transformed conservative temperature and cell thickness at our example location: print((ds_k_transform['thetao_con'].isel(time_counter=0, i=260, j=260).astype(np.float64) * ds_k_transform['e3t_new'].isel(time_counter=0, i=260, j=260).astype(np.float64)).sum().compute())  # Calculate the sum of the product of the original conservative temperature and cell thickness at our example location: print((nemo['/gridT']['thetao_con'].isel(time_counter=0, i=260, j=260).astype(np.float64) * nemo['/gridT']['e3t'].isel(time_counter=0, i=260, j=260).astype(np.float64)).sum().compute()) <pre>&lt;xarray.DataArray ()&gt; Size: 8B\narray(14272.51116587)\nCoordinates:\n    time_counter   datetime64[ns] 8B 2000-07-02\n    time_centered  datetime64[ns] 8B 2000-07-02\n    gphit          float64 8B 51.34\n    glamt          float64 8B -26.44\n    j              int64 8B 261\n    i              int64 8B 261\n&lt;xarray.DataArray ()&gt; Size: 8B\narray(14272.51116587)\nCoordinates:\n    time_counter   datetime64[ns] 8B 2000-07-02\n    time_centered  datetime64[ns] 8B 2000-07-02\n    gphit          float64 8B 51.34\n    glamt          float64 8B -26.44\n    j              int64 8B 261\n    i              int64 8B 261\n</pre>"},{"location":"recipe_transform_vertical_coords/#description","title":"Description\u00b6","text":"<p>Recipe showing how to conservatively transform the vertical coordinate system on which a variable is stored using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using ERA-5 climatologically adjusted atmospheric forcing from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_transform_vertical_coords/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note: Although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_transform_vertical_coords/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 NEMO model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_transform_vertical_coords/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and T- &amp; V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_transform_vertical_coords/#exploring-our-eorca1-nemo-model-vertical-coordinate-system","title":"Exploring our eORCA1 NEMO model vertical coordinate system\u00b6","text":"<p>Let's begin by visualising the conservative temperature in the original vertical coordinates of our eORCA1 NPD simulation by plotting a vertical profile at a location in the North Atlantic Ocean:</p>"},{"location":"recipe_transform_vertical_coords/#transforming-the-eorca1-vertical-coordinate-system","title":"Transforming the eORCA1 vertical coordinate system\u00b6","text":"<p>Next, let's apply a conservative vertical coordinate transformation to remap our conservative temperature output to a new regularly-spaced (200 m) vertical grid:</p>"},{"location":"recipe_transform_vertical_coords/#visualising-the-vertically-transformed-conservative-temperature-field","title":"Visualising the vertically transformed conservative temperature field\u00b6","text":"<p>Let's plot the original and vertically transformed conservative temperature profiles together.</p>"},{"location":"recipe_volume_census/","title":"Volume Census in T-S Space","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport numpy as np\nimport xarray as xr\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import numpy as np import xarray as xr from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x30df91010&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[2]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})\nds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={}) ds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})  ds_domain Out[2]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (t: 1, y: 331, x: 360, z: 75)\nDimensions without coordinates: t, y, x, z\nData variables: (12/54)\n    e1t            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2v            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    bottom_level   (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2t            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    e2u            (t, y, x) float64 953kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    bathy_metry    (t, y, x) float32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (z) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   (t) float64 8B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    top_level      (t, y, x) int32 477kB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we need to import the sea water conservative temperature and absolute salinity stored at T-points in a single dataset.</p> In\u00a0[3]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"\n\n# Construct NEMO model grid dataset, including seawater conservative temperature (C) and absolute salinity (g/kg):\nds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['thetao_con', 'so_abs', 'e3t']], compat=\"override\")\n\nds_gridT\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"  # Construct NEMO model grid dataset, including seawater conservative temperature (C) and absolute salinity (g/kg): ds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['thetao_con', 'so_abs', 'e3t']], compat=\"override\")  ds_gridT Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 5GB\nDimensions:        (deptht: 75, y: 331, x: 360, time_counter: 48)\nCoordinates:\n  * deptht         (deptht) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n  * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\nDimensions without coordinates: y, x\nData variables:\n    thetao_con     (time_counter, deptht, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    so_abs         (time_counter, deptht, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    e3t            (time_counter, deptht, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean\n    interval_operation:  1 yr\n    interval_write:      1 yr\n    long_name:           sea_water_conservative_temperature\n    online_operation:    average\n    standard_name:       sea_water_conservative_temperature\n    units:               degC</pre> In\u00a0[4]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain.rename({\"z\": \"nav_lev\"}), \"gridT\": ds_gridT}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain.rename({\"z\": \"nav_lev\"}), \"gridT\": ds_gridT}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[4]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 48)\n\u2502   Coordinates:\n\u2502       time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502     * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:        (time_counter: 48, k: 75, j: 331, i: 360)\n\u2502       Coordinates:\n\u2502         * deptht         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           thetao_con     (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           so_abs         (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           e3t            (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           e1t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level      (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level   (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphiv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e1v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> In\u00a0[5]: Copied! <pre># Define Atlantic Ocean basin mask:\natlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"}).astype(bool)\n</pre> # Define Atlantic Ocean basin mask: atlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"}).astype(bool) In\u00a0[6]: Copied! <pre># Define discrete conservative temperature [C] and absolute salinity [g/kg] bins:\nthetao_bins = np.arange(-2, 35, 0.5)\nso_bins = np.arange(20, 38, 0.1)\n\n# Compute volume of each T-grid cell [m3].\nnemo['gridT']['volcello'] = nemo.cell_volume(grid='/gridT')\n\n# Compute total volume in discrete conservative temperature - absolute salinity coords:\nvol_thetao_so_atl = nemo.binned_statistic(grid=\"/gridT\",\n                                          vars=[\"thetao_con\", \"so_abs\"],\n                                          values=\"volcello\",\n                                          keep_dims=[\"time_counter\"],\n                                          bins=[thetao_bins, so_bins],\n                                          statistic=\"nansum\",\n                                          mask=atlmask\n                                          )\n\nvol_thetao_so_atl\n</pre> # Define discrete conservative temperature [C] and absolute salinity [g/kg] bins: thetao_bins = np.arange(-2, 35, 0.5) so_bins = np.arange(20, 38, 0.1)  # Compute volume of each T-grid cell [m3]. nemo['gridT']['volcello'] = nemo.cell_volume(grid='/gridT')  # Compute total volume in discrete conservative temperature - absolute salinity coords: vol_thetao_so_atl = nemo.binned_statistic(grid=\"/gridT\",                                           vars=[\"thetao_con\", \"so_abs\"],                                           values=\"volcello\",                                           keep_dims=[\"time_counter\"],                                           bins=[thetao_bins, so_bins],                                           statistic=\"nansum\",                                           mask=atlmask                                           )  vol_thetao_so_atl Out[6]: <pre>&lt;xarray.DataArray 'volcello' (time_counter: 48, thetao_con_bins: 73,\n                              so_abs_bins: 179)&gt; Size: 5MB\ndask.array&lt;reshape, shape=(48, 73, 179), dtype=float64, chunksize=(48, 73, 179), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time_counter     (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-0...\n  * thetao_con_bins  (thetao_con_bins) float64 584B -1.75 -1.25 ... 33.75 34.25\n  * so_abs_bins      (so_abs_bins) float64 1kB 20.05 20.15 20.25 ... 37.75 37.85</pre> <p>Notice that the output above contains dask arrays, so we haven't actually computed the volume census yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[7]: Copied! <pre>vol_thetao_so_atl = vol_thetao_so_atl.compute()\n</pre> vol_thetao_so_atl = vol_thetao_so_atl.compute() <pre>OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n</pre> In\u00a0[8]: Copied! <pre>vol_thetao_so_atl.mean(dim='time_counter').plot()\n</pre> vol_thetao_so_atl.mean(dim='time_counter').plot() Out[8]: <pre>&lt;matplotlib.collections.QuadMesh at 0x33a884050&gt;</pre>"},{"location":"recipe_volume_census/#description","title":"Description\u00b6","text":"<p>This recipe shows how to calculate the volume census in discrete temperature-salinity coordinates using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_volume_census/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note: Although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_volume_census/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 NEMO model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_volume_census/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and T- &amp; V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_volume_census/#calculating-volume-census","title":"Calculating Volume Census\u00b6","text":"<p>Now we have constructed our <code>NEMODataTree</code>, let's calculate the volume census in in T-S coordinates using the <code>.binned_statistic()</code> method:</p>"},{"location":"recipe_volume_census/#visualising-the-time-mean-volume-census-in-t-s-coordinates","title":"Visualising the time-mean volume census in T-S coordinates\u00b6","text":"<p>Finally, let's visualise the results by plotting the time-mean volume census in conservative temperature - absolute salinity space:</p>"},{"location":"recipes/","title":"Summary","text":""},{"location":"recipes/#summary","title":"Summary","text":""},{"location":"recipes/#available-recipes","title":"Available Recipes","text":"<ol> <li> <p>Meridional overturning stream function in an arbitrary tracer coordinates.</p> </li> <li> <p>Meridional overturning stream function in depth coordinates (z/z*).</p> </li> <li> <p>Meridional heat &amp; salt transports.</p> </li> <li> <p>Surface-forced water mass transformation in potential density coordinates.</p> </li> <li> <p>Volume census in T-S coordinates.</p> </li> <li> <p>Masked statistics using bounding boxes and polygons.</p> </li> <li> <p>Extracting volume transports and properties along the Overturning in the Subpolar North Atlantic array.</p> </li> <li> <p>Vertical coordinate transformations.</p> </li> </ol>"},{"location":"recipes/#recipes-in-development","title":"Recipes In Development","text":"<ol> <li> <p>Barotropic stream functions.</p> </li> <li> <p>Meridional overturning stream functions in multi-envelope sigma coordinates.</p> </li> <li> <p>Ocean heat content &amp; mixed layer heat content. </p> </li> <li> <p>Sea ice diagnostics.</p> </li> <li> <p>Vorticity diagnostics.</p> </li> </ol>"},{"location":"recipes/#contributing-new-recipes","title":"Contributing New Recipes...","text":"<p>If you've used <code>NEMODataTree</code> to calculate a frequently used diagnostic not currently included in the Recipe Lists above, we'd strongly encourage you to visit the [Contributing] page to learn more how to add this to the NEMO Cookbook.</p>"},{"location":"reference/","title":"API","text":""},{"location":"reference/#nemodatatree-api","title":"NEMODataTree API","text":""},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree","title":"nemo_cookbook.nemodatatree.NEMODataTree","text":"<p>               Bases: <code>DataTree</code></p> <p>A hierarchical data structure containing collections of NEMO ocean model outputs.</p> <p>This class extends <code>xarray.DataTree</code> to provide methods for processing and analysing NEMO output xarray objects defining one or more model domains.</p> <p>It supports NEMO discrete scalar and vector operators such as computing gradients, divergence, curl, weighted averages, integrals, cumulative integrals, and transforming variables between grids.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Create a single node of a NEMODataTree.</p> <code>binned_statistic</code> <p>Calculate binned statistic of a variable defined on a NEMO model grid.</p> <code>cell_area</code> <p>Calculate grid cell areas orthogonal to a given dimension of a NEMO model grid.</p> <code>cell_volume</code> <p>Calculate grid cell volumes for a given NEMO model grid.</p> <code>clip_domain</code> <p>Clip a NEMO model domain to specified longitude and latitude range.</p> <code>clip_grid</code> <p>Clip a NEMO model grid to specified longitude and latitude range.</p> <code>curl</code> <p>Calculate the vertical (k) curl component of a vector field on a NEMO model grid.</p> <code>divergence</code> <p>Calculate the horizontal divergence of a vector field defined on a NEMO model grid.</p> <code>extract_mask_boundary</code> <p>Extract the boundary of a masked region defined on a NEMO model grid.</p> <code>from_datasets</code> <p>Create a NEMODataTree from a dictionary of <code>xarray.Dataset</code> objects created from NEMO model output files,</p> <code>from_paths</code> <p>Create a NEMODataTree from a dictionary of paths to NEMO model output files,</p> <code>gradient</code> <p>Calculate the gradient of a scalar variable along one dimension (e.g., 'i', 'j', 'k') of a NEMO model grid.</p> <code>integral</code> <p>Integrate a variable along one or more dimensions of a NEMO model grid.</p> <code>mask_with_polygon</code> <p>Create mask of NEMO model grid points contained within a polygon.</p> <code>masked_statistic</code> <p>Masked statistic of a variable defined on a NEMO model grid.</p> <code>transform_scalar_to</code> <p>Transform scalar variable defined on a NEMO model grid to a neighbouring horizontal grid using linear interpolation.</p> <code>transform_vertical_grid</code> <p>Transform variable defined on a NEMO model grid to a new vertical grid using conservative interpolation.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>class NEMODataTree(xr.DataTree):\n    \"\"\"\n    A hierarchical data structure containing collections of NEMO ocean model outputs.\n\n    This class extends `xarray.DataTree` to provide methods for processing\n    and analysing NEMO output xarray objects defining one or more model domains.\n\n    It supports NEMO discrete scalar and vector operators such as computing gradients,\n    divergence, curl, weighted averages, integrals, cumulative integrals, and\n    transforming variables between grids.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Create a single node of a NEMODataTree.\n\n        The node may optionally contain data in the form of data\n        and coordinate variables, stored in the same way as data\n        is stored in an `xarray.Dataset`.\n\n        Parameters\n        ----------\n        *args : tuple\n            Positional arguments to pass to the parent class.\n        **kwargs : dict\n            Keyword arguments to pass to the parent class.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n\n    @classmethod\n    def from_paths(\n        cls,\n        paths: dict[str, str],\n        nests: dict[str, str] | None = None,\n        iperio: bool = False,\n        nftype: str | None = None,\n        read_mask: bool = False,\n        nbghost_child: int = 4,\n        **open_kwargs: dict[str, any],\n    ) -&gt; Self:\n        \"\"\"\n        Create a NEMODataTree from a dictionary of paths to NEMO model output files,\n        organised into a hierarchy of domains (i.e., 'parent', 'child', 'grandchild').\n\n        Parameters\n        ----------\n        paths : dict[str, str]\n            Dictionary containing paths to NEMO grid files, structured as:\n            {\n                'parent': {'domain': 'path/to/domain.nc',\n                           'gridT': 'path/to/gridT.nc',\n                            , ... ,\n                            'icemod': 'path/to/icemod.nc',\n                            },\n                'child': {'1': {'domain': 'path/to/child_domain.nc',\n                                'gridT': 'path/to/child_gridT.nc',\n                                , ... ,\n                                'icemod': 'path/to/child_icemod.nc',\n                                },\n                          },\n                'grandchild': {'2': {'domain': 'path/to/grandchild_domain.nc',\n                                     'gridT': 'path/to/grandchild_gridT.nc',\n                                     , ...,\n                                     'icemod': 'path/to/grandchild_icemod.nc',\n                                     },\n                               }\n            }\n\n        nests : dict[str, str], optional\n            Dictionary describing the properties of nested domains, structured as:\n            {\n                \"1\": {\n                    \"parent\": \"/\",\n                    \"rx\": rx,\n                    \"ry\": ry,\n                    \"imin\": imin,\n                    \"imax\": imax,\n                    \"jmin\": jmin,\n                    \"jmax\": jmax,\n                    \"iperio\": iperio,\n                    },\n            }\n            where `rx` and `ry` are the horizontal refinement factors, and `imin`, `imax`, `jmin`, `jmax`\n            define the indices of the child (grandchild) domain within the parent (child) domain. Zonally\n            periodic nested domains should be specified with `iperio=True`.\n\n        iperio: bool = False\n            Zonal periodicity of the parent domain. Default is False.\n\n        nftype: str, optional\n            Type of north fold lateral boundary condition to apply. Options are 'T' for T-point pivot or 'F' for F-point\n            pivot. By default, no north fold lateral boundary condition is applied (None).\n\n        read_mask: bool = False\n            If True, read NEMO model land/sea mask from domain files. Default is False, meaning masks are computed from top_level and bottom_level domain variables.\n\n        nbghost_child : int = 4\n            Number of ghost cells to remove from the western/southern boundaries of the (grand)child domains. Default is 4.\n\n        **open_kwargs : dict, optional\n            Additional keyword arguments to pass to `xarray.open_dataset` or `xr.open_mfdataset` when opening NEMO model output files.\n        Returns\n        -------\n        NEMODataTree\n            A hierarchical DataTree storing NEMO model outputs.\n        \"\"\"\n        if not isinstance(paths, dict):\n            raise TypeError(\"paths must be a dictionary or nested dictionary.\")\n        if not isinstance(nests, (dict, type(None))):\n            raise TypeError(\"nests must be a dictionary or None.\")\n        if not isinstance(iperio, bool):\n            raise TypeError(\"zonal periodicity of parent domain must be a boolean.\")\n        if nftype is not None and nftype not in ('T', 'F'):\n            raise ValueError(\"north fold type of parent domain must be 'T' (T-pivot fold), 'F' (F-pivot fold), or None.\")\n        if not isinstance(read_mask, bool):\n            raise TypeError(\"read_mask must be a boolean.\")\n        if not isinstance(nbghost_child, int):\n            raise TypeError(\"number of ghost cells along the western/southern boundaries must be an integer.\")\n        if not isinstance(open_kwargs, dict):\n            raise TypeError(\"open_kwargs must be a dictionary.\")\n\n        # Define parent, child, grandchild filepath collections:\n        d_child, d_grandchild = None, None\n        if 'parent' in paths.keys() and isinstance(paths['parent'], dict):\n            for key in paths.keys():\n                if key not in ('parent', 'child', 'grandchild'):\n                    raise ValueError(f\"Unexpected key '{key}' in paths dictionary.\")\n                if key == 'parent':\n                    d_parent = paths['parent']\n                elif key == 'child':\n                    d_child = paths['child']\n                elif key == 'grandchild':\n                    d_grandchild = paths['grandchild']\n        else:\n            raise ValueError(\"Invalid paths structure. Expected a nested dictionary defining NEMO 'parent', 'child' and 'grandchild' domains.\")\n\n        # Construct DataTree from parent / child / grandchild domains:\n        d_tree = create_datatree_dict(d_parent=d_parent,\n                                      d_child=d_child,\n                                      d_grandchild=d_grandchild,\n                                      nests=nests,\n                                      iperio=iperio,\n                                      nftype=nftype,\n                                      read_mask=read_mask,\n                                      nbghost_child=nbghost_child,\n                                      open_kwargs=dict(**open_kwargs)\n                                      )\n\n        datatree = super().from_dict(d_tree)\n\n        return datatree\n\n\n    @classmethod\n    def from_datasets(\n        cls,\n        datasets: dict[str, xr.Dataset],\n        nests: dict[str, str] | None = None,\n        iperio: bool = False,\n        nftype: str | None = None,\n        read_mask: bool = False,\n        nbghost_child: int = 4\n    ) -&gt; Self:\n        \"\"\"\n        Create a NEMODataTree from a dictionary of `xarray.Dataset` objects created from NEMO model output files,\n        organised into a hierarchy of domains (i.e., 'parent', 'child', 'grandchild').\n\n        Parameters\n        ----------\n        datasets : dict[str, dict[str, xr.Dataset]]\n            Dictionary containing `xarray.Datasets` created from NEMO grid files, structured as:\n            {\n                'parent': {'domain': ds_domain, 'gridT': ds_gridT, ... , 'icemod': ds_icemod.nc},\n                'child': {'1': {'domain': ds_domain_1, 'gridT': d_gridT_1, ...}},\n                'grandchild': {'2': {'domain': ds_domain_2, 'gridT': ds_gridT_2, ...}}\n            }\n\n        nests : dict[str, dict[st, str]], optional\n            Dictionary describing the properties of nested domains, structured as:\n            {\n                \"1\": {\n                    \"parent\": \"/\",\n                    \"rx\": rx,\n                    \"ry\": ry,\n                    \"imin\": imin,\n                    \"imax\": imax,\n                    \"jmin\": jmin,\n                    \"jmax\": jmax,\n                    },\n            }\n            where `rx` and `ry` are the horizontal refinement factors, and `imin`, `imax`, `jmin`, `jmax`\n            define the indices of the child (grandchild) domain within the parent (child) domain.\n\n        iperio: bool = False\n            Zonal periodicity of the parent domain.\n\n        nftype: str, optional\n            Type of north fold lateral boundary condition to apply. Options are 'T' for T-point pivot or 'F' for F-point\n            pivot. By default, no north fold lateral boundary condition is applied (None).\n\n        read_mask: bool = False\n            If True, read NEMO model land/sea mask from domain files. Default is False, meaning masks are computed from top_level and bottom_level domain variables.\n\n        nbghost_child : int = 4\n            Number of ghost cells to remove from the western/southern boundaries of the (grand)child domains. Default is 4.\n\n        Returns\n        -------\n        NEMODataTree\n            A hierarchical data tree of NEMO model outputs.\n        \"\"\"\n        if not isinstance(datasets, dict):\n            raise TypeError(\"datasets must be a dictionary or nested dictionary.\")\n        if not isinstance(nests, (dict, type(None))):\n            raise TypeError(\"nests must be a dictionary or None.\")\n        if not isinstance(iperio, bool):\n            raise TypeError(\"zonal periodicity of parent domain must be a boolean.\")\n        if nftype is not None and nftype not in ('T', 'F'):\n            raise ValueError(\"north fold type of parent domain must be 'T' (T-pivot fold), 'F' (F-pivot fold), or None.\")\n        if not isinstance(read_mask, bool):\n            raise TypeError(\"read_mask must be a boolean.\")\n        if not isinstance(nbghost_child, int):\n            raise TypeError(\"number of ghost cells along the western/southern boundaries must be an integer.\")\n\n        # Define parent, child, grandchild dataset collections:\n        d_child, d_grandchild = None, None\n        if 'parent' in datasets.keys() and isinstance(datasets['parent'], dict):\n            for key in datasets.keys():\n                if key not in ('parent', 'child', 'grandchild'):\n                    raise ValueError(f\"unexpected key '{key}' in datasets dictionary.\")\n                if key == 'parent':\n                    d_parent = datasets['parent']\n                elif key == 'child':\n                    d_child = datasets['child']\n                elif key == 'grandchild':\n                    d_grandchild = datasets['grandchild']\n        else:\n            raise ValueError(\"invalid dataset structure. Expected a nested dictionary defining NEMO 'parent', 'child' and 'grandchild' domains.\")\n\n        # Construct DataTree from parent / child / grandchild domains:\n        d_tree = create_datatree_dict(d_parent=d_parent,\n                                      d_child=d_child,\n                                      d_grandchild=d_grandchild,\n                                      nests=nests,\n                                      iperio=iperio,\n                                      nftype=nftype,\n                                      read_mask=read_mask,\n                                      nbghost_child=nbghost_child\n                                      )\n        datatree = super().from_dict(d_tree)\n\n        return datatree\n\n\n    def _get_properties(\n        cls,\n        dom: str | None = None,\n        grid: str | None = None,\n        infer_dom: bool = False\n        ) -&gt; str:\n        \"\"\"\n        Get NEMO model domain and grid properties.\n\n        The domain prefix &amp; suffix (e.g., '1_', '1') are returned\n        if only the NEMO model domain (`dom`) is specified.\n\n        The grid suffix (e.g., 't', 'u', 'v', 'w') is returned if\n        only the NEMO model grid (`grid`) is specified.\n\n        The domain number, domain prefix &amp; suffix, and grid suffix\n        are returned if both the NEMO model grid (`grid`) and\n        `infer_dom = True` are specified.\n\n        Parameters\n        ----------\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        grid : str, optional\n            Path to NEMO model grid (e.g., '/gridT').\n        infer_dom : bool, optional\n            Whether to infer the domain number &amp; domain name from only the\n            grid path. Default is False.\n\n        Returns\n        -------\n        tuple[str]\n            NEMO model domain and grid properties.\n        \"\"\"\n        if (grid is None) &amp; (dom is not None):\n            dom_prefix = \"\" if dom == \".\" else f\"{dom}_\"\n            dom_suffix = \"\" if dom == \".\" else f\"{dom}\"\n            return dom_prefix, dom_suffix\n        else:\n            if grid not in list(cls.subtree):\n                raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n            grid_suffix = f\"{grid.lower()[-1]}\"\n\n            if infer_dom:\n                dom_inds = [char for char in grid if char.isdigit()]\n                dom_prefix = f\"{dom_inds[-1]}_\" if len(dom_inds) != 0 else \"\"\n                dom = dom_prefix[:-1] if dom_prefix != \"\" else \".\"\n                dom_suffix = dom if dom != \".\" else \"\"\n                return dom, dom_prefix, dom_suffix, grid_suffix\n            else:\n                return grid_suffix\n\n\n    def _get_grid_paths(\n        cls,\n        dom: str\n        ) -&gt; str:\n        \"\"\"\n        Get paths to NEMO model grids in a given domain.\n\n        Parameters\n        ----------\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n\n        Returns\n        -------\n        dict[str, str]\n            Dictionary of NEMO model grid paths.\n        \"\"\"\n        # Collect paths to all NEMO model grids:\n        grid_paths = [path[0] for path in list(cls.subtree_with_keys)]\n\n        if dom == '.':\n            grid_paths = [path for path in grid_paths if (\"_\" not in path) &amp; (\"grid\" in path)]\n        else:\n            grid_paths = [path for path in grid_paths if dom in path]\n\n        d_paths = {path.split(\"/\")[0]: path for path in grid_paths}\n\n        return d_paths\n\n\n    def _get_ijk_names(\n        cls,\n        dom: str | None = None,\n        grid: str | None = None\n        ) -&gt; str:\n        \"\"\"\n        Get (i, j, k) grid index names for given NEMO model domain.\n\n        If path to NEMO model grid is provided, domain is inferred.\n\n        Parameters\n        ----------\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        grid : str, optional\n            Path to NEMO model grid (e.g., '/gridT').\n\n        Returns\n        -------\n        dict[str, str]\n            NEMO model grid index names.\n        \"\"\"\n        if grid is not None:\n            dom, _, dom_suffix, _ = cls._get_properties(grid=grid, infer_dom=True)\n        else:\n            _, dom_suffix = cls._get_properties(dom=dom)\n\n        indexes = [\"i\", \"j\", \"k\"]\n        if dom == \".\":\n            d_ijk = {index: index for index in indexes}\n        else:\n            d_ijk = {index: f\"{index}{dom_suffix}\" for index in indexes}\n\n\n        return d_ijk\n\n\n    def _get_weights(\n        cls,\n        grid: str,\n        dims: list\n        ) -&gt; xr.DataArray:\n        \"\"\"\n        Get the weights (scale factors) for specified dimensions of a NEMO model grid.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where weights are stored (e.g., '/gridT').\n        dims : list\n            Dimensions to collect weights for.\n\n        Returns\n        -------\n        xr.DataArray\n            Weights (scale factors) for the specified dimensions of the NEMO model grid.\n        \"\"\"\n        if any(dim not in ['i', 'j', 'k'] for dim in dims):\n            raise ValueError(\"dims must be a list containing one or more of the following dimensions: ['i', 'j', 'k'].\")\n\n        grid_suffix = cls._get_properties(grid=grid)\n\n        weights_dict = {\"i\": f\"e1{grid_suffix}\",\n                        \"j\": f\"e2{grid_suffix}\",\n                        \"k\": f\"e3{grid_suffix}\",\n                        }\n        weights_list = [cls[grid][weights_dict[dim]] for dim in dims]\n\n        if len(weights_list) == 1:\n            weights = weights_list[0]\n        elif len(weights_list) == 2:\n            weights = weights_list[0] * weights_list[1]\n        elif len(weights_list) == 3:\n            weights = weights_list[0] * weights_list[1] * weights_list[2]\n        else:\n            raise RuntimeError(f\"weights missing for dimensions {dims} of NEMO model grid {grid}.\")\n\n        weights = weights.fillna(value=0)\n\n        return weights\n\n\n    def cell_area(\n        cls,\n        grid: str,\n        dim: str,\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Calculate grid cell areas orthogonal to a given dimension of a NEMO model grid.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid from which to calculate\n            grid cell areas (e.g., '/gridT').\n        dim : str\n            Dimension orthogonal to grid cell area to\n            calculate (e.g., 'k' returns e1 * e2).\n\n        Returns\n        -------\n        xr.DataArray\n            Grid cell areas (m^2) for the specified NEMO model grid.\n        \"\"\"\n        grid_suffix = cls._get_properties(grid=grid)\n\n        if dim not in ['i', 'j', 'k']:\n            raise ValueError(f\"dim {dim} must be one of ['i', 'j', 'k'].\")\n\n        match dim:\n            case 'i':\n                cell_area = cls[grid][f'e3{grid_suffix}'] * cls[grid][f'e2{grid_suffix}']\n            case 'j':\n                cell_area = cls[grid][f'e3{grid_suffix}'] * cls[grid][f'e1{grid_suffix}']\n            case 'k':\n                cell_area = cls[grid][f'e1{grid_suffix}'] * cls[grid][f'e2{grid_suffix}']\n        cell_area.name = \"areacello\"\n\n        return cell_area\n\n\n    def cell_volume(\n        cls,\n        grid: str\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Calculate grid cell volumes for a given NEMO model grid.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid from which to calculate\n            grid cell volumes (e.g., '/gridT').\n\n        Returns\n        -------\n        xr.DataArray\n            Grid cell volumes for the specified NEMO model grid.\n        \"\"\"\n        grid_suffix = cls._get_properties(grid=grid)\n\n        mask = cls[grid][f\"{grid_suffix}mask\"]\n\n        cell_volume = cls[grid][f\"e3{grid_suffix}\"].where(mask) * cls[grid][f\"e1{grid_suffix}\"] * cls[grid][f\"e2{grid_suffix}\"]\n        cell_volume.name = \"volcello\"\n\n        return cell_volume\n\n\n    def gradient(\n        cls,\n        var: str,\n        dim: str,\n        dom: str = '.',\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Calculate the gradient of a scalar variable along one dimension (e.g., 'i', 'j', 'k') of a NEMO model grid.\n\n        Parameters\n        ----------\n        var : str\n            Name of the scalar variable.\n        dim : str\n            Dimension along which to calculate gradient (e.g., 'i', 'j', 'k').\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n            Default is '.' for the parent domain.\n\n        Returns\n        -------\n        xr.DataArray\n            Gradient of scalar variable defined on a NEMO model grid.\n        \"\"\"\n        # -- Validate input -- #\n        if not isinstance(var, str):\n            raise ValueError(\"var must be a string specifying name of the scalar variable.\")\n        if not isinstance(dim, str):\n            raise ValueError(\"dim must be a string specifying dimension along which to calculate the gradient (e.g., 'i', 'j', 'k').\")\n        if not isinstance(dom, str):\n            raise ValueError(\"dom must be a string specifying prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\")\n\n        # -- Get NEMO model grid properties -- #\n        dom_prefix, dom_suffix = cls._get_properties(dom=dom)\n        grid_paths = cls._get_grid_paths(dom=dom)\n        gridT, gridU, gridV, gridW = grid_paths['gridT'], grid_paths['gridU'], grid_paths['gridV'], grid_paths['gridW']\n\n        if var not in cls[gridT].data_vars:\n            raise KeyError(f\"variable '{var}' not found in grid '{gridT}'.\")\n\n        da = cls[gridT][var]\n        dim_name = f\"{dim}{dom_suffix}\"\n        if dim_name not in da.dims:\n            raise KeyError(f\"dimension '{dim_name}' not found in variable '{var}'. Dimensions available: {da.dims}.\")\n\n        match dim:\n            case \"i\":\n                if f\"{dom_prefix}deptht\" in da.coords:\n                    # 3-dimensional umask:\n                    umask = cls[gridU][\"umask\"]\n                else:\n                    # 2-dimensional umask:\n                    umask = cls[gridU][\"umaskutil\"]\n\n                # Zonally Periodic Domain:\n                if cls[gridT].attrs.get(\"iperio\", False):\n                    da_end = da.isel(dim_name=0)\n                    da_end[dim_name] = da[dim_name].max() + 1\n                    da = xr.concat([da, da_end], dim=dim_name)\n                    dvar = da.diff(dim=dim_name, label=\"lower\")\n                else:\n                    # Non-Periodic: pad with NaN values after differencing:\n                    dvar = (da\n                            .diff(dim=dim_name, label=\"lower\")\n                            .pad({dim_name: (0, 1)})\n                            )\n                # Apply u-mask &amp; transform coords -&gt; calculate gradient:\n                dvar.coords[dim_name] = dvar.coords[dim_name] + 0.5\n                gradient = dvar.where(umask) / cls[gridU][\"e1u\"]\n\n                # Remove redundant depth coordinates:\n                if f\"{dom_prefix}deptht\" in gradient.coords:\n                    gradient = (gradient\n                                .drop_vars([f\"{dom_prefix}deptht\"])\n                                .assign_coords({f\"{dom_prefix}depthu\": cls[gridU][f\"{dom_prefix}depthu\"]})\n                                )\n            case \"j\":\n                # 3-dimensional vmask:\n                if f\"{dom_prefix}deptht\" in da.coords:\n                    vmask = cls[gridV][\"vmask\"]\n                else:\n                    # 2-dimensional vmask (unique points):\n                    vmask = cls[gridV][\"vmaskutil\"]\n\n                # Pad with zeros after differencing (zero gradient at jmaxdom):\n                dvar = (da\n                        .diff(dim=dim_name, label=\"lower\")\n                        .pad({dim_name: (0, 1)}, constant_values=0)\n                        )\n                # Apply vmask &amp; transform coords -&gt; calculate gradient:\n                dvar.coords[dim_name] = dvar.coords[dim_name] + 0.5\n                gradient = dvar.where(vmask) / cls[grid_paths['gridV']][\"e2v\"]\n\n                if f\"{dom_prefix}deptht\" in gradient.coords:\n                    gradient = (gradient\n                                .drop_vars([f\"{dom_prefix}deptht\"])\n                                .assign_coords({f\"{dom_prefix}depthv\": cls[gridV][f\"{dom_prefix}depthv\"]})\n                                )\n\n            case \"k\":\n                dvar = da.diff(dim=dim_name, label=\"lower\")\n                # Transform coords &amp; apply w-mask -&gt; calculate gradient:\n                dvar.coords[dim_name] = dvar.coords[dim_name] + 0.5\n                dvar = dvar.where(cls[gridW][\"wmask\"].isel({dim_name: slice(1, None)}))\n                try:\n                    gradient = - dvar / cls[gridW][\"e3w\"].isel({dim_name: slice(1, None)})\n                    gradient = gradient.drop_vars([f\"{dom_prefix}deptht\"])\n                except KeyError:\n                    raise KeyError(f\"NEMO model grid: '{gridW}' does not contain vertical scale factor 'e3w' required to calculate gradients along the k-dimension.\")\n\n        # Update DataArray properties:\n        gradient.name = f\"grad_{var}_{dim_name}\"\n        gradient = gradient.drop_vars([f\"{dom_prefix}glamt\", f\"{dom_prefix}gphit\"])\n\n        return gradient\n\n\n    def divergence(\n        cls,\n        vars : list[str],\n        dom: str = '.',\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Calculate the horizontal divergence of a vector field defined on a NEMO model grid.\n\n        Parameters\n        ----------\n        vars : list[str]\n            Name of vector variables, structured as: ['u', 'v'], where\n            'u' and 'v' are the i and j components of the vector field,\n            respectively.\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n            Default is '.' for the parent domain.\n\n        Returns\n        -------\n        xr.DataArray\n            Horizontal divergence of vector field defined on a NEMO model grid.\n        \"\"\"\n        # -- Validate input -- #\n        if not isinstance(vars, list) or len(vars) != 2:\n            raise ValueError(\"vars must be a list of two elements structured as ['u', 'v'].\")\n        if not isinstance(dom, str):\n            raise ValueError(\"dom must be a string specifying the prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\")\n\n        # -- Get NEMO model grid properties -- #\n        dom_prefix, _ = cls._get_properties(dom=dom)\n        grid_paths = cls._get_grid_paths(dom=dom)\n        gridT, gridU, gridV = grid_paths['gridT'], grid_paths['gridU'], grid_paths['gridV']\n        ijk_names = cls._get_ijk_names(dom=dom)\n        i_name, j_name = ijk_names['i'], ijk_names['j']\n\n        # -- Define i,j vector components -- #\n        var_i, var_j = vars[0], vars[1]\n        if var_i not in cls[gridU].data_vars:\n            raise KeyError(f\"variable '{var_i}' not found in grid '{gridU}'.\")\n        if var_j not in cls[gridV].data_vars:\n            raise KeyError(f\"variable '{var_j}' not found in grid '{gridV}'.\")\n\n        da_i = cls[gridU][var_i]\n        da_j = cls[gridV][var_j]\n\n        # -- Collect mask -- #\n        if (f\"{dom_prefix}depthu\" in da_i.coords) &amp; (f\"{dom_prefix}depthv\" in da_j.coords):\n            # 3-dimensional tmask:\n            tmask = cls[gridT][\"tmask\"]\n        else:\n            # 2-dimensional tmask (unique points):\n            tmask = cls[gridT][\"tmaskutil\"]\n\n        # -- Neglecting the first T-grid points along i, j dimensions -- #\n        e1t = cls[gridT][\"e1t\"].isel({i_name: slice(1, None), j_name: slice(1, None)})\n        e2t = cls[gridT][\"e2t\"].isel({i_name: slice(1, None), j_name: slice(1, None)})\n        e3t = cls[gridT][\"e3t\"].isel({i_name: slice(1, None), j_name: slice(1, None)})\n\n        e2u, e3u = cls[gridU][\"e2u\"], cls[gridU][\"e3u\"]\n        e1v, e3v = cls[gridV][\"e1v\"], cls[gridV][\"e3v\"]\n\n        # -- Calculate divergence on T-points -- #\n        dvar_i = (e2u * e3u * da_i).diff(dim=i_name, label=\"lower\")\n        dvar_i.coords[i_name] = dvar_i.coords[i_name] + 0.5\n\n        dvar_j = (e1v * e3v * da_j).diff(dim=j_name, label=\"lower\")\n        dvar_j.coords[j_name] = dvar_j.coords[j_name] + 0.5\n\n        divergence = (1 / (e1t * e2t * e3t)) * (dvar_i + dvar_j).where(tmask)\n\n        # -- Update DataArray properties -- #\n        divergence.name = f\"div_{var_i}_{var_j}\"\n        divergence = divergence.drop_vars([f\"{dom_prefix}glamu\", f\"{dom_prefix}gphiu\",\n                                           f\"{dom_prefix}glamv\", f\"{dom_prefix}gphiv\",\n                                           f\"{dom_prefix}depthu\", f\"{dom_prefix}depthv\"\n                                           ])\n\n        return divergence\n\n\n    def curl(\n        cls,\n        vars : list[str],\n        dom: str = '.',\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Calculate the vertical (k) curl component of a vector field on a NEMO model grid.\n\n        Parameters\n        ----------\n        vars : list[str]\n            Name of the vector variables, structured as: ['u', 'v'], where 'u' and 'v' are\n            the i and j components of the vector field, respectively.\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n            Default is '.' for the parent domain.\n\n        Returns\n        -------\n        xr.DataArray\n            Vertical curl component of vector field defined on a NEMO model grid.\n        \"\"\"\n        # -- Validate input -- #\n        if not isinstance(vars, list) or len(vars) != 2:\n            raise ValueError(\"vars must be a list of two elements structured as ['u', 'v'].\")\n        if not isinstance(dom, str):\n            raise ValueError(\"dom must be a string specifying the prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\")\n\n        # -- Get NEMO model grid properties -- #\n        dom_prefix, _ = cls._get_properties(dom=dom)\n        grid_paths = cls._get_grid_paths(dom=dom)\n        gridU, gridV, gridF = grid_paths['gridU'], grid_paths['gridV'], grid_paths['gridF']\n        ijk_names = cls._get_ijk_names(dom=dom)\n        i_name, j_name = ijk_names['i'], ijk_names['j']\n\n        # -- Define i,j vector components -- #\n        var_i, var_j = vars[0], vars[1]\n        if var_i not in cls[gridU].data_vars:\n            raise KeyError(f\"variable '{var_i}' not found in grid '{gridU}'.\")\n        if var_j not in cls[gridV].data_vars:\n            raise KeyError(f\"variable '{var_j}' not found in grid '{gridV}'.\")\n\n        da_i = cls[gridU][var_i]\n        da_j = cls[gridV][var_j]\n\n        # -- Collect mask -- #\n        if (f\"{dom_prefix}depthu\" in da_i.coords) &amp; (f\"{dom_prefix}depthv\" in da_j.coords):\n            # 3-dimensional fmask\n            fmask = cls[gridF][\"fmask\"]\n        else:\n            # 2-dimensional fmask (unique points):\n            fmask = cls[gridF][\"fmaskutil\"]\n\n        # -- Neglecting the final F-grid points along i, j dimensions -- #\n        e1f = cls[gridF][\"e1f\"].isel({i_name: slice(None, -1), j_name: slice(None, -1)})\n        e2f = cls[gridF][\"e2f\"].isel({i_name: slice(None, -1), j_name: slice(None, -1)})\n\n        e1u = cls[gridU][\"e1u\"]\n        e2v = cls[gridV][\"e2v\"]\n\n        # -- Calculate vertical curl component on F-points -- #\n        dvar_i = (e2v * da_j).diff(dim=i_name, label=\"lower\")\n        dvar_i.coords[i_name] = dvar_i.coords[i_name] + 0.5\n\n        dvar_j = (e1u * da_i).diff(dim=j_name, label=\"lower\")\n        dvar_j.coords[j_name] = dvar_j.coords[j_name] + 0.5\n\n        curl = (1 / (e1f * e2f)) * (dvar_i - dvar_j).where(fmask)\n\n        # -- Update DataArray properties -- #\n        curl.name = f\"curl_{var_i}_{var_j}\"\n        curl = curl.drop_vars([f\"{dom_prefix}glamu\", f\"{dom_prefix}gphiu\",\n                               f\"{dom_prefix}glamv\", f\"{dom_prefix}gphiv\",\n                               ])\n\n        return curl\n\n\n    def integral(\n        cls,\n        grid : str,\n        var : str,\n        dims : list,\n        cum_dims : list | None = None,\n        dir : str | None = None,\n        mask : xr.DataArray | None = None\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Integrate a variable along one or more dimensions of a NEMO model grid.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where variable is stored\n            (e.g., '/gridT').\n        var : str\n            Name of variable to integrate.\n        dims : list\n            Dimensions over which to integrate (e.g., ['i', 'k']).\n        cum_dims : list, optional\n            Dimensions over which to cumulatively integrate (e.g., ['k']).\n            Specified dimensions must also be included in `dims`.\n        dir : str, optional\n            Direction of cumulative integration. Options are '+1' (along\n            increasing cum_dims) or '-1' (along decreasing cum_dims).\n        mask: xr.DataArray, optional\n            Boolean mask identifying NEMO model grid points to be included (1)\n            or neglected (0) from integration.\n\n        Returns\n        -------\n        xr.DataArray\n            Variable integrated along specified dimensions of the NEMO model grid.\n\n        \"\"\"\n        # -- Validate input -- #\n        if grid not in list(cls.subtree):\n            raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n        if var not in cls[grid].data_vars:\n            raise KeyError(f\"variable '{var}' not found in grid '{grid}'.\")\n        if cum_dims is not None:\n            for dim in cum_dims:\n                if dim not in dims:\n                    raise ValueError(f\"cumulative integration dimension '{dim}' not included in `dims`.\")\n            if dir not in ['+1', '-1']:\n                raise ValueError(f\"invalid direction of cumulative integration '{dir}'. Expected '+1' or '-1'.\")\n        if mask is not None:\n            if not isinstance(mask, xr.DataArray):\n                raise ValueError(\"mask must be an xarray.DataArray.\")\n            if any(dim not in cls[grid].dims for dim in mask.dims):\n                raise ValueError(f\"mask must have dimensions subset from {cls[grid].dims}.\")\n\n        # -- Get NEMO model grid properties -- #\n        _, dom_prefix, _, grid_suffix = cls._get_properties(grid=grid, infer_dom=True)\n\n        # -- Collect variable, weights &amp; mask -- #\n        da = cls[grid][var].where(mask) if mask is not None else cls[grid][var]\n        weights = cls._get_weights(grid=grid, dims=dims)\n\n        if f\"{dom_prefix}depth{grid_suffix}\" in da.coords:\n            # Apply 3-dimensional t/u/v/f/w mask:\n            dom_mask = cls[grid][f\"{grid_suffix}mask\"]\n        else:\n            # Apply 2-dimensional t/u/v/f mask (unique points):\n            hgrid_type = grid_suffix if 'w' not in grid_suffix else 't'\n            dom_mask = cls[grid][f\"{hgrid_type}maskutil\"]\n\n        # -- Perform integration -- #\n        if cum_dims is not None:\n            sum_dims = [dim for dim in dims if dim not in cum_dims]\n            if dir == '+1':\n                # Cumulative integration along ordered dimension:\n                result = da.where(dom_mask).weighted(weights).sum(dim=sum_dims, skipna=True).cumsum(dim=cum_dims, skipna=True)\n            elif dir == '-1':\n                # Cumulative integration along reversed dimension:\n                result = (da\n                            .where(dom_mask)\n                            .weighted(weights)\n                            .sum(dim=sum_dims, skipna=True)\n                            .reindex({dim: cls[grid][dim][::-1] for dim in cum_dims})\n                            .cumsum(dim=cum_dims, skipna=True)\n                            )\n        else:\n            # Integration only:\n            result = da.weighted(weights).sum(dim=dims, skipna=True)\n\n        return result\n\n\n    def clip_grid(\n        cls,\n        grid: str,\n        bbox: tuple,\n    ) -&gt; Self:\n        \"\"\"\n        Clip a NEMO model grid to specified longitude and latitude range.\n\n        Parameters\n        ----------\n        Path to NEMO model grid to clip (e.g., '/gridT').\n        bbox : tuple\n            Bounding box to clip to (lon_min, lon_max, lat_min, lat_max).\n\n        Returns\n        -------\n        NEMODataTree\n            NEMO DataTree with specified model grid clipped to bounding box.\n        \"\"\"\n        if grid not in list(cls.subtree):\n            raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n        if not isinstance(bbox, tuple) or len(bbox) != 4:\n            raise ValueError(\"bounding box must be a tuple (lon_min, lon_max, lat_min, lat_max).\")\n\n        # -- Get NEMO model grid properties -- #\n        _, dom_prefix, _, grid_suffix = cls._get_properties(grid=grid, infer_dom=True)\n        hgrid_type = grid_suffix if 'w' not in grid_suffix else 't'\n\n        # -- Clip the grid to given bounding box -- #\n        # Indexing with a mask requires loading coords into memory:\n        glam = cls[grid][f\"{dom_prefix}glam{hgrid_type}\"].load()\n        gphi = cls[grid][f\"{dom_prefix}gphi{hgrid_type}\"].load()\n\n        grid_clipped = cls[grid].dataset.where(\n            (glam &gt;= bbox[0]) &amp;\n            (glam &lt;= bbox[1]) &amp;\n            (gphi &gt;= bbox[2]) &amp;\n            (gphi &lt;= bbox[3]),\n            drop=True\n            )\n\n        d_dtypes = {var: cls[grid][var].dtype for var in cls[grid].dataset.data_vars}\n        for var, dtype in d_dtypes.items():\n            if dtype in [np.int32, np.int64, bool]:\n                grid_clipped[var] = grid_clipped[var].fillna(0).astype(dtype)\n\n        if bbox != (-180, 180, -90, 90):\n            grid_clipped = grid_clipped.assign_attrs({\"iperio\": False})\n        cls[grid] = grid_clipped\n\n        return cls\n\n\n    def clip_domain(\n        cls,\n        dom: str,\n        bbox: tuple,\n        ) -&gt; Self:\n        \"\"\"\n        Clip a NEMO model domain to specified longitude and latitude range.\n\n        Parameters\n        ----------\n        dom : str\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n            Default is '.' for the parent domain.\n        bbox : tuple\n            Bounding box to clip to (lon_min, lon_max, lat_min, lat_max).\n\n        Returns\n        -------\n        NEMODataTree\n            NEMO DataTree with specified model domain clipped to bounding box.\n        \"\"\"\n        if not isinstance(dom, str):\n            raise ValueError(\"dom must be a string specifying the prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\")\n        if not isinstance(bbox, tuple) or len(bbox) != 4:\n            raise ValueError(\"bounding box must be a tuple: (lon_min, lon_max, lat_min, lat_max).\")\n\n        # -- Get NEMO model grid properties -- #\n        dom_prefix, _ = cls._get_properties(dom=dom)\n        grid_paths = cls._get_grid_paths(dom=dom)\n\n        # -- Clip grids to given bounding box -- #\n        if not grid_paths:\n            raise ValueError(f\"NEMO model domain '{dom}' not found in the DataTree.\")\n        else:\n            for grid in grid_paths.values():\n                # Use (glamt, gphit) coords for W-grids:\n                grid_suffix = cls._get_properties(grid=grid)\n                hgrid_type = grid_suffix if 'w' not in grid_suffix else 't'\n                # Indexing with a mask requires eager loading:\n                glam = cls[grid][f\"{dom_prefix}glam{hgrid_type}\"].load()\n                gphi = cls[grid][f\"{dom_prefix}gphi{hgrid_type}\"].load()\n\n                grid_clipped = cls[grid].dataset.where(\n                    (glam &gt;= bbox[0]) &amp;\n                    (glam &lt;= bbox[1]) &amp;\n                    (gphi &gt;= bbox[2]) &amp;\n                    (gphi &lt;= bbox[3]),\n                    drop=True\n                    )\n\n                d_dtypes = {var: cls[grid][var].dtype for var in cls[grid].dataset.data_vars}\n                for var, dtype in d_dtypes.items():\n                    if dtype in [np.int32, np.int64, bool]:\n                        grid_clipped[var] = grid_clipped[var].fillna(0).astype(dtype)\n\n                if bbox != (-180, 180, -90, 90):\n                    grid_clipped = grid_clipped.assign_attrs({\"iperio\": False})\n                cls[grid] = grid_clipped\n\n        return cls\n\n\n    def mask_with_polygon(\n        cls,\n        grid: str,\n        lon_poly: list | np.ndarray,\n        lat_poly: list | np.ndarray,\n    ):\n        \"\"\"\n        Create mask of NEMO model grid points contained within a polygon.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where longitude and latitude coordinates\n            are stored (e.g., '/gridT').\n        lon_poly : list | ndarray\n            Longitudes of closed polygon.\n        lat_poly : list | ndarray\n            Latitudes of closed polygon.\n\n        Returns\n        -------\n        xr.DataArray\n            Boolean mask identifying NEMO model grid points which are inside\n            the polygon.\n        \"\"\"\n        # -- Validate input -- #\n        if not isinstance(lon_poly, (np.ndarray, list)) or not isinstance(lat_poly, (np.ndarray, list)):\n            raise TypeError(\"longitude &amp; latitude coordinates of polygon must be numpy arrays or lists.\")\n        if (lon_poly[0] != lon_poly[-1]) or (lat_poly[0] != lat_poly[-1]):\n            raise ValueError(\"longitude &amp; latitude coordinates must form a closed polygon.\")\n        if grid not in list(cls.subtree):\n            raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n\n        # -- Get NEMO model grid properties -- #\n        dom, dom_prefix, _, grid_suffix = cls._get_properties(grid=grid, infer_dom=True)\n        hgrid_type = grid_suffix if 'w' not in grid_suffix else 't'\n        ijk_names = cls._get_ijk_names(grid=grid)\n        i_name, j_name = ijk_names['i'], ijk_names['j']\n\n        if dom == \".\":\n            lon_name = f\"glam{hgrid_type}\"\n            lat_name = f\"gphi{hgrid_type}\"\n        else:\n            lon_name = f\"{dom_prefix}glam{hgrid_type}\"\n            lat_name = f\"{dom_prefix}gphi{hgrid_type}\"\n\n        # -- Create mask using polygon coordinates -- #\n        mask = create_polygon_mask(lon_grid=cls[grid][lon_name],\n                                   lat_grid=cls[grid][lat_name],\n                                   lon_poly=lon_poly,\n                                   lat_poly=lat_poly,\n                                   dims=(j_name, i_name)\n                                   )\n\n        return mask\n\n\n    def masked_statistic(\n        cls, \n        grid : str,\n        var : str,\n        lon_poly : list | np.ndarray,\n        lat_poly : list | np.ndarray,\n        statistic : str,\n        dims : list\n        ) -&gt; xr.DataArray:\n        \"\"\"\n        Masked statistic of a variable defined on a NEMO model grid.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where variable is stored\n            (e.g., '/gridT').\n        var : str\n            Name of the variable to compute statistic.\n        lon_poly : list | np.ndarray\n            Longitudes of closed polygon.\n        lat_poly : list | np.ndarray\n            Latitudes of closed polygon.\n        statistic : str\n            Name of the statistic to calculate (e.g., 'mean', 'weighted_mean' 'sum').\n        dims : list\n            Dimensions over which to apply statistic (e.g., ['i', 'j']).\n\n        Returns\n        -------\n        xr.DataArray\n            Masked statistic of specified variable.\n        \"\"\"\n        # -- Validate input -- #\n        if grid not in list(cls.subtree):\n            raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n        if var not in cls[grid].data_vars:\n            raise KeyError(f\"variable '{var}' not found in grid '{grid}'.\")\n\n        # -- Create polygon mask using coordinates -- #\n        mask_poly = cls.mask_with_polygon(lon_poly=lon_poly,\n                                          lat_poly=lat_poly,\n                                          grid=grid\n                                          )\n\n        # -- Get NEMO model grid properties -- #\n        _, dom_prefix, dom_suffix, grid_suffix = cls._get_properties(grid=grid, infer_dom=True)\n\n        # -- Apply masks &amp; calculate statistic -- #\n        if f\"{dom_prefix}depth{grid_suffix}\" in cls[grid][var].coords:\n            # Apply 3-dimensional t/u/v/f/w mask:\n            dom_mask = cls[grid][f\"{grid_suffix}mask\"]\n        else:\n            # Apply 2-dimensional t/u/v/f mask (unique points):\n            hgrid_type = grid_suffix if 'w' not in grid_suffix else 't'\n            dom_mask = cls[grid][f\"{hgrid_type}maskutil\"]\n\n        da = cls[grid][var].where(dom_mask &amp; mask_poly)\n\n        match statistic:\n            case \"mean\":\n                result = da.mean(dim=dims, skipna=True)\n\n            case \"weighted_mean\":\n                weight_dims = [dim.replace(dom_suffix, \"\") for dim in dims]\n                weights = cls._get_weights(grid=grid, dims=weight_dims)\n                result = da.weighted(weights).mean(dim=dims, skipna=True)\n\n            case \"min\":\n                result = da.min(dim=dims, skipna=True)\n\n            case \"max\":\n                result = da.max(dim=dims, skipna=True)\n\n            case \"sum\":\n                result = da.sum(dim=dims, skipna=True)\n\n        return result\n\n\n    def extract_mask_boundary(\n        cls,\n        mask: xr.DataArray,\n        uv_vars: list = ['uo', 'vo'],\n        vars: list | None = None,\n        dom: str = '.',\n        ) -&gt; xr.Dataset:\n        \"\"\"\n        Extract the boundary of a masked region defined on a NEMO model grid.\n\n        Parameters\n        ----------\n        mask : xr.DataArray\n            Boolean mask identifying NEMO model grid points which\n            are inside the region of interest.\n        uv_vars : list, optional\n            Names of velocity variables to extract along the boundary.\n            Default is ['uo', 'vo'].\n        vars : list, optional\n            Names of scalar variables to extract along the boundary.\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n            Default is '.' for the parent domain.\n\n        Returns\n        -------\n        xr.Dataset\n            Dataset containing variables and NEMO model coordinates\n            extracted along the boundary of the mask.\n        \"\"\"\n        if not isinstance(mask, xr.DataArray):\n            raise ValueError(\"mask must be an xarray DataArray\")\n        if not isinstance(dom, str):\n            raise ValueError(\"dom must be a string specifying prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\")\n\n        # -- Get NEMO model grid properties -- #\n        dom_prefix, dom_suffix = cls._get_properties(dom=dom)\n        grid_paths = cls._get_grid_paths(dom=dom)\n        gridT, gridU, gridV = grid_paths['gridT'], grid_paths['gridU'], grid_paths['gridV']\n        ijk_names = cls._get_ijk_names(dom=dom)\n        k_name = ijk_names['k']\n\n        # -- Extract mask boundary -- #\n        if f'i{dom_suffix}' not in mask.dims or f'j{dom_suffix}' not in mask.dims:\n            raise ValueError(f\"mask must have dimensions f'i{dom_suffix}' and 'j{dom_suffix}'\")\n        i_bdy, j_bdy, flux_type, flux_dir = get_mask_boundary(mask)\n\n        # -- Construct boundary dataset -- #\n        time_name = [dim for dim in cls[gridU].dims if 'time' in dim][0]\n\n        ds = xr.Dataset(\n            data_vars={\n            'i_bdy': (['bdy'], i_bdy[::-1]),\n            'j_bdy': (['bdy'], j_bdy[::-1]),\n            'flux_type': (['bdy'], flux_type[::-1]),\n            'flux_dir': (['bdy'], flux_dir[::-1])\n            },\n            coords={\n            time_name: cls[gridU][time_name].values,\n            k_name: cls[gridU][k_name].values,\n            'bdy': np.arange(len(i_bdy)),\n            })\n\n        # Add velocities normal to boundary:\n        if uv_vars[0] not in cls[gridU].data_vars:\n            raise KeyError(f\"variable '{uv_vars[0]}' not found in grid '{gridU}'.\")\n        if uv_vars[1] not in cls[gridV].data_vars:\n            raise KeyError(f\"variable '{uv_vars[1]}' not found in grid '{gridV}'.\")\n\n        ubdy_mask = ds['flux_type'] == 'U'\n        vbdy_mask = ds['flux_type'] == 'V'\n\n        dim_sizes = [cls[gridU][time_name].size, cls[gridU][k_name].size, ds[\"bdy\"].size]\n\n        ds['velocity'] = xr.DataArray(data=dask.array.zeros(dim_sizes), dims=[time_name, k_name, 'bdy'])\n        ds['velocity'][:, :, ubdy_mask] = cls[gridU]['uo'].where(cls[gridU]['umask']).sel(i=ds['i_bdy'][ubdy_mask], j=ds['j_bdy'][ubdy_mask]) * ds['flux_dir'][ubdy_mask]\n        ds['velocity'][:, :, vbdy_mask] = cls[gridV]['vo'].where(cls[gridV]['vmask']).sel(i=ds['i_bdy'][vbdy_mask], j=ds['j_bdy'][vbdy_mask]) * ds['flux_dir'][vbdy_mask]\n\n        ds = ds.assign_coords({f\"{dom_prefix}glamb\": (['bdy'], np.zeros(ds[\"bdy\"].size)),\n                               f\"{dom_prefix}gphib\": (['bdy'], np.zeros(ds[\"bdy\"].size)),\n                               f\"{dom_prefix}depthb\": ((k_name, 'bdy'), np.zeros(dim_sizes[1:])),\n                               })\n\n        ds[f\"{dom_prefix}glamb\"][ubdy_mask] = cls[gridU]['glamu'].sel(i=ds['i_bdy'][ubdy_mask], j=ds['j_bdy'][ubdy_mask])\n        ds[f\"{dom_prefix}glamb\"][vbdy_mask] = cls[gridV]['glamv'].sel(i=ds['i_bdy'][vbdy_mask], j=ds['j_bdy'][vbdy_mask])\n\n        ds[f\"{dom_prefix}gphib\"][ubdy_mask] = cls[gridU]['gphiu'].sel(i=ds['i_bdy'][ubdy_mask], j=ds['j_bdy'][ubdy_mask])\n        ds[f\"{dom_prefix}gphib\"][vbdy_mask] = cls[gridV]['gphiv'].sel(i=ds['i_bdy'][vbdy_mask], j=ds['j_bdy'][vbdy_mask])\n\n        ds[f\"{dom_prefix}depthb\"][:, ubdy_mask] = cls[gridU]['depthu']\n        ds[f\"{dom_prefix}depthb\"][:, vbdy_mask] = cls[gridV]['depthv']\n\n        if vars is not None:\n            # Add scalar variables along the boundary:\n            for var in vars:\n                if var in cls[gridT].data_vars:\n                    ds[var] = xr.DataArray(data=dask.array.zeros(dim_sizes), dims=[time_name, k_name, 'bdy'])\n                else:\n                    raise KeyError(f\"variable {var} not found in grid '{gridT}'.\")\n\n                # Linearly interpolate scalar variables onto NEMO model U/V grid points:\n                ds[var][:, :, ubdy_mask] = 0.5 * (\n                    cls[gridT][var].where(cls[gridT]['tmask']).sel(i=ds['i_bdy'][ubdy_mask] - 0.5, j=ds['j_bdy'][ubdy_mask]) +\n                    cls[gridT][var].where(cls[gridT]['tmask']).sel(i=ds['i_bdy'][ubdy_mask] + 0.5, j=ds['j_bdy'][ubdy_mask])\n                    )\n                ds[var][:, :, vbdy_mask] = 0.5 * (\n                    cls[gridT][var].where(cls[gridT]['tmask']).sel(i=ds['i_bdy'][vbdy_mask], j=ds['j_bdy'][vbdy_mask] - 0.5) +\n                    cls[gridT][var].where(cls[gridT]['tmask']).sel(i=ds['i_bdy'][vbdy_mask], j=ds['j_bdy'][vbdy_mask] + 0.5)\n                    )\n\n        return ds\n\n\n    def binned_statistic(\n        cls,\n        grid : str,\n        vars : list[str],\n        values : str,\n        keep_dims : list[str] | None,\n        bins : list[list | np.ndarray],\n        statistic : str,\n        mask : xr.DataArray | None\n        ) -&gt; xr.DataArray:\n        \"\"\"\n        Calculate binned statistic of a variable defined on a NEMO model grid.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where variables and values are stored\n            (e.g., '/gridT').\n        vars : list[str]\n            Names of variable(s) to be grouped in discrete bins.\n        values : str\n            Name of the values with which to calculate binned statistic.\n        keep_dims : list[str] | None\n            Names of dimensions in values to keep as labels in binned statistic.\n        bins : list[list | np.ndarray]\n            Bin edges used to group each of the variables in `vars`.\n        statistic : str\n            Statistic to calculate (e.g., 'count', 'sum', 'nansum', 'mean', 'nanmean',\n            'max', 'nanmax', 'min', 'nanmin'). See flox.xarray.xarray_reduce for a\n            complete list of aggregation statistics.\n        mask : xr.DataArray | None\n            Boolean mask identifying NEMO model grid points to be included (1)\n            or neglected (0) from calculation.\n\n        Returns\n        -------\n        xr.DataArray\n            Values of the selected statistic in each bin.\n        \"\"\"\n        # -- Validate input -- #\n        if grid not in list(cls.subtree):\n            raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n        if any(var not in cls[grid].data_vars for var in vars):\n            raise KeyError(f\"one or more variables {vars} not found in grid '{grid}'.\")\n        if values not in cls[grid].data_vars:\n            raise KeyError(f\"values '{values}' not found in grid '{grid}'.\")\n        if keep_dims is not None:\n            if any(dim not in cls[grid][values].dims for dim in keep_dims):\n                raise KeyError(f\"one or more dimensions {keep_dims} not found in values '{values}'.\")\n        if not all(isinstance(bin, (list, np.ndarray)) for bin in bins):\n            raise ValueError(\"bins must be a list of lists or numpy arrays.\")\n        if statistic not in [\"all\", \"any\", \"count\", \"sum\", \"nansum\", \"mean\", \"nanmean\", \"max\",\n                            \"nanmax\", \"min\", \"nanmin\", \"argmax\", \"nanargmax\", \"argmin\",\n                            \"nanargmin\", \"quantile\", \"nanquantile\", \"median\", \"nanmedian\",\n                            \"mode\", \"nanmode\", \"first\", \"nanfirst\", \"last\", \"nanlast\"]:\n            raise ValueError(f\"statistic '{statistic}' is not supported.\")\n        if mask is not None:\n            if not isinstance(mask, xr.DataArray):\n                raise ValueError(\"mask must be an xarray.DataArray.\")\n            if mask.dtype != bool:\n                raise TypeError(\"mask dtype must be boolean.\")\n            if any(dim not in cls[grid].dims for dim in mask.dims):\n                raise ValueError(f\"mask must have dimensions subset from {cls[grid].dims}.\")\n\n        # -- Get NEMO model grid properties -- #\n        _, dom_prefix, _, grid_suffix = cls._get_properties(grid=grid, infer_dom=True)\n\n        # -- Define input variables &amp; apply grid mask -- #\n        if f\"{dom_prefix}depth{grid_suffix}\" in cls[grid][values].coords:\n            # Apply 3-dimensional t/u/v/f/w mask:\n            dom_mask = cls[grid][f\"{grid_suffix}mask\"]\n        else:\n            # Apply 2-dimensional t/u/v/f mask (unique points):\n            hgrid_type = grid_suffix if 'w' not in grid_suffix else 't'\n            dom_mask = cls[grid][f\"{hgrid_type}maskutil\"]\n\n        values_data = cls[grid][values].where(mask &amp; dom_mask) if mask is not None else cls[grid][values].where(dom_mask)\n        var_data = [cls[grid][var].where(mask &amp; dom_mask) if mask is not None else cls[grid][var].where(dom_mask) for var in vars]\n        keep_vars_data = [cls[grid][dim] for dim in keep_dims]\n\n        expected_groups = [None for _ in keep_dims]\n        expected_groups.extend(bin for bin in bins)\n\n        isbin = [False for _ in keep_dims]\n        isbin.extend(True for _ in bins)\n\n        # -- Calculate binned statistics -- #\n        da = xarray_reduce(\n            *[values_data, *keep_vars_data, *var_data],\n            func=statistic,\n            expected_groups=tuple(expected_groups),\n            isbin=tuple(isbin),\n            method=\"map-reduce\",\n            fill_value=np.nan, # Fill missing values with NaN.\n            reindex=False, # Do not reindex during block aggregations to reduce memory at cost of performance.\n            engine='numbagg' # Use numbagg grouped aggregations.\n            )\n\n        # -- Update binned dimensions -- #\n        # Transform coords from pd.IntervalIndex to interval mid-points:\n        coord_dict = {f'{var}_bins': np.array([interval.mid for interval in da[f'{var}_bins'].values]) for var in vars}\n        result = da.assign_coords(coord_dict)\n\n        return result\n\n\n    def transform_vertical_grid(\n        cls,\n        grid: str,\n        var: str,\n        e3_new: xr.DataArray\n    ) -&gt; xr.Dataset:\n        \"\"\"\n        Transform variable defined on a NEMO model grid to a new vertical grid using conservative interpolation.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where variable is stored\n            (e.g., '/gridT').\n        var : str\n            Name of the variable to transform.\n        e3_new : xarray.DataArray\n            Grid cell thicknesses of the new vertical grid.\n            Must be a 1-dimensional xarray.DataArray with\n            dimension 'k_new'.\n\n        Returns\n        -------\n        tuple[xr.DataArray, xr.DataArray]\n            Values of variable defined at the centre of each vertical\n            grid cell on the new grid, and vertical grid cell\n            thicknesses adjusted for model bathymetry.\n        \"\"\"\n        # -- Validate input -- #\n        if grid not in list(cls.subtree):\n            raise KeyError(f\"Grid '{grid}' not found in the NEMODataTree.\")\n        if var not in cls[grid].data_vars:\n            raise KeyError(f\"Variable '{var}' not found in grid '{grid}'.\")\n        if e3_new.dims != ('k_new',) or (e3_new.ndim != 1):\n            raise ValueError(\"e3_new must be a 1-dimensional xarray.DataArray with dimension 'k_new'.\")\n\n        # -- Get NEMO model grid properties -- #\n        dom, _, _, grid_suffix = cls._get_properties(grid=grid, infer_dom=True)\n        ijk_names = cls._get_ijk_names(dom=dom)\n        i_name, j_name, k_name = ijk_names['i'], ijk_names['j'], ijk_names['k']\n\n        # -- Define input variables -- #\n        mask = cls[grid][f\"{grid_suffix}mask\"]\n\n        var_in = cls[grid][var].where(mask)\n        e3_in = cls[grid][f\"e3{grid_suffix}\"].where(mask)\n        if e3_new.sum(dim=\"k_new\") &lt; cls[grid][f\"depth{grid_suffix}\"].max(dim=k_name):\n            raise ValueError(f\"e3_new must sum to at least the maximum depth ({cls[grid][f\"depth{grid_suffix}\"].max(dim=k_name).item()} m) of the original vertical grid.\")\n\n        # -- Transform variable to target vertical grid -- #\n        var_out, e3_out = xr.apply_ufunc(transform_vertical_coords,\n                                         e3_in,\n                                         var_in,\n                                         e3_new.astype(e3_in.dtype),\n                                         input_core_dims=[[k_name], [k_name], [\"k_new\"]],\n                                         output_core_dims=[[\"k_new\"], [\"k_new\"]],\n                                         dask=\"allowed\"\n                                         )\n\n        # -- Create transformed variable Dataset -- #\n        t_name = var_in.dims[0]\n        var_out = var_out.transpose(t_name, \"k_new\", j_name, i_name)\n\n        ds_out = xr.Dataset(\n            data_vars={var: var_out, f\"e3{grid_suffix}_new\": e3_out},\n            coords={f\"depth{grid_suffix}_new\": (\"k_new\", e3_new.cumsum(dim=\"k_new\").data)}\n            )\n\n        return ds_out\n\n\n    def transform_scalar_to(\n        cls,\n        grid: str,\n        var: str,\n        to: str\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Transform scalar variable defined on a NEMO model grid to a neighbouring horizontal grid using linear interpolation.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where variable is stored\n            (e.g., '/gridT').\n        var : str\n            Name of the variable to transform.\n        to : str\n            Suffix of the neighbouring horizontal NEMO model grid to\n            transform variable to. Options are 'U', 'V'.\n\n        Returns\n        -------\n        xr.DataArray\n            Values of variable linearly interpolated onto a neighbouring\n            horizontal grid.\n        \"\"\"\n        # -- Validate input -- #\n        if grid not in list(cls.subtree):\n            raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n        if var not in cls[grid].data_vars:\n            raise KeyError(f\"variable '{var}' not found in grid '{grid}'.\")\n        if not isinstance(to, str):\n            raise TypeError(f\"'to' must be a string, got {type(to)}.\")\n        if to not in ['U', 'V']:\n            raise ValueError(f\"'to' must be one of ['U', 'V'], got {to}.\")\n\n        # -- Get NEMO model grid properties -- #\n        ijk_names = cls._get_ijk_names(grid=grid)\n        i_name, j_name = ijk_names['i'], ijk_names['j']\n\n        fill_dim_name = \"i\" if to == \"U\" else \"j\"\n        target_grid = f\"{grid.replace(grid[-1], to)}\"\n        target_mask = f\"{to.lower()}mask\"\n\n        # -- Perform interpolation -- #\n        result = (cls[grid][var]\n                  .interpolate_na(dim=fill_dim_name, method='nearest', fill_value=\"extrapolate\")\n                  .interp({i_name: cls[grid.replace(grid[-1], to)][i_name],\n                           j_name: cls[grid.replace(grid[-1], to)][j_name]},\n                           method='linear')\n                  .where(cls[target_grid][target_mask])\n                  )\n\n        return result\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.__init__","title":"__init__","text":"<pre><code>__init__(*args, **kwargs)\n</code></pre> <p>Create a single node of a NEMODataTree.</p> <p>The node may optionally contain data in the form of data and coordinate variables, stored in the same way as data is stored in an <code>xarray.Dataset</code>.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>tuple</code> <p>Positional arguments to pass to the parent class.</p> <code>()</code> <code>**kwargs</code> <code>dict</code> <p>Keyword arguments to pass to the parent class.</p> <code>{}</code> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Create a single node of a NEMODataTree.\n\n    The node may optionally contain data in the form of data\n    and coordinate variables, stored in the same way as data\n    is stored in an `xarray.Dataset`.\n\n    Parameters\n    ----------\n    *args : tuple\n        Positional arguments to pass to the parent class.\n    **kwargs : dict\n        Keyword arguments to pass to the parent class.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.binned_statistic","title":"binned_statistic","text":"<pre><code>binned_statistic(grid, vars, values, keep_dims, bins, statistic, mask)\n</code></pre> <p>Calculate binned statistic of a variable defined on a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where variables and values are stored (e.g., '/gridT').</p> required <code>vars</code> <code>list[str]</code> <p>Names of variable(s) to be grouped in discrete bins.</p> required <code>values</code> <code>str</code> <p>Name of the values with which to calculate binned statistic.</p> required <code>keep_dims</code> <code>list[str] | None</code> <p>Names of dimensions in values to keep as labels in binned statistic.</p> required <code>bins</code> <code>list[list | ndarray]</code> <p>Bin edges used to group each of the variables in <code>vars</code>.</p> required <code>statistic</code> <code>str</code> <p>Statistic to calculate (e.g., 'count', 'sum', 'nansum', 'mean', 'nanmean', 'max', 'nanmax', 'min', 'nanmin'). See flox.xarray.xarray_reduce for a complete list of aggregation statistics.</p> required <code>mask</code> <code>DataArray | None</code> <p>Boolean mask identifying NEMO model grid points to be included (1) or neglected (0) from calculation.</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Values of the selected statistic in each bin.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def binned_statistic(\n    cls,\n    grid : str,\n    vars : list[str],\n    values : str,\n    keep_dims : list[str] | None,\n    bins : list[list | np.ndarray],\n    statistic : str,\n    mask : xr.DataArray | None\n    ) -&gt; xr.DataArray:\n    \"\"\"\n    Calculate binned statistic of a variable defined on a NEMO model grid.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where variables and values are stored\n        (e.g., '/gridT').\n    vars : list[str]\n        Names of variable(s) to be grouped in discrete bins.\n    values : str\n        Name of the values with which to calculate binned statistic.\n    keep_dims : list[str] | None\n        Names of dimensions in values to keep as labels in binned statistic.\n    bins : list[list | np.ndarray]\n        Bin edges used to group each of the variables in `vars`.\n    statistic : str\n        Statistic to calculate (e.g., 'count', 'sum', 'nansum', 'mean', 'nanmean',\n        'max', 'nanmax', 'min', 'nanmin'). See flox.xarray.xarray_reduce for a\n        complete list of aggregation statistics.\n    mask : xr.DataArray | None\n        Boolean mask identifying NEMO model grid points to be included (1)\n        or neglected (0) from calculation.\n\n    Returns\n    -------\n    xr.DataArray\n        Values of the selected statistic in each bin.\n    \"\"\"\n    # -- Validate input -- #\n    if grid not in list(cls.subtree):\n        raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n    if any(var not in cls[grid].data_vars for var in vars):\n        raise KeyError(f\"one or more variables {vars} not found in grid '{grid}'.\")\n    if values not in cls[grid].data_vars:\n        raise KeyError(f\"values '{values}' not found in grid '{grid}'.\")\n    if keep_dims is not None:\n        if any(dim not in cls[grid][values].dims for dim in keep_dims):\n            raise KeyError(f\"one or more dimensions {keep_dims} not found in values '{values}'.\")\n    if not all(isinstance(bin, (list, np.ndarray)) for bin in bins):\n        raise ValueError(\"bins must be a list of lists or numpy arrays.\")\n    if statistic not in [\"all\", \"any\", \"count\", \"sum\", \"nansum\", \"mean\", \"nanmean\", \"max\",\n                        \"nanmax\", \"min\", \"nanmin\", \"argmax\", \"nanargmax\", \"argmin\",\n                        \"nanargmin\", \"quantile\", \"nanquantile\", \"median\", \"nanmedian\",\n                        \"mode\", \"nanmode\", \"first\", \"nanfirst\", \"last\", \"nanlast\"]:\n        raise ValueError(f\"statistic '{statistic}' is not supported.\")\n    if mask is not None:\n        if not isinstance(mask, xr.DataArray):\n            raise ValueError(\"mask must be an xarray.DataArray.\")\n        if mask.dtype != bool:\n            raise TypeError(\"mask dtype must be boolean.\")\n        if any(dim not in cls[grid].dims for dim in mask.dims):\n            raise ValueError(f\"mask must have dimensions subset from {cls[grid].dims}.\")\n\n    # -- Get NEMO model grid properties -- #\n    _, dom_prefix, _, grid_suffix = cls._get_properties(grid=grid, infer_dom=True)\n\n    # -- Define input variables &amp; apply grid mask -- #\n    if f\"{dom_prefix}depth{grid_suffix}\" in cls[grid][values].coords:\n        # Apply 3-dimensional t/u/v/f/w mask:\n        dom_mask = cls[grid][f\"{grid_suffix}mask\"]\n    else:\n        # Apply 2-dimensional t/u/v/f mask (unique points):\n        hgrid_type = grid_suffix if 'w' not in grid_suffix else 't'\n        dom_mask = cls[grid][f\"{hgrid_type}maskutil\"]\n\n    values_data = cls[grid][values].where(mask &amp; dom_mask) if mask is not None else cls[grid][values].where(dom_mask)\n    var_data = [cls[grid][var].where(mask &amp; dom_mask) if mask is not None else cls[grid][var].where(dom_mask) for var in vars]\n    keep_vars_data = [cls[grid][dim] for dim in keep_dims]\n\n    expected_groups = [None for _ in keep_dims]\n    expected_groups.extend(bin for bin in bins)\n\n    isbin = [False for _ in keep_dims]\n    isbin.extend(True for _ in bins)\n\n    # -- Calculate binned statistics -- #\n    da = xarray_reduce(\n        *[values_data, *keep_vars_data, *var_data],\n        func=statistic,\n        expected_groups=tuple(expected_groups),\n        isbin=tuple(isbin),\n        method=\"map-reduce\",\n        fill_value=np.nan, # Fill missing values with NaN.\n        reindex=False, # Do not reindex during block aggregations to reduce memory at cost of performance.\n        engine='numbagg' # Use numbagg grouped aggregations.\n        )\n\n    # -- Update binned dimensions -- #\n    # Transform coords from pd.IntervalIndex to interval mid-points:\n    coord_dict = {f'{var}_bins': np.array([interval.mid for interval in da[f'{var}_bins'].values]) for var in vars}\n    result = da.assign_coords(coord_dict)\n\n    return result\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.cell_area","title":"cell_area","text":"<pre><code>cell_area(grid, dim)\n</code></pre> <p>Calculate grid cell areas orthogonal to a given dimension of a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid from which to calculate grid cell areas (e.g., '/gridT').</p> required <code>dim</code> <code>str</code> <p>Dimension orthogonal to grid cell area to calculate (e.g., 'k' returns e1 * e2).</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Grid cell areas (m^2) for the specified NEMO model grid.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def cell_area(\n    cls,\n    grid: str,\n    dim: str,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Calculate grid cell areas orthogonal to a given dimension of a NEMO model grid.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid from which to calculate\n        grid cell areas (e.g., '/gridT').\n    dim : str\n        Dimension orthogonal to grid cell area to\n        calculate (e.g., 'k' returns e1 * e2).\n\n    Returns\n    -------\n    xr.DataArray\n        Grid cell areas (m^2) for the specified NEMO model grid.\n    \"\"\"\n    grid_suffix = cls._get_properties(grid=grid)\n\n    if dim not in ['i', 'j', 'k']:\n        raise ValueError(f\"dim {dim} must be one of ['i', 'j', 'k'].\")\n\n    match dim:\n        case 'i':\n            cell_area = cls[grid][f'e3{grid_suffix}'] * cls[grid][f'e2{grid_suffix}']\n        case 'j':\n            cell_area = cls[grid][f'e3{grid_suffix}'] * cls[grid][f'e1{grid_suffix}']\n        case 'k':\n            cell_area = cls[grid][f'e1{grid_suffix}'] * cls[grid][f'e2{grid_suffix}']\n    cell_area.name = \"areacello\"\n\n    return cell_area\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.cell_volume","title":"cell_volume","text":"<pre><code>cell_volume(grid)\n</code></pre> <p>Calculate grid cell volumes for a given NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid from which to calculate grid cell volumes (e.g., '/gridT').</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Grid cell volumes for the specified NEMO model grid.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def cell_volume(\n    cls,\n    grid: str\n) -&gt; xr.DataArray:\n    \"\"\"\n    Calculate grid cell volumes for a given NEMO model grid.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid from which to calculate\n        grid cell volumes (e.g., '/gridT').\n\n    Returns\n    -------\n    xr.DataArray\n        Grid cell volumes for the specified NEMO model grid.\n    \"\"\"\n    grid_suffix = cls._get_properties(grid=grid)\n\n    mask = cls[grid][f\"{grid_suffix}mask\"]\n\n    cell_volume = cls[grid][f\"e3{grid_suffix}\"].where(mask) * cls[grid][f\"e1{grid_suffix}\"] * cls[grid][f\"e2{grid_suffix}\"]\n    cell_volume.name = \"volcello\"\n\n    return cell_volume\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.clip_domain","title":"clip_domain","text":"<pre><code>clip_domain(dom, bbox)\n</code></pre> <p>Clip a NEMO model domain to specified longitude and latitude range.</p> <p>Parameters:</p> Name Type Description Default <code>dom</code> <code>str</code> <p>Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.). Default is '.' for the parent domain.</p> required <code>bbox</code> <code>tuple</code> <p>Bounding box to clip to (lon_min, lon_max, lat_min, lat_max).</p> required <p>Returns:</p> Type Description <code>NEMODataTree</code> <p>NEMO DataTree with specified model domain clipped to bounding box.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def clip_domain(\n    cls,\n    dom: str,\n    bbox: tuple,\n    ) -&gt; Self:\n    \"\"\"\n    Clip a NEMO model domain to specified longitude and latitude range.\n\n    Parameters\n    ----------\n    dom : str\n        Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        Default is '.' for the parent domain.\n    bbox : tuple\n        Bounding box to clip to (lon_min, lon_max, lat_min, lat_max).\n\n    Returns\n    -------\n    NEMODataTree\n        NEMO DataTree with specified model domain clipped to bounding box.\n    \"\"\"\n    if not isinstance(dom, str):\n        raise ValueError(\"dom must be a string specifying the prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\")\n    if not isinstance(bbox, tuple) or len(bbox) != 4:\n        raise ValueError(\"bounding box must be a tuple: (lon_min, lon_max, lat_min, lat_max).\")\n\n    # -- Get NEMO model grid properties -- #\n    dom_prefix, _ = cls._get_properties(dom=dom)\n    grid_paths = cls._get_grid_paths(dom=dom)\n\n    # -- Clip grids to given bounding box -- #\n    if not grid_paths:\n        raise ValueError(f\"NEMO model domain '{dom}' not found in the DataTree.\")\n    else:\n        for grid in grid_paths.values():\n            # Use (glamt, gphit) coords for W-grids:\n            grid_suffix = cls._get_properties(grid=grid)\n            hgrid_type = grid_suffix if 'w' not in grid_suffix else 't'\n            # Indexing with a mask requires eager loading:\n            glam = cls[grid][f\"{dom_prefix}glam{hgrid_type}\"].load()\n            gphi = cls[grid][f\"{dom_prefix}gphi{hgrid_type}\"].load()\n\n            grid_clipped = cls[grid].dataset.where(\n                (glam &gt;= bbox[0]) &amp;\n                (glam &lt;= bbox[1]) &amp;\n                (gphi &gt;= bbox[2]) &amp;\n                (gphi &lt;= bbox[3]),\n                drop=True\n                )\n\n            d_dtypes = {var: cls[grid][var].dtype for var in cls[grid].dataset.data_vars}\n            for var, dtype in d_dtypes.items():\n                if dtype in [np.int32, np.int64, bool]:\n                    grid_clipped[var] = grid_clipped[var].fillna(0).astype(dtype)\n\n            if bbox != (-180, 180, -90, 90):\n                grid_clipped = grid_clipped.assign_attrs({\"iperio\": False})\n            cls[grid] = grid_clipped\n\n    return cls\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.clip_grid","title":"clip_grid","text":"<pre><code>clip_grid(grid, bbox)\n</code></pre> <p>Clip a NEMO model grid to specified longitude and latitude range.</p> <p>Parameters:</p> Name Type Description Default <code>Path</code> required <code>bbox</code> <code>tuple</code> <p>Bounding box to clip to (lon_min, lon_max, lat_min, lat_max).</p> required <p>Returns:</p> Type Description <code>NEMODataTree</code> <p>NEMO DataTree with specified model grid clipped to bounding box.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def clip_grid(\n    cls,\n    grid: str,\n    bbox: tuple,\n) -&gt; Self:\n    \"\"\"\n    Clip a NEMO model grid to specified longitude and latitude range.\n\n    Parameters\n    ----------\n    Path to NEMO model grid to clip (e.g., '/gridT').\n    bbox : tuple\n        Bounding box to clip to (lon_min, lon_max, lat_min, lat_max).\n\n    Returns\n    -------\n    NEMODataTree\n        NEMO DataTree with specified model grid clipped to bounding box.\n    \"\"\"\n    if grid not in list(cls.subtree):\n        raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n    if not isinstance(bbox, tuple) or len(bbox) != 4:\n        raise ValueError(\"bounding box must be a tuple (lon_min, lon_max, lat_min, lat_max).\")\n\n    # -- Get NEMO model grid properties -- #\n    _, dom_prefix, _, grid_suffix = cls._get_properties(grid=grid, infer_dom=True)\n    hgrid_type = grid_suffix if 'w' not in grid_suffix else 't'\n\n    # -- Clip the grid to given bounding box -- #\n    # Indexing with a mask requires loading coords into memory:\n    glam = cls[grid][f\"{dom_prefix}glam{hgrid_type}\"].load()\n    gphi = cls[grid][f\"{dom_prefix}gphi{hgrid_type}\"].load()\n\n    grid_clipped = cls[grid].dataset.where(\n        (glam &gt;= bbox[0]) &amp;\n        (glam &lt;= bbox[1]) &amp;\n        (gphi &gt;= bbox[2]) &amp;\n        (gphi &lt;= bbox[3]),\n        drop=True\n        )\n\n    d_dtypes = {var: cls[grid][var].dtype for var in cls[grid].dataset.data_vars}\n    for var, dtype in d_dtypes.items():\n        if dtype in [np.int32, np.int64, bool]:\n            grid_clipped[var] = grid_clipped[var].fillna(0).astype(dtype)\n\n    if bbox != (-180, 180, -90, 90):\n        grid_clipped = grid_clipped.assign_attrs({\"iperio\": False})\n    cls[grid] = grid_clipped\n\n    return cls\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.curl","title":"curl","text":"<pre><code>curl(vars, dom='.')\n</code></pre> <p>Calculate the vertical (k) curl component of a vector field on a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>vars</code> <code>list[str]</code> <p>Name of the vector variables, structured as: ['u', 'v'], where 'u' and 'v' are the i and j components of the vector field, respectively.</p> required <code>dom</code> <code>str</code> <p>Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.). Default is '.' for the parent domain.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Vertical curl component of vector field defined on a NEMO model grid.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def curl(\n    cls,\n    vars : list[str],\n    dom: str = '.',\n) -&gt; xr.DataArray:\n    \"\"\"\n    Calculate the vertical (k) curl component of a vector field on a NEMO model grid.\n\n    Parameters\n    ----------\n    vars : list[str]\n        Name of the vector variables, structured as: ['u', 'v'], where 'u' and 'v' are\n        the i and j components of the vector field, respectively.\n    dom : str, optional\n        Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        Default is '.' for the parent domain.\n\n    Returns\n    -------\n    xr.DataArray\n        Vertical curl component of vector field defined on a NEMO model grid.\n    \"\"\"\n    # -- Validate input -- #\n    if not isinstance(vars, list) or len(vars) != 2:\n        raise ValueError(\"vars must be a list of two elements structured as ['u', 'v'].\")\n    if not isinstance(dom, str):\n        raise ValueError(\"dom must be a string specifying the prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\")\n\n    # -- Get NEMO model grid properties -- #\n    dom_prefix, _ = cls._get_properties(dom=dom)\n    grid_paths = cls._get_grid_paths(dom=dom)\n    gridU, gridV, gridF = grid_paths['gridU'], grid_paths['gridV'], grid_paths['gridF']\n    ijk_names = cls._get_ijk_names(dom=dom)\n    i_name, j_name = ijk_names['i'], ijk_names['j']\n\n    # -- Define i,j vector components -- #\n    var_i, var_j = vars[0], vars[1]\n    if var_i not in cls[gridU].data_vars:\n        raise KeyError(f\"variable '{var_i}' not found in grid '{gridU}'.\")\n    if var_j not in cls[gridV].data_vars:\n        raise KeyError(f\"variable '{var_j}' not found in grid '{gridV}'.\")\n\n    da_i = cls[gridU][var_i]\n    da_j = cls[gridV][var_j]\n\n    # -- Collect mask -- #\n    if (f\"{dom_prefix}depthu\" in da_i.coords) &amp; (f\"{dom_prefix}depthv\" in da_j.coords):\n        # 3-dimensional fmask\n        fmask = cls[gridF][\"fmask\"]\n    else:\n        # 2-dimensional fmask (unique points):\n        fmask = cls[gridF][\"fmaskutil\"]\n\n    # -- Neglecting the final F-grid points along i, j dimensions -- #\n    e1f = cls[gridF][\"e1f\"].isel({i_name: slice(None, -1), j_name: slice(None, -1)})\n    e2f = cls[gridF][\"e2f\"].isel({i_name: slice(None, -1), j_name: slice(None, -1)})\n\n    e1u = cls[gridU][\"e1u\"]\n    e2v = cls[gridV][\"e2v\"]\n\n    # -- Calculate vertical curl component on F-points -- #\n    dvar_i = (e2v * da_j).diff(dim=i_name, label=\"lower\")\n    dvar_i.coords[i_name] = dvar_i.coords[i_name] + 0.5\n\n    dvar_j = (e1u * da_i).diff(dim=j_name, label=\"lower\")\n    dvar_j.coords[j_name] = dvar_j.coords[j_name] + 0.5\n\n    curl = (1 / (e1f * e2f)) * (dvar_i - dvar_j).where(fmask)\n\n    # -- Update DataArray properties -- #\n    curl.name = f\"curl_{var_i}_{var_j}\"\n    curl = curl.drop_vars([f\"{dom_prefix}glamu\", f\"{dom_prefix}gphiu\",\n                           f\"{dom_prefix}glamv\", f\"{dom_prefix}gphiv\",\n                           ])\n\n    return curl\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.divergence","title":"divergence","text":"<pre><code>divergence(vars, dom='.')\n</code></pre> <p>Calculate the horizontal divergence of a vector field defined on a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>vars</code> <code>list[str]</code> <p>Name of vector variables, structured as: ['u', 'v'], where 'u' and 'v' are the i and j components of the vector field, respectively.</p> required <code>dom</code> <code>str</code> <p>Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.). Default is '.' for the parent domain.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Horizontal divergence of vector field defined on a NEMO model grid.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def divergence(\n    cls,\n    vars : list[str],\n    dom: str = '.',\n) -&gt; xr.DataArray:\n    \"\"\"\n    Calculate the horizontal divergence of a vector field defined on a NEMO model grid.\n\n    Parameters\n    ----------\n    vars : list[str]\n        Name of vector variables, structured as: ['u', 'v'], where\n        'u' and 'v' are the i and j components of the vector field,\n        respectively.\n    dom : str, optional\n        Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        Default is '.' for the parent domain.\n\n    Returns\n    -------\n    xr.DataArray\n        Horizontal divergence of vector field defined on a NEMO model grid.\n    \"\"\"\n    # -- Validate input -- #\n    if not isinstance(vars, list) or len(vars) != 2:\n        raise ValueError(\"vars must be a list of two elements structured as ['u', 'v'].\")\n    if not isinstance(dom, str):\n        raise ValueError(\"dom must be a string specifying the prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\")\n\n    # -- Get NEMO model grid properties -- #\n    dom_prefix, _ = cls._get_properties(dom=dom)\n    grid_paths = cls._get_grid_paths(dom=dom)\n    gridT, gridU, gridV = grid_paths['gridT'], grid_paths['gridU'], grid_paths['gridV']\n    ijk_names = cls._get_ijk_names(dom=dom)\n    i_name, j_name = ijk_names['i'], ijk_names['j']\n\n    # -- Define i,j vector components -- #\n    var_i, var_j = vars[0], vars[1]\n    if var_i not in cls[gridU].data_vars:\n        raise KeyError(f\"variable '{var_i}' not found in grid '{gridU}'.\")\n    if var_j not in cls[gridV].data_vars:\n        raise KeyError(f\"variable '{var_j}' not found in grid '{gridV}'.\")\n\n    da_i = cls[gridU][var_i]\n    da_j = cls[gridV][var_j]\n\n    # -- Collect mask -- #\n    if (f\"{dom_prefix}depthu\" in da_i.coords) &amp; (f\"{dom_prefix}depthv\" in da_j.coords):\n        # 3-dimensional tmask:\n        tmask = cls[gridT][\"tmask\"]\n    else:\n        # 2-dimensional tmask (unique points):\n        tmask = cls[gridT][\"tmaskutil\"]\n\n    # -- Neglecting the first T-grid points along i, j dimensions -- #\n    e1t = cls[gridT][\"e1t\"].isel({i_name: slice(1, None), j_name: slice(1, None)})\n    e2t = cls[gridT][\"e2t\"].isel({i_name: slice(1, None), j_name: slice(1, None)})\n    e3t = cls[gridT][\"e3t\"].isel({i_name: slice(1, None), j_name: slice(1, None)})\n\n    e2u, e3u = cls[gridU][\"e2u\"], cls[gridU][\"e3u\"]\n    e1v, e3v = cls[gridV][\"e1v\"], cls[gridV][\"e3v\"]\n\n    # -- Calculate divergence on T-points -- #\n    dvar_i = (e2u * e3u * da_i).diff(dim=i_name, label=\"lower\")\n    dvar_i.coords[i_name] = dvar_i.coords[i_name] + 0.5\n\n    dvar_j = (e1v * e3v * da_j).diff(dim=j_name, label=\"lower\")\n    dvar_j.coords[j_name] = dvar_j.coords[j_name] + 0.5\n\n    divergence = (1 / (e1t * e2t * e3t)) * (dvar_i + dvar_j).where(tmask)\n\n    # -- Update DataArray properties -- #\n    divergence.name = f\"div_{var_i}_{var_j}\"\n    divergence = divergence.drop_vars([f\"{dom_prefix}glamu\", f\"{dom_prefix}gphiu\",\n                                       f\"{dom_prefix}glamv\", f\"{dom_prefix}gphiv\",\n                                       f\"{dom_prefix}depthu\", f\"{dom_prefix}depthv\"\n                                       ])\n\n    return divergence\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.extract_mask_boundary","title":"extract_mask_boundary","text":"<pre><code>extract_mask_boundary(mask, uv_vars=['uo', 'vo'], vars=None, dom='.')\n</code></pre> <p>Extract the boundary of a masked region defined on a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>DataArray</code> <p>Boolean mask identifying NEMO model grid points which are inside the region of interest.</p> required <code>uv_vars</code> <code>list</code> <p>Names of velocity variables to extract along the boundary. Default is ['uo', 'vo'].</p> <code>['uo', 'vo']</code> <code>vars</code> <code>list</code> <p>Names of scalar variables to extract along the boundary.</p> <code>None</code> <code>dom</code> <code>str</code> <p>Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.). Default is '.' for the parent domain.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>Dataset containing variables and NEMO model coordinates extracted along the boundary of the mask.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def extract_mask_boundary(\n    cls,\n    mask: xr.DataArray,\n    uv_vars: list = ['uo', 'vo'],\n    vars: list | None = None,\n    dom: str = '.',\n    ) -&gt; xr.Dataset:\n    \"\"\"\n    Extract the boundary of a masked region defined on a NEMO model grid.\n\n    Parameters\n    ----------\n    mask : xr.DataArray\n        Boolean mask identifying NEMO model grid points which\n        are inside the region of interest.\n    uv_vars : list, optional\n        Names of velocity variables to extract along the boundary.\n        Default is ['uo', 'vo'].\n    vars : list, optional\n        Names of scalar variables to extract along the boundary.\n    dom : str, optional\n        Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        Default is '.' for the parent domain.\n\n    Returns\n    -------\n    xr.Dataset\n        Dataset containing variables and NEMO model coordinates\n        extracted along the boundary of the mask.\n    \"\"\"\n    if not isinstance(mask, xr.DataArray):\n        raise ValueError(\"mask must be an xarray DataArray\")\n    if not isinstance(dom, str):\n        raise ValueError(\"dom must be a string specifying prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\")\n\n    # -- Get NEMO model grid properties -- #\n    dom_prefix, dom_suffix = cls._get_properties(dom=dom)\n    grid_paths = cls._get_grid_paths(dom=dom)\n    gridT, gridU, gridV = grid_paths['gridT'], grid_paths['gridU'], grid_paths['gridV']\n    ijk_names = cls._get_ijk_names(dom=dom)\n    k_name = ijk_names['k']\n\n    # -- Extract mask boundary -- #\n    if f'i{dom_suffix}' not in mask.dims or f'j{dom_suffix}' not in mask.dims:\n        raise ValueError(f\"mask must have dimensions f'i{dom_suffix}' and 'j{dom_suffix}'\")\n    i_bdy, j_bdy, flux_type, flux_dir = get_mask_boundary(mask)\n\n    # -- Construct boundary dataset -- #\n    time_name = [dim for dim in cls[gridU].dims if 'time' in dim][0]\n\n    ds = xr.Dataset(\n        data_vars={\n        'i_bdy': (['bdy'], i_bdy[::-1]),\n        'j_bdy': (['bdy'], j_bdy[::-1]),\n        'flux_type': (['bdy'], flux_type[::-1]),\n        'flux_dir': (['bdy'], flux_dir[::-1])\n        },\n        coords={\n        time_name: cls[gridU][time_name].values,\n        k_name: cls[gridU][k_name].values,\n        'bdy': np.arange(len(i_bdy)),\n        })\n\n    # Add velocities normal to boundary:\n    if uv_vars[0] not in cls[gridU].data_vars:\n        raise KeyError(f\"variable '{uv_vars[0]}' not found in grid '{gridU}'.\")\n    if uv_vars[1] not in cls[gridV].data_vars:\n        raise KeyError(f\"variable '{uv_vars[1]}' not found in grid '{gridV}'.\")\n\n    ubdy_mask = ds['flux_type'] == 'U'\n    vbdy_mask = ds['flux_type'] == 'V'\n\n    dim_sizes = [cls[gridU][time_name].size, cls[gridU][k_name].size, ds[\"bdy\"].size]\n\n    ds['velocity'] = xr.DataArray(data=dask.array.zeros(dim_sizes), dims=[time_name, k_name, 'bdy'])\n    ds['velocity'][:, :, ubdy_mask] = cls[gridU]['uo'].where(cls[gridU]['umask']).sel(i=ds['i_bdy'][ubdy_mask], j=ds['j_bdy'][ubdy_mask]) * ds['flux_dir'][ubdy_mask]\n    ds['velocity'][:, :, vbdy_mask] = cls[gridV]['vo'].where(cls[gridV]['vmask']).sel(i=ds['i_bdy'][vbdy_mask], j=ds['j_bdy'][vbdy_mask]) * ds['flux_dir'][vbdy_mask]\n\n    ds = ds.assign_coords({f\"{dom_prefix}glamb\": (['bdy'], np.zeros(ds[\"bdy\"].size)),\n                           f\"{dom_prefix}gphib\": (['bdy'], np.zeros(ds[\"bdy\"].size)),\n                           f\"{dom_prefix}depthb\": ((k_name, 'bdy'), np.zeros(dim_sizes[1:])),\n                           })\n\n    ds[f\"{dom_prefix}glamb\"][ubdy_mask] = cls[gridU]['glamu'].sel(i=ds['i_bdy'][ubdy_mask], j=ds['j_bdy'][ubdy_mask])\n    ds[f\"{dom_prefix}glamb\"][vbdy_mask] = cls[gridV]['glamv'].sel(i=ds['i_bdy'][vbdy_mask], j=ds['j_bdy'][vbdy_mask])\n\n    ds[f\"{dom_prefix}gphib\"][ubdy_mask] = cls[gridU]['gphiu'].sel(i=ds['i_bdy'][ubdy_mask], j=ds['j_bdy'][ubdy_mask])\n    ds[f\"{dom_prefix}gphib\"][vbdy_mask] = cls[gridV]['gphiv'].sel(i=ds['i_bdy'][vbdy_mask], j=ds['j_bdy'][vbdy_mask])\n\n    ds[f\"{dom_prefix}depthb\"][:, ubdy_mask] = cls[gridU]['depthu']\n    ds[f\"{dom_prefix}depthb\"][:, vbdy_mask] = cls[gridV]['depthv']\n\n    if vars is not None:\n        # Add scalar variables along the boundary:\n        for var in vars:\n            if var in cls[gridT].data_vars:\n                ds[var] = xr.DataArray(data=dask.array.zeros(dim_sizes), dims=[time_name, k_name, 'bdy'])\n            else:\n                raise KeyError(f\"variable {var} not found in grid '{gridT}'.\")\n\n            # Linearly interpolate scalar variables onto NEMO model U/V grid points:\n            ds[var][:, :, ubdy_mask] = 0.5 * (\n                cls[gridT][var].where(cls[gridT]['tmask']).sel(i=ds['i_bdy'][ubdy_mask] - 0.5, j=ds['j_bdy'][ubdy_mask]) +\n                cls[gridT][var].where(cls[gridT]['tmask']).sel(i=ds['i_bdy'][ubdy_mask] + 0.5, j=ds['j_bdy'][ubdy_mask])\n                )\n            ds[var][:, :, vbdy_mask] = 0.5 * (\n                cls[gridT][var].where(cls[gridT]['tmask']).sel(i=ds['i_bdy'][vbdy_mask], j=ds['j_bdy'][vbdy_mask] - 0.5) +\n                cls[gridT][var].where(cls[gridT]['tmask']).sel(i=ds['i_bdy'][vbdy_mask], j=ds['j_bdy'][vbdy_mask] + 0.5)\n                )\n\n    return ds\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.from_datasets","title":"from_datasets  <code>classmethod</code>","text":"<pre><code>from_datasets(datasets, nests=None, iperio=False, nftype=None, read_mask=False, nbghost_child=4)\n</code></pre> <p>Create a NEMODataTree from a dictionary of <code>xarray.Dataset</code> objects created from NEMO model output files, organised into a hierarchy of domains (i.e., 'parent', 'child', 'grandchild').</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>dict[str, dict[str, Dataset]]</code> <p>Dictionary containing <code>xarray.Datasets</code> created from NEMO grid files, structured as: {     'parent': {'domain': ds_domain, 'gridT': ds_gridT, ... , 'icemod': ds_icemod.nc},     'child': {'1': {'domain': ds_domain_1, 'gridT': d_gridT_1, ...}},     'grandchild': {'2': {'domain': ds_domain_2, 'gridT': ds_gridT_2, ...}} }</p> required <code>nests</code> <code>dict[str, dict[st, str]]</code> <p>Dictionary describing the properties of nested domains, structured as: {     \"1\": {         \"parent\": \"/\",         \"rx\": rx,         \"ry\": ry,         \"imin\": imin,         \"imax\": imax,         \"jmin\": jmin,         \"jmax\": jmax,         }, } where <code>rx</code> and <code>ry</code> are the horizontal refinement factors, and <code>imin</code>, <code>imax</code>, <code>jmin</code>, <code>jmax</code> define the indices of the child (grandchild) domain within the parent (child) domain.</p> <code>None</code> <code>iperio</code> <code>bool</code> <p>Zonal periodicity of the parent domain.</p> <code>False</code> <code>nftype</code> <code>str | None</code> <p>Type of north fold lateral boundary condition to apply. Options are 'T' for T-point pivot or 'F' for F-point pivot. By default, no north fold lateral boundary condition is applied (None).</p> <code>None</code> <code>read_mask</code> <code>bool</code> <p>If True, read NEMO model land/sea mask from domain files. Default is False, meaning masks are computed from top_level and bottom_level domain variables.</p> <code>False</code> <code>nbghost_child</code> <code>int = 4</code> <p>Number of ghost cells to remove from the western/southern boundaries of the (grand)child domains. Default is 4.</p> <code>4</code> <p>Returns:</p> Type Description <code>NEMODataTree</code> <p>A hierarchical data tree of NEMO model outputs.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>@classmethod\ndef from_datasets(\n    cls,\n    datasets: dict[str, xr.Dataset],\n    nests: dict[str, str] | None = None,\n    iperio: bool = False,\n    nftype: str | None = None,\n    read_mask: bool = False,\n    nbghost_child: int = 4\n) -&gt; Self:\n    \"\"\"\n    Create a NEMODataTree from a dictionary of `xarray.Dataset` objects created from NEMO model output files,\n    organised into a hierarchy of domains (i.e., 'parent', 'child', 'grandchild').\n\n    Parameters\n    ----------\n    datasets : dict[str, dict[str, xr.Dataset]]\n        Dictionary containing `xarray.Datasets` created from NEMO grid files, structured as:\n        {\n            'parent': {'domain': ds_domain, 'gridT': ds_gridT, ... , 'icemod': ds_icemod.nc},\n            'child': {'1': {'domain': ds_domain_1, 'gridT': d_gridT_1, ...}},\n            'grandchild': {'2': {'domain': ds_domain_2, 'gridT': ds_gridT_2, ...}}\n        }\n\n    nests : dict[str, dict[st, str]], optional\n        Dictionary describing the properties of nested domains, structured as:\n        {\n            \"1\": {\n                \"parent\": \"/\",\n                \"rx\": rx,\n                \"ry\": ry,\n                \"imin\": imin,\n                \"imax\": imax,\n                \"jmin\": jmin,\n                \"jmax\": jmax,\n                },\n        }\n        where `rx` and `ry` are the horizontal refinement factors, and `imin`, `imax`, `jmin`, `jmax`\n        define the indices of the child (grandchild) domain within the parent (child) domain.\n\n    iperio: bool = False\n        Zonal periodicity of the parent domain.\n\n    nftype: str, optional\n        Type of north fold lateral boundary condition to apply. Options are 'T' for T-point pivot or 'F' for F-point\n        pivot. By default, no north fold lateral boundary condition is applied (None).\n\n    read_mask: bool = False\n        If True, read NEMO model land/sea mask from domain files. Default is False, meaning masks are computed from top_level and bottom_level domain variables.\n\n    nbghost_child : int = 4\n        Number of ghost cells to remove from the western/southern boundaries of the (grand)child domains. Default is 4.\n\n    Returns\n    -------\n    NEMODataTree\n        A hierarchical data tree of NEMO model outputs.\n    \"\"\"\n    if not isinstance(datasets, dict):\n        raise TypeError(\"datasets must be a dictionary or nested dictionary.\")\n    if not isinstance(nests, (dict, type(None))):\n        raise TypeError(\"nests must be a dictionary or None.\")\n    if not isinstance(iperio, bool):\n        raise TypeError(\"zonal periodicity of parent domain must be a boolean.\")\n    if nftype is not None and nftype not in ('T', 'F'):\n        raise ValueError(\"north fold type of parent domain must be 'T' (T-pivot fold), 'F' (F-pivot fold), or None.\")\n    if not isinstance(read_mask, bool):\n        raise TypeError(\"read_mask must be a boolean.\")\n    if not isinstance(nbghost_child, int):\n        raise TypeError(\"number of ghost cells along the western/southern boundaries must be an integer.\")\n\n    # Define parent, child, grandchild dataset collections:\n    d_child, d_grandchild = None, None\n    if 'parent' in datasets.keys() and isinstance(datasets['parent'], dict):\n        for key in datasets.keys():\n            if key not in ('parent', 'child', 'grandchild'):\n                raise ValueError(f\"unexpected key '{key}' in datasets dictionary.\")\n            if key == 'parent':\n                d_parent = datasets['parent']\n            elif key == 'child':\n                d_child = datasets['child']\n            elif key == 'grandchild':\n                d_grandchild = datasets['grandchild']\n    else:\n        raise ValueError(\"invalid dataset structure. Expected a nested dictionary defining NEMO 'parent', 'child' and 'grandchild' domains.\")\n\n    # Construct DataTree from parent / child / grandchild domains:\n    d_tree = create_datatree_dict(d_parent=d_parent,\n                                  d_child=d_child,\n                                  d_grandchild=d_grandchild,\n                                  nests=nests,\n                                  iperio=iperio,\n                                  nftype=nftype,\n                                  read_mask=read_mask,\n                                  nbghost_child=nbghost_child\n                                  )\n    datatree = super().from_dict(d_tree)\n\n    return datatree\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.from_paths","title":"from_paths  <code>classmethod</code>","text":"<pre><code>from_paths(paths, nests=None, iperio=False, nftype=None, read_mask=False, nbghost_child=4, **open_kwargs)\n</code></pre> <p>Create a NEMODataTree from a dictionary of paths to NEMO model output files, organised into a hierarchy of domains (i.e., 'parent', 'child', 'grandchild').</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>dict[str, str]</code> <p>Dictionary containing paths to NEMO grid files, structured as: {     'parent': {'domain': 'path/to/domain.nc',                'gridT': 'path/to/gridT.nc',                 , ... ,                 'icemod': 'path/to/icemod.nc',                 },     'child': {'1': {'domain': 'path/to/child_domain.nc',                     'gridT': 'path/to/child_gridT.nc',                     , ... ,                     'icemod': 'path/to/child_icemod.nc',                     },               },     'grandchild': {'2': {'domain': 'path/to/grandchild_domain.nc',                          'gridT': 'path/to/grandchild_gridT.nc',                          , ...,                          'icemod': 'path/to/grandchild_icemod.nc',                          },                    } }</p> required <code>nests</code> <code>dict[str, str]</code> <p>Dictionary describing the properties of nested domains, structured as: {     \"1\": {         \"parent\": \"/\",         \"rx\": rx,         \"ry\": ry,         \"imin\": imin,         \"imax\": imax,         \"jmin\": jmin,         \"jmax\": jmax,         \"iperio\": iperio,         }, } where <code>rx</code> and <code>ry</code> are the horizontal refinement factors, and <code>imin</code>, <code>imax</code>, <code>jmin</code>, <code>jmax</code> define the indices of the child (grandchild) domain within the parent (child) domain. Zonally periodic nested domains should be specified with <code>iperio=True</code>.</p> <code>None</code> <code>iperio</code> <code>bool</code> <p>Zonal periodicity of the parent domain. Default is False.</p> <code>False</code> <code>nftype</code> <code>str | None</code> <p>Type of north fold lateral boundary condition to apply. Options are 'T' for T-point pivot or 'F' for F-point pivot. By default, no north fold lateral boundary condition is applied (None).</p> <code>None</code> <code>read_mask</code> <code>bool</code> <p>If True, read NEMO model land/sea mask from domain files. Default is False, meaning masks are computed from top_level and bottom_level domain variables.</p> <code>False</code> <code>nbghost_child</code> <code>int = 4</code> <p>Number of ghost cells to remove from the western/southern boundaries of the (grand)child domains. Default is 4.</p> <code>4</code> <code>**open_kwargs</code> <code>dict</code> <p>Additional keyword arguments to pass to <code>xarray.open_dataset</code> or <code>xr.open_mfdataset</code> when opening NEMO model output files.</p> <code>{}</code> <p>Returns:</p> Type Description <code>NEMODataTree</code> <p>A hierarchical DataTree storing NEMO model outputs.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>@classmethod\ndef from_paths(\n    cls,\n    paths: dict[str, str],\n    nests: dict[str, str] | None = None,\n    iperio: bool = False,\n    nftype: str | None = None,\n    read_mask: bool = False,\n    nbghost_child: int = 4,\n    **open_kwargs: dict[str, any],\n) -&gt; Self:\n    \"\"\"\n    Create a NEMODataTree from a dictionary of paths to NEMO model output files,\n    organised into a hierarchy of domains (i.e., 'parent', 'child', 'grandchild').\n\n    Parameters\n    ----------\n    paths : dict[str, str]\n        Dictionary containing paths to NEMO grid files, structured as:\n        {\n            'parent': {'domain': 'path/to/domain.nc',\n                       'gridT': 'path/to/gridT.nc',\n                        , ... ,\n                        'icemod': 'path/to/icemod.nc',\n                        },\n            'child': {'1': {'domain': 'path/to/child_domain.nc',\n                            'gridT': 'path/to/child_gridT.nc',\n                            , ... ,\n                            'icemod': 'path/to/child_icemod.nc',\n                            },\n                      },\n            'grandchild': {'2': {'domain': 'path/to/grandchild_domain.nc',\n                                 'gridT': 'path/to/grandchild_gridT.nc',\n                                 , ...,\n                                 'icemod': 'path/to/grandchild_icemod.nc',\n                                 },\n                           }\n        }\n\n    nests : dict[str, str], optional\n        Dictionary describing the properties of nested domains, structured as:\n        {\n            \"1\": {\n                \"parent\": \"/\",\n                \"rx\": rx,\n                \"ry\": ry,\n                \"imin\": imin,\n                \"imax\": imax,\n                \"jmin\": jmin,\n                \"jmax\": jmax,\n                \"iperio\": iperio,\n                },\n        }\n        where `rx` and `ry` are the horizontal refinement factors, and `imin`, `imax`, `jmin`, `jmax`\n        define the indices of the child (grandchild) domain within the parent (child) domain. Zonally\n        periodic nested domains should be specified with `iperio=True`.\n\n    iperio: bool = False\n        Zonal periodicity of the parent domain. Default is False.\n\n    nftype: str, optional\n        Type of north fold lateral boundary condition to apply. Options are 'T' for T-point pivot or 'F' for F-point\n        pivot. By default, no north fold lateral boundary condition is applied (None).\n\n    read_mask: bool = False\n        If True, read NEMO model land/sea mask from domain files. Default is False, meaning masks are computed from top_level and bottom_level domain variables.\n\n    nbghost_child : int = 4\n        Number of ghost cells to remove from the western/southern boundaries of the (grand)child domains. Default is 4.\n\n    **open_kwargs : dict, optional\n        Additional keyword arguments to pass to `xarray.open_dataset` or `xr.open_mfdataset` when opening NEMO model output files.\n    Returns\n    -------\n    NEMODataTree\n        A hierarchical DataTree storing NEMO model outputs.\n    \"\"\"\n    if not isinstance(paths, dict):\n        raise TypeError(\"paths must be a dictionary or nested dictionary.\")\n    if not isinstance(nests, (dict, type(None))):\n        raise TypeError(\"nests must be a dictionary or None.\")\n    if not isinstance(iperio, bool):\n        raise TypeError(\"zonal periodicity of parent domain must be a boolean.\")\n    if nftype is not None and nftype not in ('T', 'F'):\n        raise ValueError(\"north fold type of parent domain must be 'T' (T-pivot fold), 'F' (F-pivot fold), or None.\")\n    if not isinstance(read_mask, bool):\n        raise TypeError(\"read_mask must be a boolean.\")\n    if not isinstance(nbghost_child, int):\n        raise TypeError(\"number of ghost cells along the western/southern boundaries must be an integer.\")\n    if not isinstance(open_kwargs, dict):\n        raise TypeError(\"open_kwargs must be a dictionary.\")\n\n    # Define parent, child, grandchild filepath collections:\n    d_child, d_grandchild = None, None\n    if 'parent' in paths.keys() and isinstance(paths['parent'], dict):\n        for key in paths.keys():\n            if key not in ('parent', 'child', 'grandchild'):\n                raise ValueError(f\"Unexpected key '{key}' in paths dictionary.\")\n            if key == 'parent':\n                d_parent = paths['parent']\n            elif key == 'child':\n                d_child = paths['child']\n            elif key == 'grandchild':\n                d_grandchild = paths['grandchild']\n    else:\n        raise ValueError(\"Invalid paths structure. Expected a nested dictionary defining NEMO 'parent', 'child' and 'grandchild' domains.\")\n\n    # Construct DataTree from parent / child / grandchild domains:\n    d_tree = create_datatree_dict(d_parent=d_parent,\n                                  d_child=d_child,\n                                  d_grandchild=d_grandchild,\n                                  nests=nests,\n                                  iperio=iperio,\n                                  nftype=nftype,\n                                  read_mask=read_mask,\n                                  nbghost_child=nbghost_child,\n                                  open_kwargs=dict(**open_kwargs)\n                                  )\n\n    datatree = super().from_dict(d_tree)\n\n    return datatree\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.gradient","title":"gradient","text":"<pre><code>gradient(var, dim, dom='.')\n</code></pre> <p>Calculate the gradient of a scalar variable along one dimension (e.g., 'i', 'j', 'k') of a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>var</code> <code>str</code> <p>Name of the scalar variable.</p> required <code>dim</code> <code>str</code> <p>Dimension along which to calculate gradient (e.g., 'i', 'j', 'k').</p> required <code>dom</code> <code>str</code> <p>Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.). Default is '.' for the parent domain.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Gradient of scalar variable defined on a NEMO model grid.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def gradient(\n    cls,\n    var: str,\n    dim: str,\n    dom: str = '.',\n) -&gt; xr.DataArray:\n    \"\"\"\n    Calculate the gradient of a scalar variable along one dimension (e.g., 'i', 'j', 'k') of a NEMO model grid.\n\n    Parameters\n    ----------\n    var : str\n        Name of the scalar variable.\n    dim : str\n        Dimension along which to calculate gradient (e.g., 'i', 'j', 'k').\n    dom : str, optional\n        Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        Default is '.' for the parent domain.\n\n    Returns\n    -------\n    xr.DataArray\n        Gradient of scalar variable defined on a NEMO model grid.\n    \"\"\"\n    # -- Validate input -- #\n    if not isinstance(var, str):\n        raise ValueError(\"var must be a string specifying name of the scalar variable.\")\n    if not isinstance(dim, str):\n        raise ValueError(\"dim must be a string specifying dimension along which to calculate the gradient (e.g., 'i', 'j', 'k').\")\n    if not isinstance(dom, str):\n        raise ValueError(\"dom must be a string specifying prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\")\n\n    # -- Get NEMO model grid properties -- #\n    dom_prefix, dom_suffix = cls._get_properties(dom=dom)\n    grid_paths = cls._get_grid_paths(dom=dom)\n    gridT, gridU, gridV, gridW = grid_paths['gridT'], grid_paths['gridU'], grid_paths['gridV'], grid_paths['gridW']\n\n    if var not in cls[gridT].data_vars:\n        raise KeyError(f\"variable '{var}' not found in grid '{gridT}'.\")\n\n    da = cls[gridT][var]\n    dim_name = f\"{dim}{dom_suffix}\"\n    if dim_name not in da.dims:\n        raise KeyError(f\"dimension '{dim_name}' not found in variable '{var}'. Dimensions available: {da.dims}.\")\n\n    match dim:\n        case \"i\":\n            if f\"{dom_prefix}deptht\" in da.coords:\n                # 3-dimensional umask:\n                umask = cls[gridU][\"umask\"]\n            else:\n                # 2-dimensional umask:\n                umask = cls[gridU][\"umaskutil\"]\n\n            # Zonally Periodic Domain:\n            if cls[gridT].attrs.get(\"iperio\", False):\n                da_end = da.isel(dim_name=0)\n                da_end[dim_name] = da[dim_name].max() + 1\n                da = xr.concat([da, da_end], dim=dim_name)\n                dvar = da.diff(dim=dim_name, label=\"lower\")\n            else:\n                # Non-Periodic: pad with NaN values after differencing:\n                dvar = (da\n                        .diff(dim=dim_name, label=\"lower\")\n                        .pad({dim_name: (0, 1)})\n                        )\n            # Apply u-mask &amp; transform coords -&gt; calculate gradient:\n            dvar.coords[dim_name] = dvar.coords[dim_name] + 0.5\n            gradient = dvar.where(umask) / cls[gridU][\"e1u\"]\n\n            # Remove redundant depth coordinates:\n            if f\"{dom_prefix}deptht\" in gradient.coords:\n                gradient = (gradient\n                            .drop_vars([f\"{dom_prefix}deptht\"])\n                            .assign_coords({f\"{dom_prefix}depthu\": cls[gridU][f\"{dom_prefix}depthu\"]})\n                            )\n        case \"j\":\n            # 3-dimensional vmask:\n            if f\"{dom_prefix}deptht\" in da.coords:\n                vmask = cls[gridV][\"vmask\"]\n            else:\n                # 2-dimensional vmask (unique points):\n                vmask = cls[gridV][\"vmaskutil\"]\n\n            # Pad with zeros after differencing (zero gradient at jmaxdom):\n            dvar = (da\n                    .diff(dim=dim_name, label=\"lower\")\n                    .pad({dim_name: (0, 1)}, constant_values=0)\n                    )\n            # Apply vmask &amp; transform coords -&gt; calculate gradient:\n            dvar.coords[dim_name] = dvar.coords[dim_name] + 0.5\n            gradient = dvar.where(vmask) / cls[grid_paths['gridV']][\"e2v\"]\n\n            if f\"{dom_prefix}deptht\" in gradient.coords:\n                gradient = (gradient\n                            .drop_vars([f\"{dom_prefix}deptht\"])\n                            .assign_coords({f\"{dom_prefix}depthv\": cls[gridV][f\"{dom_prefix}depthv\"]})\n                            )\n\n        case \"k\":\n            dvar = da.diff(dim=dim_name, label=\"lower\")\n            # Transform coords &amp; apply w-mask -&gt; calculate gradient:\n            dvar.coords[dim_name] = dvar.coords[dim_name] + 0.5\n            dvar = dvar.where(cls[gridW][\"wmask\"].isel({dim_name: slice(1, None)}))\n            try:\n                gradient = - dvar / cls[gridW][\"e3w\"].isel({dim_name: slice(1, None)})\n                gradient = gradient.drop_vars([f\"{dom_prefix}deptht\"])\n            except KeyError:\n                raise KeyError(f\"NEMO model grid: '{gridW}' does not contain vertical scale factor 'e3w' required to calculate gradients along the k-dimension.\")\n\n    # Update DataArray properties:\n    gradient.name = f\"grad_{var}_{dim_name}\"\n    gradient = gradient.drop_vars([f\"{dom_prefix}glamt\", f\"{dom_prefix}gphit\"])\n\n    return gradient\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.integral","title":"integral","text":"<pre><code>integral(grid, var, dims, cum_dims=None, dir=None, mask=None)\n</code></pre> <p>Integrate a variable along one or more dimensions of a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where variable is stored (e.g., '/gridT').</p> required <code>var</code> <code>str</code> <p>Name of variable to integrate.</p> required <code>dims</code> <code>list</code> <p>Dimensions over which to integrate (e.g., ['i', 'k']).</p> required <code>cum_dims</code> <code>list</code> <p>Dimensions over which to cumulatively integrate (e.g., ['k']). Specified dimensions must also be included in <code>dims</code>.</p> <code>None</code> <code>dir</code> <code>str</code> <p>Direction of cumulative integration. Options are '+1' (along increasing cum_dims) or '-1' (along decreasing cum_dims).</p> <code>None</code> <code>mask</code> <code>DataArray | None</code> <p>Boolean mask identifying NEMO model grid points to be included (1) or neglected (0) from integration.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Variable integrated along specified dimensions of the NEMO model grid.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def integral(\n    cls,\n    grid : str,\n    var : str,\n    dims : list,\n    cum_dims : list | None = None,\n    dir : str | None = None,\n    mask : xr.DataArray | None = None\n) -&gt; xr.DataArray:\n    \"\"\"\n    Integrate a variable along one or more dimensions of a NEMO model grid.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where variable is stored\n        (e.g., '/gridT').\n    var : str\n        Name of variable to integrate.\n    dims : list\n        Dimensions over which to integrate (e.g., ['i', 'k']).\n    cum_dims : list, optional\n        Dimensions over which to cumulatively integrate (e.g., ['k']).\n        Specified dimensions must also be included in `dims`.\n    dir : str, optional\n        Direction of cumulative integration. Options are '+1' (along\n        increasing cum_dims) or '-1' (along decreasing cum_dims).\n    mask: xr.DataArray, optional\n        Boolean mask identifying NEMO model grid points to be included (1)\n        or neglected (0) from integration.\n\n    Returns\n    -------\n    xr.DataArray\n        Variable integrated along specified dimensions of the NEMO model grid.\n\n    \"\"\"\n    # -- Validate input -- #\n    if grid not in list(cls.subtree):\n        raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n    if var not in cls[grid].data_vars:\n        raise KeyError(f\"variable '{var}' not found in grid '{grid}'.\")\n    if cum_dims is not None:\n        for dim in cum_dims:\n            if dim not in dims:\n                raise ValueError(f\"cumulative integration dimension '{dim}' not included in `dims`.\")\n        if dir not in ['+1', '-1']:\n            raise ValueError(f\"invalid direction of cumulative integration '{dir}'. Expected '+1' or '-1'.\")\n    if mask is not None:\n        if not isinstance(mask, xr.DataArray):\n            raise ValueError(\"mask must be an xarray.DataArray.\")\n        if any(dim not in cls[grid].dims for dim in mask.dims):\n            raise ValueError(f\"mask must have dimensions subset from {cls[grid].dims}.\")\n\n    # -- Get NEMO model grid properties -- #\n    _, dom_prefix, _, grid_suffix = cls._get_properties(grid=grid, infer_dom=True)\n\n    # -- Collect variable, weights &amp; mask -- #\n    da = cls[grid][var].where(mask) if mask is not None else cls[grid][var]\n    weights = cls._get_weights(grid=grid, dims=dims)\n\n    if f\"{dom_prefix}depth{grid_suffix}\" in da.coords:\n        # Apply 3-dimensional t/u/v/f/w mask:\n        dom_mask = cls[grid][f\"{grid_suffix}mask\"]\n    else:\n        # Apply 2-dimensional t/u/v/f mask (unique points):\n        hgrid_type = grid_suffix if 'w' not in grid_suffix else 't'\n        dom_mask = cls[grid][f\"{hgrid_type}maskutil\"]\n\n    # -- Perform integration -- #\n    if cum_dims is not None:\n        sum_dims = [dim for dim in dims if dim not in cum_dims]\n        if dir == '+1':\n            # Cumulative integration along ordered dimension:\n            result = da.where(dom_mask).weighted(weights).sum(dim=sum_dims, skipna=True).cumsum(dim=cum_dims, skipna=True)\n        elif dir == '-1':\n            # Cumulative integration along reversed dimension:\n            result = (da\n                        .where(dom_mask)\n                        .weighted(weights)\n                        .sum(dim=sum_dims, skipna=True)\n                        .reindex({dim: cls[grid][dim][::-1] for dim in cum_dims})\n                        .cumsum(dim=cum_dims, skipna=True)\n                        )\n    else:\n        # Integration only:\n        result = da.weighted(weights).sum(dim=dims, skipna=True)\n\n    return result\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.mask_with_polygon","title":"mask_with_polygon","text":"<pre><code>mask_with_polygon(grid, lon_poly, lat_poly)\n</code></pre> <p>Create mask of NEMO model grid points contained within a polygon.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where longitude and latitude coordinates are stored (e.g., '/gridT').</p> required <code>lon_poly</code> <code>list | ndarray</code> <p>Longitudes of closed polygon.</p> required <code>lat_poly</code> <code>list | ndarray</code> <p>Latitudes of closed polygon.</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Boolean mask identifying NEMO model grid points which are inside the polygon.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def mask_with_polygon(\n    cls,\n    grid: str,\n    lon_poly: list | np.ndarray,\n    lat_poly: list | np.ndarray,\n):\n    \"\"\"\n    Create mask of NEMO model grid points contained within a polygon.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where longitude and latitude coordinates\n        are stored (e.g., '/gridT').\n    lon_poly : list | ndarray\n        Longitudes of closed polygon.\n    lat_poly : list | ndarray\n        Latitudes of closed polygon.\n\n    Returns\n    -------\n    xr.DataArray\n        Boolean mask identifying NEMO model grid points which are inside\n        the polygon.\n    \"\"\"\n    # -- Validate input -- #\n    if not isinstance(lon_poly, (np.ndarray, list)) or not isinstance(lat_poly, (np.ndarray, list)):\n        raise TypeError(\"longitude &amp; latitude coordinates of polygon must be numpy arrays or lists.\")\n    if (lon_poly[0] != lon_poly[-1]) or (lat_poly[0] != lat_poly[-1]):\n        raise ValueError(\"longitude &amp; latitude coordinates must form a closed polygon.\")\n    if grid not in list(cls.subtree):\n        raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n\n    # -- Get NEMO model grid properties -- #\n    dom, dom_prefix, _, grid_suffix = cls._get_properties(grid=grid, infer_dom=True)\n    hgrid_type = grid_suffix if 'w' not in grid_suffix else 't'\n    ijk_names = cls._get_ijk_names(grid=grid)\n    i_name, j_name = ijk_names['i'], ijk_names['j']\n\n    if dom == \".\":\n        lon_name = f\"glam{hgrid_type}\"\n        lat_name = f\"gphi{hgrid_type}\"\n    else:\n        lon_name = f\"{dom_prefix}glam{hgrid_type}\"\n        lat_name = f\"{dom_prefix}gphi{hgrid_type}\"\n\n    # -- Create mask using polygon coordinates -- #\n    mask = create_polygon_mask(lon_grid=cls[grid][lon_name],\n                               lat_grid=cls[grid][lat_name],\n                               lon_poly=lon_poly,\n                               lat_poly=lat_poly,\n                               dims=(j_name, i_name)\n                               )\n\n    return mask\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.masked_statistic","title":"masked_statistic","text":"<pre><code>masked_statistic(grid, var, lon_poly, lat_poly, statistic, dims)\n</code></pre> <p>Masked statistic of a variable defined on a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where variable is stored (e.g., '/gridT').</p> required <code>var</code> <code>str</code> <p>Name of the variable to compute statistic.</p> required <code>lon_poly</code> <code>list | ndarray</code> <p>Longitudes of closed polygon.</p> required <code>lat_poly</code> <code>list | ndarray</code> <p>Latitudes of closed polygon.</p> required <code>statistic</code> <code>str</code> <p>Name of the statistic to calculate (e.g., 'mean', 'weighted_mean' 'sum').</p> required <code>dims</code> <code>list</code> <p>Dimensions over which to apply statistic (e.g., ['i', 'j']).</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Masked statistic of specified variable.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def masked_statistic(\n    cls, \n    grid : str,\n    var : str,\n    lon_poly : list | np.ndarray,\n    lat_poly : list | np.ndarray,\n    statistic : str,\n    dims : list\n    ) -&gt; xr.DataArray:\n    \"\"\"\n    Masked statistic of a variable defined on a NEMO model grid.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where variable is stored\n        (e.g., '/gridT').\n    var : str\n        Name of the variable to compute statistic.\n    lon_poly : list | np.ndarray\n        Longitudes of closed polygon.\n    lat_poly : list | np.ndarray\n        Latitudes of closed polygon.\n    statistic : str\n        Name of the statistic to calculate (e.g., 'mean', 'weighted_mean' 'sum').\n    dims : list\n        Dimensions over which to apply statistic (e.g., ['i', 'j']).\n\n    Returns\n    -------\n    xr.DataArray\n        Masked statistic of specified variable.\n    \"\"\"\n    # -- Validate input -- #\n    if grid not in list(cls.subtree):\n        raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n    if var not in cls[grid].data_vars:\n        raise KeyError(f\"variable '{var}' not found in grid '{grid}'.\")\n\n    # -- Create polygon mask using coordinates -- #\n    mask_poly = cls.mask_with_polygon(lon_poly=lon_poly,\n                                      lat_poly=lat_poly,\n                                      grid=grid\n                                      )\n\n    # -- Get NEMO model grid properties -- #\n    _, dom_prefix, dom_suffix, grid_suffix = cls._get_properties(grid=grid, infer_dom=True)\n\n    # -- Apply masks &amp; calculate statistic -- #\n    if f\"{dom_prefix}depth{grid_suffix}\" in cls[grid][var].coords:\n        # Apply 3-dimensional t/u/v/f/w mask:\n        dom_mask = cls[grid][f\"{grid_suffix}mask\"]\n    else:\n        # Apply 2-dimensional t/u/v/f mask (unique points):\n        hgrid_type = grid_suffix if 'w' not in grid_suffix else 't'\n        dom_mask = cls[grid][f\"{hgrid_type}maskutil\"]\n\n    da = cls[grid][var].where(dom_mask &amp; mask_poly)\n\n    match statistic:\n        case \"mean\":\n            result = da.mean(dim=dims, skipna=True)\n\n        case \"weighted_mean\":\n            weight_dims = [dim.replace(dom_suffix, \"\") for dim in dims]\n            weights = cls._get_weights(grid=grid, dims=weight_dims)\n            result = da.weighted(weights).mean(dim=dims, skipna=True)\n\n        case \"min\":\n            result = da.min(dim=dims, skipna=True)\n\n        case \"max\":\n            result = da.max(dim=dims, skipna=True)\n\n        case \"sum\":\n            result = da.sum(dim=dims, skipna=True)\n\n    return result\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.transform_scalar_to","title":"transform_scalar_to","text":"<pre><code>transform_scalar_to(grid, var, to)\n</code></pre> <p>Transform scalar variable defined on a NEMO model grid to a neighbouring horizontal grid using linear interpolation.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where variable is stored (e.g., '/gridT').</p> required <code>var</code> <code>str</code> <p>Name of the variable to transform.</p> required <code>to</code> <code>str</code> <p>Suffix of the neighbouring horizontal NEMO model grid to transform variable to. Options are 'U', 'V'.</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Values of variable linearly interpolated onto a neighbouring horizontal grid.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def transform_scalar_to(\n    cls,\n    grid: str,\n    var: str,\n    to: str\n) -&gt; xr.DataArray:\n    \"\"\"\n    Transform scalar variable defined on a NEMO model grid to a neighbouring horizontal grid using linear interpolation.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where variable is stored\n        (e.g., '/gridT').\n    var : str\n        Name of the variable to transform.\n    to : str\n        Suffix of the neighbouring horizontal NEMO model grid to\n        transform variable to. Options are 'U', 'V'.\n\n    Returns\n    -------\n    xr.DataArray\n        Values of variable linearly interpolated onto a neighbouring\n        horizontal grid.\n    \"\"\"\n    # -- Validate input -- #\n    if grid not in list(cls.subtree):\n        raise KeyError(f\"grid '{grid}' not found in the NEMODataTree.\")\n    if var not in cls[grid].data_vars:\n        raise KeyError(f\"variable '{var}' not found in grid '{grid}'.\")\n    if not isinstance(to, str):\n        raise TypeError(f\"'to' must be a string, got {type(to)}.\")\n    if to not in ['U', 'V']:\n        raise ValueError(f\"'to' must be one of ['U', 'V'], got {to}.\")\n\n    # -- Get NEMO model grid properties -- #\n    ijk_names = cls._get_ijk_names(grid=grid)\n    i_name, j_name = ijk_names['i'], ijk_names['j']\n\n    fill_dim_name = \"i\" if to == \"U\" else \"j\"\n    target_grid = f\"{grid.replace(grid[-1], to)}\"\n    target_mask = f\"{to.lower()}mask\"\n\n    # -- Perform interpolation -- #\n    result = (cls[grid][var]\n              .interpolate_na(dim=fill_dim_name, method='nearest', fill_value=\"extrapolate\")\n              .interp({i_name: cls[grid.replace(grid[-1], to)][i_name],\n                       j_name: cls[grid.replace(grid[-1], to)][j_name]},\n                       method='linear')\n              .where(cls[target_grid][target_mask])\n              )\n\n    return result\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.transform_vertical_grid","title":"transform_vertical_grid","text":"<pre><code>transform_vertical_grid(grid, var, e3_new)\n</code></pre> <p>Transform variable defined on a NEMO model grid to a new vertical grid using conservative interpolation.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where variable is stored (e.g., '/gridT').</p> required <code>var</code> <code>str</code> <p>Name of the variable to transform.</p> required <code>e3_new</code> <code>DataArray</code> <p>Grid cell thicknesses of the new vertical grid. Must be a 1-dimensional xarray.DataArray with dimension 'k_new'.</p> required <p>Returns:</p> Type Description <code>tuple[DataArray, DataArray]</code> <p>Values of variable defined at the centre of each vertical grid cell on the new grid, and vertical grid cell thicknesses adjusted for model bathymetry.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def transform_vertical_grid(\n    cls,\n    grid: str,\n    var: str,\n    e3_new: xr.DataArray\n) -&gt; xr.Dataset:\n    \"\"\"\n    Transform variable defined on a NEMO model grid to a new vertical grid using conservative interpolation.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where variable is stored\n        (e.g., '/gridT').\n    var : str\n        Name of the variable to transform.\n    e3_new : xarray.DataArray\n        Grid cell thicknesses of the new vertical grid.\n        Must be a 1-dimensional xarray.DataArray with\n        dimension 'k_new'.\n\n    Returns\n    -------\n    tuple[xr.DataArray, xr.DataArray]\n        Values of variable defined at the centre of each vertical\n        grid cell on the new grid, and vertical grid cell\n        thicknesses adjusted for model bathymetry.\n    \"\"\"\n    # -- Validate input -- #\n    if grid not in list(cls.subtree):\n        raise KeyError(f\"Grid '{grid}' not found in the NEMODataTree.\")\n    if var not in cls[grid].data_vars:\n        raise KeyError(f\"Variable '{var}' not found in grid '{grid}'.\")\n    if e3_new.dims != ('k_new',) or (e3_new.ndim != 1):\n        raise ValueError(\"e3_new must be a 1-dimensional xarray.DataArray with dimension 'k_new'.\")\n\n    # -- Get NEMO model grid properties -- #\n    dom, _, _, grid_suffix = cls._get_properties(grid=grid, infer_dom=True)\n    ijk_names = cls._get_ijk_names(dom=dom)\n    i_name, j_name, k_name = ijk_names['i'], ijk_names['j'], ijk_names['k']\n\n    # -- Define input variables -- #\n    mask = cls[grid][f\"{grid_suffix}mask\"]\n\n    var_in = cls[grid][var].where(mask)\n    e3_in = cls[grid][f\"e3{grid_suffix}\"].where(mask)\n    if e3_new.sum(dim=\"k_new\") &lt; cls[grid][f\"depth{grid_suffix}\"].max(dim=k_name):\n        raise ValueError(f\"e3_new must sum to at least the maximum depth ({cls[grid][f\"depth{grid_suffix}\"].max(dim=k_name).item()} m) of the original vertical grid.\")\n\n    # -- Transform variable to target vertical grid -- #\n    var_out, e3_out = xr.apply_ufunc(transform_vertical_coords,\n                                     e3_in,\n                                     var_in,\n                                     e3_new.astype(e3_in.dtype),\n                                     input_core_dims=[[k_name], [k_name], [\"k_new\"]],\n                                     output_core_dims=[[\"k_new\"], [\"k_new\"]],\n                                     dask=\"allowed\"\n                                     )\n\n    # -- Create transformed variable Dataset -- #\n    t_name = var_in.dims[0]\n    var_out = var_out.transpose(t_name, \"k_new\", j_name, i_name)\n\n    ds_out = xr.Dataset(\n        data_vars={var: var_out, f\"e3{grid_suffix}_new\": e3_out},\n        coords={f\"depth{grid_suffix}_new\": (\"k_new\", e3_new.cumsum(dim=\"k_new\").data)}\n        )\n\n    return ds_out\n</code></pre>"}]}