{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#getting-started","title":"Getting Started","text":"<p>Welcome to the documentation for the NEMO Cookbook </p>"},{"location":"#what-is-the-nemo-cookbook","title":"What is the NEMO Cookbook?","text":"<p>NEMO Cookbook is a collection of recipes for performing reproducible analyses of the Nucleus for European Modelling of the Ocean (NEMO) ocean general circulation model outputs.</p> <p>Our aim is to provide Python implementations of the post-processing &amp; analysis functions available in CDFTOOLS alongside new diagnostics (e.g., surface-forced water mass transformation), which are compatible with generalised vertical coordinate systems (e.g., MEs).</p>"},{"location":"#nemodatatree","title":"NEMODataTree","text":"<p>NEMO Cookbook utilises the <code>NEMODataTree</code> object, which is an extension of the <code>xarray.DataTree</code> and an alternative to the xgcm grid object.</p> <p><code>NEMODataTree</code> enables users to:</p> <ul> <li> <p>Store output variables defined on NEMO T/U/V/W grids using the model\u2019s native (i, j, k) curvilinear coordinate system.</p> </li> <li> <p>Analyse parent, child and grandchild domains of nested configurations using a single DataTree.</p> </li> <li> <p>Pre-process model outputs (i.e., removing ghost points and generating t/u/v/f masks without needing a mesh_mask file).</p> </li> <li> <p>Perform scalar (e.g., gradient) and vector (e.g., divergence, curl) operations as formulated in NEMO.</p> </li> <li> <p>Calculate grid-aware diagnostics, including masked &amp; binned statistics.</p> </li> <li> <p>Perform vertical grid coordinate transformations via conservative interpolation. </p> </li> </ul> <p>Each recipe in the NEMO Cookbook uses <code>NEMODataTree</code> to leverage xarray, flox &amp; dask libraries to calculate a diagnostic with NEMO ocean model outputs.</p>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<p>Users are recommended to installing NEMO Cookbook into a new virtual environment via GitHub:</p> <pre><code>pip install git+https://github.com/NOC-MSM/nemo_cookbook.git\n</code></pre> <p>Alternatively, users can clone the latest version of the nemo_cookbook repository using Git:</p> <pre><code>git clone git@github.com:NOC-MSM/nemo_cookbook.git\n</code></pre> <p>Then, install the dependencies in a new conda virtual environment and pip install NEMO Cookbook in editable mode:</p> <pre><code>cd nemo_cookbook\n\nconda env create -f environment.yml\nconda activate env_nemo_cookbook\n\npip install -e .\n</code></pre> Helpful Tip... <ul> <li>We strongly recommend setting-up a virtual environment before installing nemo_cookbook with pip.</li> </ul> <p>The simplest way to create a new virtual environment is to use venv:</p> <p><code>sh python3.13 -m venv \"env_nemo_cookbook\"</code></p> <p>Alternatively, using an existing miniconda or miniforge installation:</p> <p><code>sh conda env create -f environment.yml</code></p>"},{"location":"#next-steps","title":"Next Steps...","text":"<ul> <li> <p>To learn more about NEMODataTree, see the User Guide and How To pages - this is an especially starting point for new NEMO users!</p> </li> <li> <p>To get started working with the recipes in the NEMO Cookbook, visit the to Recipes page.</p> </li> <li> <p>For those looking for more detailed documentation, explore the NEMODataTree API.</p> </li> <li> <p>To contribute your own recipes to NEMO Cookbook, see the Contributing page</p> </li> </ul>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":""},{"location":"contributing/#contributing-to-nemo-cookbook","title":"Contributing to NEMO Cookbook","text":"<p>Thank you for your interest in contributing to NEMO Cookbook!</p> <p>We welcome contributions from the community to help us support the reproducible analysis of NEMO model outputs.</p>"},{"location":"contributing/#getting-started","title":"Getting Started","text":"<p>To get started with contributing to NEMO Cookbook, please follow the steps below:</p> <ol> <li>Fork the NEMO Cookbook repository on GitHub.</li> <li>Clone your forked repository to your local machine.</li> <li>Create a new branch for your contribution.</li> <li> <p>Add your new recipe or improvements to the codebase.</p> </li> <li> <p>Follow the NumPy docstring conventions when adding or modifying docstrings.</p> </li> <li> <p>Follow the PEP 8 style guide when writing code.</p> </li> <li> <p>Test your changes thoroughly to ensure they work as expected.</p> </li> <li>Commit your changes with clear and descriptive commit messages.</li> <li>Push your changes to your forked repository.</li> <li>Submit a pull request to the main branch of NEMO Cookbook.</li> </ol>"},{"location":"contributing/#code-guidelines","title":"Code Guidelines","text":"<p>When contributing code to NEMO Cookbook, please adhere to the following guidelines:</p> <ul> <li>Follow the coding style and conventions used in the existing codebase.</li> <li>Write clear and concise code with appropriate comments.</li> <li>Ensure your code is well-tested and does not introduce any regressions.</li> <li>Make sure your recipe is scalable using dask.</li> <li>Add a new .ipynb demonstrating your new recipe.</li> <li>Document any new features or changes in the appropriate sections of the documentation.</li> </ul>"},{"location":"contributing/#bug-reports-and-feature-requests","title":"Bug Reports and Feature Requests","text":"<p>If you find any bugs or have ideas for new features, please open an issue on the NEMO Cookbook GitHub repository.</p> <p>Provide as much detail as possible, including steps to reproduce the issue or a clear description of the desired feature.</p>"},{"location":"contributing/#community-guidelines","title":"Community Guidelines","text":"<p>When participating in the NEMO Cookbook community, please be respectful and considerate towards others. Follow the code of conduct and engage in constructive discussions.</p> <p>We appreciate your contributions and look forward to working together to improve NEMO Cookbook!</p>"},{"location":"howto/","title":"How To...","text":""},{"location":"howto/#a-quickstart-guide-to-common-operations-with-nemodatatree","title":"A Quickstart Guide to Common Operations with NEMODataTree","text":"<p>In this section, we describe some of the most common <code>NEMODataTree</code> operations in a concise how-to guide (inspired by the excellent documentation of Icechunk).</p> <p>For more detailed documentation on each of the <code>NEMODataTree</code> methods, user should visit the API.</p>"},{"location":"howto/#create-a-nemodatatree-from-local-files","title":"Create a NEMODataTree from Local Files","text":"<p>We can create a <code>NEMODataTree</code> from a dictionary of paths to local netCDF files using the <code>.from_paths()</code> constructor:</p> <pre><code>paths = {\"parent\": {\n         \"domain\": \"/path/to/domain_cfg.nc\",\n         \"gridT\": \"path/to/*_gridT.nc\",\n         \"gridU\": \"path/to/*_gridV.nc\",\n         \"gridV\": \"path/to/*_gridV.nc\",\n         \"gridW\": \"path/to/*_gridW.nc\",\n         \"icemod\": \"path/to/*_icemod.nc\",\n        },\n        }\n\nNEMODataTree.from_paths(paths, iperio=True, nftype=\"T\")\n</code></pre> <p>In the example above, we consider only a global parent domain, which is zonally periodic (<code>iperio=True</code>) and north-folding on T grid points (<code>nftype=\"T\"</code>). Note, that we are only required to specify paths for one or more NEMO model grid types (e.g., <code>*_gridT.nc</code>).</p>"},{"location":"howto/#create-a-nemodatatree-from-xarraydatasets","title":"Create a NEMODataTree from <code>xarray.Datasets</code>","text":"<p>Alternatively, we can create a <code>NEMODataTree</code> from a dictionary of single or multi-file <code>xarray.Datasets</code>. This is particularly valuable when working with remote NEMO model data or Coupled Model Intercomparison Project (CMIP) outputs which require us to reformat coordinate dimensions (see Example NEMODataTrees).</p> <pre><code>ds_domain = xr.open_zarr(\"https://some_remote_data/domain_cfg.zarr\")\nds_gridT = xr.open_zarr(\"https://some_remote_data/MY_MODEL_gridT.zarr\")\n\ndatasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}\n\nnemo = NEMODataTree.from_datasets(datasets=datasets)\n</code></pre> <p>This example would be applicable to the outputs of a regional NEMO model configuration which is neither zonally periodic nor north-folding (by default, <code>iperio=False</code> &amp; <code>nftype=None</code>).</p>"},{"location":"howto/#access-masked-grid-variables","title":"Access Masked Grid Variables","text":"<p>To access an unmasked (i.e., unchanged from the original model output files) variable stored within a given grid node of a <code>NEMODataTree</code>, we can use the follow syntax:</p> <pre><code>nemo[{grid_name}][{variable_name}]\n</code></pre> <p>However, if we want to automatically mask the chosen variable with the appropriate domain mask, we can instead provide the direct path to the variable as follows:</p> <pre><code>nemo[\"gridT/thetao_con\"]\n</code></pre> <p>In the example above, the 4-dimensional conservative temperature variable <code>thetao_con</code> is masked using the 3-dimensional <code>tmask</code> before being returned.</p>"},{"location":"howto/#calculate-grid-cell-areas","title":"Calculate Grid Cell Areas","text":"<p>To calculate the area of a model grid cell face, we can use the <code>.cell_area()</code> method.</p> <p>For example, to compute the horizontal area of cells centered on T grid points in the parent domain:</p> <pre><code>nemo.cell_area(grid=\"gridT\", dim=\"k\")\n</code></pre> <p>Importantly, the <code>dim</code> argument represents the dimensional orthogonal to the grid cell area to be computed. For T grid points, this results in the following grid cell areas: </p> <code>dim</code> Grid Cell Area <code>i</code> e2t * e3t <code>j</code> e1t * e3t <code>k</code> e1t * e2t"},{"location":"howto/#calculate-grid-cell-volumes","title":"Calculate Grid Cell Volumes","text":"<p>To calculate the volume of model grid cells, we can use the <code>.cell_volume()</code> method.</p> <p>For example, to compute the volume of each grid cell centered on a V grid point in the model parent domain:</p> <pre><code>nemo.cell_volume(grid=\"gridV\")\n</code></pre>"},{"location":"howto/#indexing-with-geographical-coordinates","title":"Indexing with Geographical Coordinates","text":"<p>To subset variables of a given model grid using their longitude &amp; latitude coordinates (i.e., <code>glam{t/u/v/w}(j, i)</code> &amp; <code>gphi{t/u/v/w}(j, i)</code>), we can add these geographical variables as indexes using the <code>.add_geoindex()</code> method.</p> <p>For example, to enable geographical indexing of the parent T grid points &amp; select the values of this dataset nearest to (-30\u00b0E, 60\u00b0N):</p> <pre><code>nemo_geo = nemo.add_geoindex(grid=\"gridT\")\n\nnemo_geo.dataset.sel(gphit=60, glamt=-30, method='nearest')\n</code></pre>"},{"location":"howto/#clip-a-nemo-model-grid","title":"Clip a NEMO Model Grid","text":"<p>To clip a given model grid using a geographical bounding box defined by a tuple of the form (<code>lon_min</code>, <code>lon_max</code>, <code>lat_min</code>, <code>lat_max</code>), we can use the <code>.clip_grid()</code> method.</p> <p>For example, to clip the parent T-grid in the bounding box (-80\u00b0E, 0\u00b0E, 40\u00b0N, 80\u00b0N):</p> <pre><code>bbox = (-80, 0, 40, 80)\n\nnemo.clip_grid(grid=\"gridT\", bbox=bbox)\n</code></pre>"},{"location":"howto/#clip-a-nemo-model-domain","title":"Clip a NEMO Model Domain","text":"<p>To clip all of the model grids of a given NEMO model domain:</p> <pre><code>nemo.clip_domain(dom=\".\", bbox=bbox)\n</code></pre> <p>where <code>dom</code> is the prefix of the chosen NEMO model domain. Note <code>dom=\".\"</code> for the parent domain.</p>"},{"location":"howto/#calculate-horizontal-gradients","title":"Calculate Horizontal Gradients","text":"<p>To calculate the gradient of a scalar variable <code>var</code> along one of the horizontal dimensions (e.g., <code>i</code>, <code>j</code>) of a given NEMO model grid, we can use the <code>.gradient()</code> method.</p> <p>For example, to compute the 'meridional' gradient of sea surface temperature <code>tos_con</code> along the NEMO model parent domain <code>j</code> dimension:</p> <pre><code>nemo.gradient(dom='.', var=\"tos_con\", dim=\"j\")\n</code></pre>"},{"location":"howto/#calculate-vertical-gradients","title":"Calculate Vertical Gradients","text":"<p>To calculate the vertical gradient of a scalar variable <code>var</code> along the <code>k</code> dimension of a given NEMO model grid, we can also use the <code>.gradient()</code> method.</p> <p>For example, to compute the vertical gradient of absolute salinity in our first NEMO model nested child domain:</p> <pre><code>nemo.gradient(dom=\"1\", var=\"so_abs\", dim=\"k\")\n</code></pre>"},{"location":"howto/#calculate-divergence","title":"Calculate Divergence","text":"<p>To calculate the horizontal divergence from the <code>i</code> and <code>j</code> components of a vector field, we can use the <code>.divergence()</code> method.</p> <p>For example, to compute the horizontal divergence from the seawater velocity field in the NEMO model parent domain:</p> <pre><code>nemo.divergence(dom=\".\", vars=[\"uo\", \"vo\"])\n</code></pre> <p>where <code>vars</code> is a list specifying the names of <code>i</code> and <code>j</code> vector components, respectively.</p>"},{"location":"howto/#calculate-curl","title":"Calculate Curl","text":"<p>To calculate the vertical <code>k</code> component of the curl of a horizontal vector field, we can use the <code>.curl()</code> method.</p> <p>For example, to compute the vertical component of the curl of the seawater velocity field in the second NEMO nested child domain:</p> <pre><code>nemo.curl(dom=\"2\", vars=[\"uo\", \"vo\"])\n</code></pre> <p>where, as in the case of <code>.divergence()</code>, the <code>vars</code> argument expects a list of the <code>i</code> and <code>j</code> components of the vector field, respectively.</p>"},{"location":"howto/#calculate-integrals","title":"Calculate Integrals","text":"<p>To integrate a variable along one or more dimensions of a given NEMO model grid, we can use the <code>.integral()</code> method.</p> <p>For example, to compute the integral of conservative temperature <code>thetao_con</code> along the vertical <code>k</code> dimension in the NEMO model parent domain:</p> <pre><code>nemo.integral(grid=\"gridT\", var=\"thetao_con\", dims=[\"k\"])\n</code></pre> <p>which will return an <code>xarray.DataArray</code> with one less dimension than <code>thetao_con</code>, in this case <code>k</code> since we have integrated vertically.</p>"},{"location":"howto/#calculate-cumulative-integrals","title":"Calculate Cumulative Integrals","text":"<p>We can also use the <code>.integral()</code> method to calculate cumulative integrals along one or more dimensions of a given NEMO model grid.</p> <p>For example, to calculate the vertical meridional overturning stream function from the meridional velocity <code>vo</code> (zonally integrated meridional velocity accumulated with increasing depth):</p> <pre><code>nemo.integral(grid=\"gridV\",\n              var=\"vo\",\n              dims=[\"i\", \"k\"], \n              cum_dims=[\"k\"],\n              dir=\"+1\",\n              )\n</code></pre> <p>where <code>dims</code> is a list of the names of all grid dimensions along which integration will be performed, and <code>cum_dims</code> specifies which of the dimensions in <code>dims</code> should be cumulatively integrated.</p> <p>The <code>dir</code> argument is used to define the direction of cumulative integration, where <code>dir = \"+1\"</code> means accumulating along the chosen dimension, such that grid indices are increasing. Conversely, <code>dir = \"-1\"</code> means that cumulative integration is performed after reversing the chosen dimension, such that grid dimensions are decreasing.</p> <p>Note, we can also pass the <code>mask</code> argument to <code>.integral()</code> to mask the variable <code>var</code> prior to performing the integration.</p>"},{"location":"howto/#calculate-depth-integrals","title":"Calculate Depth Integrals","text":"<p>To integrate a variable of a given NEMO model grid in depth coordinates between two limits, we can use the <code>.depth_integral()</code> method.</p> <p>For example, to compute the vertical integral of conservative temperature <code>thetao_con</code> in the upper 100 m in the NEMO model parent domain:</p> <pre><code>nemo.depth_integral(grid='gridT', var='thetao_con', limits=(0, 100))\n</code></pre> <p>where <code>limits</code> is a tuple of the form (depth_lower, depth_upper) where depth_lower and depth_upper are the lower and upper limits of vertical integration, respectively.</p>"},{"location":"howto/#create-regional-masks-using-polygons","title":"Create Regional Masks using Polygons","text":"<p>To define a regional mask using the geographical coordinates of a closed polygon, we can use the <code>.mask_with_polygon()</code> method:</p> <pre><code>nemo.mask_with_polygon(grid=\"gridT\", lon_poly, lat_poly)\n</code></pre> <p>where <code>lon_poly</code> and <code>lat_poly</code> are lists or ndarrays containing the longitude and latitude coordinates defining the closed polygon.</p>"},{"location":"howto/#calculate-statistics-for-a-region-masked-using-a-polygon","title":"Calculate Statistics for a Region Masked using a Polygon","text":"<p>To calculate an aggregated statistic from only the model grid cells contained inside a geographical polygon, we can use the <code>.masked_statistic()</code> method.</p> <p>For example, to compute the grid cell area-weighted mean sea surface temperature <code>tos_con</code> for a region enclosed in a polygon defined by <code>lon_poly</code> and <code>lat_poly</code> in a NEMO model nested child domain:</p> <pre><code>nemo.masked_statistic(grid=\"gridT/1_gridT\",\n                      var=\"tos_con\",\n                      lon_poly,\n                      lat_poly,\n                      statistic=\"weighted_mean\",\n                      dims=[\"i\", \"j\"]\n                      )\n</code></pre> <p>where <code>dims</code> represent the dimensions of the NEMO model grid used for aggregation. In this example, combining <code>statistic=\"weighted_mean\"</code> and <code>dims=[\"i\", \"j\"]</code> is equivalent to computing the mean of variable <code>tos_con</code> using the horizontal cell area of T grid points (i.e., e1t * e2t) as weights.</p>"},{"location":"howto/#calculate-binned-statistics","title":"Calculate Binned Statistics","text":"<p>To calculate aggregated statistics of a variable binned according to the values of one or more variables, we can use the <code>.binned_statistic()</code> method. </p> <p>This is a generalization of a histogram function, enabling the computation of the sum, mean, median, or other statistic of the values assigned to each bin.</p> <p>For example, to compute the mean depth associated with each isopycnal in discrete potential density (<code>sigma0</code>) coordinates:</p> <pre><code>sigma0_bins = np.arange(22, 29.05, 0.05)\n\nnemo.binned_statistic(grid=\"gridT\",\n                      vars=[\"sigma0\"],\n                      values=\"deptht\",\n                      keep_dims=[\"time_counter\"],\n                      bins=[sigma0_bins],\n                      statistic=\"nanmean\",\n                      )\n</code></pre> <p>where <code>vars</code> is a list of the names of variables to be binned using the bin edges passed to <code>bins</code>, and <code>values</code> is the name of the variable over which the <code>statistic</code> will be performed once values have been grouped into each bin.</p> <p>We can use <code>keep_dims</code> to specify the dimensions of the <code>xarray.DataArray</code> named <code>values</code> to retain. In the example above, using <code>keep_dims=\"time_counter\"</code> will return the average depths of water in each potential density bin for each time-slice of available NEMO model output.</p>"},{"location":"howto/#transform-variable-to-a-neighbouring-horizontal-grid","title":"Transform Variable to a Neighbouring Horizontal Grid","text":"<p>To transform a variable defined on a given NEMO horizontal grid to a neighbouring grid using linear interpolation, we can use the <code>.transform_to()</code> method.</p> <p>For example, to transform conservative temperature <code>thetao_con</code> defined on scalar T-points to neighbouring V-points in a NEMO model parent domain:</p> <pre><code>nemo.transform_to(grid='gridT', var='thetao_con', to='V')\n</code></pre> <p>We can also transform variables defined on U- and V-points to either scalar or vector grid points. Unlike transforming scalar variables defined on T-points, this is achieved by linearly interpolating the grid cell face area-weighted flux onto the target grid, before then normalising by the grid cell face area defined on the target horizontal grid.</p> <p>For example, to transform the zonal wind stress defined on U-points to neighbouring V-points in a NEMO model parent domain and store this in the V-grid node of our NEMODataTree:</p> <pre><code>nemo['gridV']['tauuo'] = nemo.transform_to(grid='gridU', var='tauuo', to='V')\n</code></pre>"},{"location":"howto/#transform-a-vertical-grid","title":"Transform a Vertical Grid","text":"<p>To transform a variable defined on a given NEMO model vertical grid to a new vertical grid using conservative interpolation, we can use the <code>.transform_vertical_grid()</code> method.</p> <p>For example, if we wanted to transform the conservative temperature variable <code>thetao_con</code> defined in a NEMO model parent domain from it's native 75 unevenly-spaced z-levels to regularly spaced z-levels at 200 m intervals:</p> <pre><code>e3t_target = xr.DataArray(np.repeat(200.0, 30), dims=['k_new'])\n\nnemo.transform_vertical_grid(grid='gridT',\n                             var = 'thetao_con',\n                             e3_new = e3t_target\n                            )\n</code></pre> <p>where <code>e3_new</code> represents the time-invariant vertical grid cell thicknesses defing the vertical grid onto which the variable <code>var</code> will be conservatively interpolated. </p> <p>There are some important points to remember when transforming variables onto new vertical grids with <code>NEMODataTree</code>:</p> <ul> <li> <p>New vertical grid cell thicknesses <code>e3_new</code> must sum to at least the maximum depth of the original vertical grid cell thicknesses (e.g., e3t).</p> </li> <li> <p>Currently, <code>e3_new</code> must be a 1-dimensional <code>xarray.DataArray</code> with dimension 'k_new'.</p> </li> <li> <p>The output <code>xarray.Dataset</code> will contain multi-dimensional <code>xarray.DataArrays</code> for both the vertically remapped variable <code>var(time_counter, k_new, j, i)</code> and the vertical grid cell thicknesses <code>e3t_new(time_counter, k_new, j, i)</code> (updated to explicitly account for partial grid cells above the seafloor).</p> </li> </ul>"},{"location":"nemodatatree/","title":"User Guide","text":""},{"location":"nemodatatree/#nemodatatree","title":"NEMODataTree","text":"<p>Each recipe in the NEMO Cookbook leverages the <code>NEMODataTree</code> object to store NEMO ocean model outputs and to help perform diagnostic calculations.</p> <p>In this User Guide, we provide an introduction to the <code>NEMODataTree</code>, including examples using outputs from the NEMO version 5 <code>AGRIF_DEMO</code> and <code>AMM12</code> reference configurations.</p> <p>For further details on <code>NEMODataTree</code> constructors, properties and computation patterns, users are referred to the API documentation.</p>"},{"location":"nemodatatree/#what-is-a-datatree","title":"What is a DataTree?","text":"<p>Ocean model simulations produce large collections of datasets, including physics, biogeochemistry, and sea ice diagnostics, which are defined on different grids. Moreover, ocean models configuration often include nested domains, where datasets of model diagnostics are produced for each of the parent, child and grandchild domains.</p> <p>Organising these gridded datasets into a single, interpretable data structure has traditionally been a major challenge for researchers when developing their data analysis workflows.</p> <p>This is where the <code>xarray.DataTree</code> comes in.</p> <p>The <code>xarray.DataTree</code> extends the more familiar collection of xarray data structures (e.g., <code>xarray.Dataset</code>) to allow hierarchical grouping of datasets, similar to a local file system. Each <code>xarray.DataTree</code> is composed of a hierarchy of nodes, each containing a separate <code>xarray.Dataset</code>. </p> <pre><code>&lt;xarray.DataTree 'OceanModel'&gt;\nGroup: /\n\u2514\u2500\u2500 Group: /global\n    \u251c\u2500\u2500 Group: /global/regional_nest_1\n    \u2514\u2500\u2500 Group: /global/regional_nest_2\n</code></pre> <p>The root node sits at the top of the DataTree ('/') and each of its child nodes can have children (or sub-groups) of their own. In the example above, the root node has a single child node (<code>global</code>) storing the global domain outputs of an ocean model simulation <code>OceanModel</code>. This in-turn has two child nodes (<code>regional_nest_1</code> &amp; <code>regional_nest_2</code>) storing the outputs of two regional nests located inside the global domain.</p> <p>We can hence describe each node in a DataTree in terms of the <code>parent</code> to which the node belongs, and its <code>children</code> - child nodes to which it is the parent. The root node is an important exception however, since it has no <code>parent</code> node.</p> <p>To access a node in our DataTree, we use Python's standard dictionary syntax to define the path to the target node in the DataTree as follows:</p> <pre><code>dt['global/regional_nest']\n</code></pre> <p>We can then access the variables stored in the <code>xarray.Dataset</code> associated with a given node as follows:</p> <pre><code>ds['global/regional_nest']['var_name']\n</code></pre> <p>In summary, an <code>xarray.DataTree</code> can help ocean modellers organise complex outputs (nested domains, groups of variables) in a natural, hierarchical way by acting as a container for a collection of related  <code>xarray.Datasets</code>.</p>"},{"location":"nemodatatree/#what-is-a-nemodatatree","title":"What is a NEMODataTree?   |","text":"<p><code>NEMODataTree</code> is an extension of the <code>xarray.DataTree</code> structure designed to store NEMO model output datasets as nodes in a hierarchical tree.</p>"},{"location":"nemodatatree/#nemo-model-grid","title":"NEMO Model Grid","text":"<p>The NEMO Ocean Engine (Madec et al., 2024) solves the Primitive Equations using the traditional, centred second-order finite difference approximation.</p> <p>Variables are spatially discretised using a 3-dimensional Arakawa \u201cC\u201d grid (Mesinger and Arakawa, 1976), consisting of cells centred on scalar points T (e.g. temperature, salinity, density, and horizontal divergence).</p> <p>Vector points (u, v, w) are defined at the centre of each cell face. The relative and planetary vorticity, \u03b6 and f, are defined at f points, which are located at the centre of each vertical edge.</p> <p>In NEMO, the ocean mesh (i.e. the position of all the scalar and vector points) is defined in terms of a set of orthogonal curvilinear grid indices (i, j, k), such that geographical coordinates are given as functions of these grid indices (i.e., \u03bb(j, i), \u03c6(j, i), z(k)).</p> <p>All grid-points on the ocean mesh are located at integer or integer and a half values of (i, j, k) as shown below:</p> Grid Type Grid Indices <code>T</code> (i, j, k) <code>U</code> (i + 1/2, j, k) <code>V</code> (i, j + 1/2, k) <code>W</code> (i, j, k + 1/2) <code>F</code> (i + 1/2, j + 1/2, k) <p>For each type of grid-point, three grid scale factors are defined... </p> <ul> <li>Horizontal scale factors (e1, e2)</li> <li>Vertical scale factor (e3)</li> </ul> <p>...such that the volume of a given type of grid cell is given by (e1<sub>k</sub> e2<sub>k</sub> e3<sub>k</sub>), where k is the grid point type. Similarly, the horizontal grid cell area is given by (e1<sub>k</sub> e2<sub>k</sub>).</p> <p>For more information on the spatial discretisation of variables in NEMO, see Chapter 3 of the NEMO Reference Manual.</p>"},{"location":"nemodatatree/#nemo-outputs","title":"NEMO Outputs","text":"<p>Although many experienced researchers will be familiar with the typical output format of NEMO model simulations, we provide a brief summary below for new users.</p> <p>NEMO model simulations write time-averaged diagnostics to output files in netCDF4 format using an external I/O library and server named XIOS.</p> <p>Typically, separate netCDF files are produced at each time-averaging interval (e.g., monthly) for groups of variables located at the same type of grid points. This results in the following types of netCDF files:</p> <ul> <li> <p><code>...grid_T.nc</code>  scalar variables (e.g., conservative temperature &amp; absolute salinity) defined at the centre of each model grid cell.</p> </li> <li> <p><code>...grid_U.nc</code>  vector variables (e.g., zonal seawater velocity) defined at the centre of each eastern grid cell face.</p> </li> <li> <p><code>...grid_V.nc</code>  vector variables (e.g., meridional seawater velocity) defined at the centre of each northern grid cell face.</p> </li> <li> <p><code>...grid_W.nc</code>  vector variables (e.g., vertical seawater velocity) defined at the centre of each bottom grid cell face.</p> </li> <li> <p><code>...grid_F.nc</code>  vector variables (e.g., relative vorticity) defined at the centre of each vertical edge.</p> </li> </ul> <p>Often global scalar diagnostics (e.g., global mean temperature) are also produced, resulting in a further type of netCDF file:</p> <ul> <li><code>...scalar.nc</code>  1-dimensional scalar variables calculated by aggregating a variable defined on the model T grid.</li> </ul> <p>When the NEMO ocean engine is coupled to a sea ice model (e.g., SI3), netCDF files will also be produced for sea ice variables using the following suffix:</p> <ul> <li><code>...icemod.nc</code>  sea ice variables (e.g., sea ice concetration) defined at the centre of each model grid cell.</li> </ul>"},{"location":"nemodatatree/#defining-a-simple-nemodatatree","title":"Defining a Simple NEMODataTree","text":"<p>For a typical NEMO model configuration, consisting of a global parent domain coupled to a sea ice model, we can define a simple <code>DataTree</code>:</p> <pre><code>&lt;xarray.DataTree 'nemo'&gt;\nGroup: /\n\u251c\u2500\u2500 Group: /gridT\n\u251c\u2500\u2500 Group: /gridU\n\u251c\u2500\u2500 Group: /gridV\n\u251c\u2500\u2500 Group: /gridW\n\u2514\u2500\u2500 Group: /gridF\n</code></pre> <p>where the <code>gridT</code> child node contains time series of scalar variables stored in the <code>...grid_T.nc</code> files in a single <code>xarray.Dataset</code> and so on.</p>"},{"location":"nemodatatree/#domain-variables","title":"Domain Variables","text":"<p>Importantly, a <code>NEMODataTree</code> does not need a <code>domain</code> node to store the grid scale factors and masks associated with each model domain. </p> <p>Why?</p> <p>This is because domain variables are assigned to their respective grid nodes during pre-processing (e.g., horizontal grid scale factors <code>e1t</code> and <code>e2t</code> are stored in <code>gridT</code> etc.).</p>"},{"location":"nemodatatree/#dimensions-coordinates","title":"Dimensions &amp; Coordinates","text":"<p>Typically, the netCDF files output by NEMO model simulations have dimensions (<code>depth{k}</code>, <code>y</code>, <code>x</code>), where k is the grid point type.</p> <p>During the construction of a NEMODataTree, these coordinate dimensions are transformed into the NEMO model grid indices (i, j, k) according to the Table included in the NEMO Model Grid section above. This has two important implications:</p> <ol> <li> <p>The <code>xarray.Datasets</code> stored in each grid node share the same coordinate dimension names (<code>i</code>, <code>j</code>, <code>k</code>), but are staggered according to where variables are position on the NEMO model grid.</p> </li> <li> <p>All grid indices use Fortran (1-based) indexing consistent with their definition in the original NEMO model code.</p> </li> </ol> <p>In practice, this means that a variable defined at the first T-point will be at (<code>i=1</code>, <code>j=1</code>), whereas a variable located at the first U-point will be at (<code>i=1.5</code>, <code>j=1</code>). This approach was chosen to ensure users encounter alignment errors when attempting to calculate diagnostics using variables defined on different grids. Instead, scalar or vector variables should be interpolated onto the desired grid before computation.</p> <p>A further practical implication is that users should always use <code>.sel()</code> to subset data variables according to their grid indices on the NEMO ocean mesh.</p>"},{"location":"nemodatatree/#summary","title":"Summary","text":"<p>Below we summarise the steps required to define a <code>NEMODataTree</code> from a collection of output netCDF files:</p> <p>Steps to Define a NEMODataTree</p> <ol> <li> <p>For each type of netCDF output, open all available files as a single <code>xarray.Dataset</code> using <code>xarray.open_mfdataset()</code>.</p> </li> <li> <p>Add domain variables stored in the domain_cfg.nc file to the each grid dataset (e.g., <code>e1t</code>, <code>e2t</code> are added to <code>gridT</code>).</p> </li> <li> <p>Add / calculate masks for each grid type (e.g., <code>tmask</code> is added to <code>gridT</code>).</p> </li> <li> <p>Redefine the <code>dims</code> and <code>coords</code> of each grid dataset to use <code>i</code>, <code>j</code>, <code>k</code> as used to define the semi-discrete equations in NEMO.</p> </li> <li> <p>Assemble the <code>xarray.DataTree</code> using a dictionary of processed NEMO model grid datasets.</p> </li> </ol> <p>The steps above highlight that the <code>NEMODataTree</code> is simply a specific case of the more general <code>xarray.DataTree</code> structure.</p>"},{"location":"nemodatatree/#defining-a-nested-nemodatatree","title":"Defining a Nested NEMODataTree","text":"<p>For a nested NEMO model configuration, including a parent, child and grandchild domain, we can define a more complex <code>NEMODataTree</code>:</p> <pre><code>&lt;xarray.DataTree 'nemo'&gt;\nGroup: /\n\u251c\u2500\u2500 Group: /gridT\n|   \u2514\u2500\u2500 Group: /gridT/1_gridT\n|       \u2514\u2500\u2500 Group: /gridT/1_gridT/2_gridT\n\u251c\u2500\u2500 Group: /gridU\n|   \u2514\u2500\u2500 Group: /gridU/1_gridU\n|       \u2514\u2500\u2500 Group: /gridU/1_gridU/2_gridU\n\u251c\u2500\u2500 Group: /gridV\n|   \u2514\u2500\u2500 Group: /gridV/1_gridV\n|       \u2514\u2500\u2500 Group: /gridV/1_gridV/2_gridV\n\u251c\u2500\u2500 Group: /gridW\n|   \u2514\u2500\u2500 Group: /gridW/1_gridW\n|       \u2514\u2500\u2500 Group: /gridW/1_gridW/2_gridW\n\u2514\u2500\u2500 Group: /gridF\n    \u2514\u2500\u2500 Group: /gridF/1_gridF\n        \u2514\u2500\u2500 Group: /gridF/1_gridF/2_gridF\n</code></pre> <p>where each parent grid node (e.g., <code>gridT</code>) has a corresponding child grid node (e.g., <code>1_gridT</code>), which itself has a corresponding child (grandchild) node (e.g., <code>2_gridT</code>).</p>"},{"location":"nemodatatree/#domain-variables_1","title":"Domain Variables","text":"<p>Nested child / grandchild domain variables are also assigned to their respective grid nodes during pre-processing (e.g., horizontal grid scale factors <code>e1t</code> and <code>e2t</code> are stored in <code>gridT</code> etc.).</p>"},{"location":"nemodatatree/#dimensions-coordinates_1","title":"Dimensions &amp; Coordinates","text":"<p>To ensure that the dimensions of nested child / grandchild domains are distinct from their parent, a prefix is added to all grid indices and associated geographical coordinate variables.</p> <p>The prefix corresponds to the unique domain number used to identify each child and grandchild domain during the construction the <code>NEMODataTree</code>. Hence, in the example above, the child grid node <code>1_gridT</code> will have NEMO model grid indices (<code>i1</code>, <code>j1</code>, <code>k1</code>) and associated coordinates <code>1_glamt(j1, i1)</code>, <code>1_gphit(j1, i1)</code> etc.</p>"},{"location":"nemodatatree/#summary_1","title":"Summary","text":"<p>In summary, defining a <code>NEMODataTree</code> for a nested configuration includes two important additional steps:</p> <p>Steps to Define a NEMODataTree</p> <ol> <li> <p>For each type of netCDF output, open all available files as a single <code>xarray.Dataset</code> using <code>xarray.open_mfdataset()</code>.</p> </li> <li> <p>Add domain variables stored in the domain_cfg.nc file to the each grid dataset (e.g., <code>e1t</code>, <code>e2t</code> are added to <code>gridT</code>).</p> </li> <li> <p>Add / calculate masks for each grid type (e.g., <code>tmask</code> is added to <code>gridT</code>).</p> </li> <li> <p>Redefine the <code>dims</code> and <code>coords</code> of each grid dataset to use <code>i{dom}</code>, <code>j{dom}</code>, <code>k{dom}</code> as used to define the semi-discrete equations in NEMO, where dom is the unique domain number.</p> </li> <li> <p>Clip nested child domains to remove ghost points along the boundaries &amp; add a mapping from the parent grid indices to the child grid indices to the <code>coords</code>.</p> </li> <li> <p>Assemble dictionaries of processed NEMO model grid datasets for each of the parent, child and grandchild domains.</p> </li> <li> <p>Assemble the <code>xarray.DataTree</code> using a nested dictionary of NEMO model domains.</p> </li> </ol>"},{"location":"nemodatatree/#example-nemodatatrees","title":"Example NEMODataTrees","text":"<p>In this section, we demonstrate how to construct <code>NEMODataTrees</code> using global, regional, nested and coupled NEMO ocean sea-ice outputs.</p> <p>Users can also explore the following examples using the <code>example_nemodatatrees.ipynb</code> Jupyter Notebook available in the <code>recipes</code> directory.</p> <p>To get started, let's begin by importing the Python packages we'll be using:</p> <pre><code>import xarray as xr\nimport nemo_cookbook as nc\nfrom nemo_cookbook import NEMODataTree\n</code></pre>"},{"location":"nemodatatree/#global-ocean-sea-ice-models","title":"Global Ocean Sea-Ice Models:","text":"<p>1. <code>AGRIF_DEMO</code></p> <p>Let's start by creating a <code>NEMODataTree</code> using example outputs from the global <code>AGRIF_DEMO</code> NEMO reference configuration.</p> <p><code>AGRIF_DEMO</code> is based on the <code>ORCA2_ICE_PISCES</code> reference configuration with the inclusion of 3 online nested domains.</p> <p>Here, we will only consider the 2\u00b0 global parent domain.</p> <p>Further information on this reference configuration can be found here.</p> <p>NEMO Cookbook includes a selection of example NEMO model output datasets accessible via cloud object storage.</p> <p><code>nemo_cookbook.examples.get_filepaths()</code> is a convenience function used to download and generate local filepaths for an available NEMO reference configuration.</p> <pre><code>filepaths = nc.examples.get_filepaths(\"AGRIF_DEMO\")\n\nfilepaths\n</code></pre> <p>The <code>get_filepaths()</code> function will download each of the files to your local machine, returning a dictionary of filepaths for the chosen configuration (<code>AGRIF_DEMO</code>):</p> <pre><code>{'domain_cfg.nc': '/Users/me/Library/Caches/nemo_cookbook/AGRIF_DEMO/domain_cfg.nc',\n '2_domain_cfg.nc': '/Users/me/Library/Caches/nemo_cookbook/AGRIF_DEMO/2_domain_cfg.nc',\n '3_domain_cfg.nc': '/Users/me/Library/Caches/nemo_cookbook/AGRIF_DEMO/3_domain_cfg.nc',\n 'ORCA2_5d_00010101_00010110_grid_T.nc': '/Users/me/Library/Caches/nemo_cookbook/AGRIF_DEMO/ORCA2_5d_00010101_00010110_grid_T.nc',\n ...\n '3_Nordic_5d_00010101_00010110_icemod.nc': '/Users/me/Library/Caches/nemo_cookbook/AGRIF_DEMO/3_Nordic_5d_00010101_00010110_icemod.nc'\n }\n</code></pre> <p>Next, we need to define the <code>paths</code> dictionary, which contains the filepaths corresponding to our global parent domain.</p> <p>We populate the <code>parent</code> dictionary with the filepaths to the <code>domain_cfg</code> and <code>gridT/U/V/W</code> netCDF files produced for the <code>AGRIF_DEMO</code> parent domain. </p> <pre><code>paths = {\"parent\": {\n         \"domain\": filepaths[\"domain_cfg.nc\"],\n         \"gridT\": filepaths[\"ORCA2_5d_00010101_00010110_grid_T.nc\"],\n         \"gridU\": filepaths[\"ORCA2_5d_00010101_00010110_grid_U.nc\"],\n         \"gridV\": filepaths[\"ORCA2_5d_00010101_00010110_grid_V.nc\"],\n         \"gridW\": filepaths[\"ORCA2_5d_00010101_00010110_grid_W.nc\"],\n         \"icemod\": filepaths[\"ORCA2_5d_00010101_00010110_icemod.nc\"]\n        },\n        }\n</code></pre> <p>We can construct a new <code>NEMODataTree</code> called <code>nemo</code> using the <code>.from_paths()</code> constructor.</p> <p>Notice, that we also need to specify that our global parent domain is zonally periodic (<code>iperio=True</code>) and north folding on T-points (<code>nftype = \"T\"</code>) rather than a closed (regional) domain.</p> <pre><code>nemo = NEMODataTree.from_paths(paths, iperio=True, nftype=\"T\")\n\nnemo\n</code></pre> <p>This returns the following <code>xarray.DataTree</code>, where we have truncated the outputs for improved readability:</p> <pre><code>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:               (time_counter: 2, axis_nbounds: 2, ncatice: 5)\n\u2502   ...\n\u2502 \n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:               (time_counter: 2, axis_nbounds: 2, j: 148, i: 180,\n\u2502                                  ncatice: 5, k: 31)\n\u2502       Coordinates:\n\u2502           time_centered         (time_counter) object 16B 0001-01-03 12:00:00 0001-...\n\u2502         * deptht                (k) float32 124B 5.0 15.0 25.0 ... 4.75e+03 5.25e+03\n\u2502           time_instant          (time_counter) object 16B ...\n\u2502           gphit                 (j, i) float64 213kB ...\n\u2502           glamt                 (j, i) float64 213kB ...\n\u2502         * k                     (k) int64 248B 1 2 3 4 5 6 7 ... 25 26 27 28 29 30 31\n\u2502         * j                     (j) int64 1kB 1 2 3 4 5 6 ... 143 144 145 146 147 148\n\u2502         * i                     (i) int64 1kB 1 2 3 4 5 6 ... 175 176 177 178 179 180\n\u2502       Dimensions without coordinates: axis_nbounds\n\u2502       Data variables: (12/87)\n\u2502           time_centered_bounds  (time_counter, axis_nbounds) object 32B 0001-01-01 ...\n\u2502           time_counter_bounds   (time_counter, axis_nbounds) object 32B 0001-01-01 ...\n\u2502           simsk                 (time_counter, j, i) float32 213kB ...\n\u2502           simsk05               (time_counter, j, i) float32 213kB ...\n\u2502           simsk15               (time_counter, j, i) float32 213kB ...\n\u2502           snvolu                (time_counter, j, i) float32 213kB ...\n\u2502           ...                    ...\n\u2502           e1t                   (j, i) float64 213kB ...\n\u2502           e2t                   (j, i) float64 213kB ...\n\u2502           top_level             (j, i) int32 107kB ...\n\u2502           bottom_level          (j, i) int32 107kB ...\n\u2502           tmask                 (k, j, i) bool 826kB False False False ... False False\n\u2502           tmaskutil             (j, i) bool 27kB False False False ... False False\n\u2502       Attributes:\n\u2502           name:         ORCA2_5d_00010101_00010110_icemod\n\u2502           description:  ice variables\n\u2502           title:        ice variables\n\u2502           Conventions:  CF-1.6\n\u2502           timeStamp:    2025-Sep-13 17:44:13 GMT\n\u2502           uuid:         c6c24bd5-1d2b-4d7b-98b5-8d379c94e84b\n\u2502           nftype:       T\n\u2502           iperio:       True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:               (k: 31, axis_nbounds: 2, time_counter: 2, j: 148,\n\u2502                                  i: 180)\n\u2502       ...\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:               (k: 31, axis_nbounds: 2, time_counter: 2, j: 148,\n\u2502                                  i: 180)\n\u2502       ...\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:               (k: 31, axis_nbounds: 2, time_counter: 2, j: 148,\n\u2502                                  i: 180)\n\u2502       ...\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 148, i: 180, k: 31)\n        ...\n</code></pre> <p>2. <code>NOC Near-Present Day eORCA1</code></p> <p>Next, we'll consider monthly-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using ERA5 atmospheric reanalysis from 1976-present. </p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p> <p>The eORCA1 ERA5v1 NPD data are stored in publicly available Icechunk repositories accessible via the NOC OceanDataStore library. In this example, we will show how to use to the OceanDataCatalog API to remotely access NOC NPD outputs and use the <code>.from_datasets()</code> constructor to create a NEMODataTree.</p> <p>Users can find more information on how to get started using the OceanDataCatalog to search for and access available NEMO model outputs here.</p> <pre><code>from OceanDataStore import OceanDataCatalog\n\n# Create a new OceanDataCatalog to access the NOC STAC:\ncatalog = OceanDataCatalog(catalog_name=\"noc-model-stac\")\n\n# Opening domain_cfg:\nds_domain = catalog.open_dataset(id=\"noc-npd-era5/npd-eorca1-era5v1/gn/domain/domain_cfg\")\n\n# Opening gridT dataset, including sea surface temperature (\u00b0C) and sea surface height (m):\nds_gridT = catalog.open_dataset(id=\"noc-npd-era5/npd-eorca1-era5v1/gn/T1m\",\n                                variable_names=['tos_con', 'zos'],\n                                start_datetime='2000-01',\n                                end_datetime='2020-12',\n                                )\n</code></pre> <p>Next, let's create a <code>NEMODataTree</code> from a dictionary of eORCA1 ERA5v1 <code>xarray.Datasets</code>, specifying that our global domain is zonally periodic (<code>iperio=True</code>) and north folding on T-points (<code>nftype = \"F\"</code>).</p> <pre><code>datasets = {\"parent\": {\"domain\": ds_domain.squeeze(), \"gridT\": ds_gridT}}\n\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</code></pre> <pre><code>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 240)\n\u2502   ...\n\u2502 \n\u251c\u2500\u2500 Group: /gridT\n\u2502   Dimensions:        (time_counter: 240)\n\u2502       Dimensions:        (time_counter: 240, j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502           time_centered  (time_counter) datetime64[ns] 5kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502       Data variables:\n\u2502           tos_con        (time_counter, j, i) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           zos            (time_counter, j, i) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           e1t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level      (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level   (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502           tmaskutil      (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       ...\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       ...\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       ...\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        ...\n</code></pre>"},{"location":"nemodatatree/#regional-ocean-models","title":"Regional Ocean Models:","text":"<p><code>AMM12</code></p> <p>We can also construct a <code>NEMODataTree</code> using outputs from regional NEMO ocean model simulations.</p> <p>Here, we will consider example outputs from the regional <code>AMM12</code> NEMO reference configuration.</p> <p>The AMM, Atlantic Margins Model, is a regional model covering the Northwest European Shelf domain on a regular lat-lon grid at approximately 12km horizontal resolution. <code>AMM12</code> uses the vertical s-coordinates system, GLS turbulence scheme, and tidal lateral boundary conditions using a flather scheme.</p> <p>Further information on this reference configuration can be found here.</p> <pre><code>filepaths = nc.examples.get_filepaths(\"AMM12\")\n\nfilepaths\n</code></pre> <pre><code>{'domain_cfg.nc': '/Users/me/Library/Caches/nemo_cookbook/AMM12/domain_cfg.nc',\n 'AMM12_1d_20120102_20120110_grid_T.nc': '/Users/me/Library/Caches/nemo_cookbook/AMM12/AMM12_1d_20120102_20120110_grid_T.nc',\n 'AMM12_1d_20120102_20120110_grid_U.nc': '/Users/me/Library/Caches/nemo_cookbook/AMM12/AMM12_1d_20120102_20120110_grid_U.nc',\n 'AMM12_1d_20120102_20120110_grid_V.nc': '/Users/me/Library/Caches/nemo_cookbook/AMM12/AMM12_1d_20120102_20120110_grid_V.nc'\n }\n</code></pre> <p>As we showed in the <code>AGRIF_DEMO</code> example, we need to populate the <code>paths</code> dictionary with the <code>domain_cfg</code> and <code>gridT/U/V</code> filepaths corresponding to our regional model domain.</p> <pre><code>paths = {\"parent\": {\n         \"domain\": filepaths[\"domain_cfg.nc\"],\n         \"gridT\": filepaths[\"AMM12_1d_20120102_20120110_grid_T.nc\"],\n         \"gridU\": filepaths[\"AMM12_1d_20120102_20120110_grid_U.nc\"],\n         \"gridV\": filepaths[\"AMM12_1d_20120102_20120110_grid_V.nc\"],\n        },\n        }\n</code></pre> <p>Next, we can construct a new <code>NEMODataTree</code> called <code>nemo</code> using the <code>.from_paths()</code> constructor.</p> <p>Note, we do not actually need to specify that our regional domain is not zonally periodic in this case, given that, by default, <code>iperio=False</code>.</p> <pre><code>nemo = NEMODataTree.from_paths(paths, iperio=False)\n\nnemo\n</code></pre> <pre><code>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:               (time_counter: 8, axis_nbounds: 2)\n\u2502   ...\n\u2502 \n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:               (time_counter: 8, axis_nbounds: 2, j: 224, i: 198,\n\u2502                                  k: 51)\n\u2502       Coordinates:\n\u2502           time_centered         (time_counter) datetime64[ns] 64B ...\n\u2502           gphit                 (j, i) float64 355kB ...\n\u2502           glamt                 (j, i) float64 355kB ...\n\u2502         * k                     (k) int64 408B 1 2 3 4 5 6 7 ... 45 46 47 48 49 50 51\n\u2502         * j                     (j) int64 2kB 1 2 3 4 5 6 ... 219 220 221 222 223 224\n\u2502         * i                     (i) int64 2kB 1 2 3 4 5 6 ... 193 194 195 196 197 198\n\u2502       Dimensions without coordinates: axis_nbounds\n\u2502       Data variables:\n\u2502           time_centered_bounds  (time_counter, axis_nbounds) datetime64[ns] 128B ...\n\u2502           time_counter_bounds   (time_counter, axis_nbounds) datetime64[ns] 128B ...\n\u2502           tos                   (time_counter, j, i) float32 1MB ...\n\u2502           sos                   (time_counter, j, i) float32 1MB ...\n\u2502           zos                   (time_counter, j, i) float32 1MB ...\n\u2502           e1t                   (j, i) float64 355kB ...\n\u2502           e2t                   (j, i) float64 355kB ...\n\u2502           top_level             (j, i) int32 177kB ...\n\u2502           bottom_level          (j, i) int32 177kB ...\n\u2502           tmask                 (k, j, i) bool 2MB False False False ... False False\n\u2502           tmaskutil             (j, i) bool 44kB False False False ... False False\n\u2502       Attributes:\n\u2502           nftype:   None\n\u2502           iperio:   False\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:               (time_counter: 8, axis_nbounds: 2, j: 224, i: 198,\n\u2502                                  k: 51)\n\u2502       ...\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:               (time_counter: 8, axis_nbounds: 2, j: 224, i: 198,\n\u2502                                  k: 51)\n\u2502       ...\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 224, i: 198, k: 51)\n\u2502       ...\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 224, i: 198, k: 51)\n        ...\n</code></pre>"},{"location":"nemodatatree/#nested-global-ocean-sea-ice-models","title":"Nested Global Ocean Sea-Ice Models:","text":"<p><code>AGRIF_DEMO</code></p> <p>Returning to our <code>AGRIF_DEMO</code> NEMO reference configuration, we can also construct a more complex <code>NEMODataTree</code> to store the outputs of the global parent and its child domains in a single data structure.</p> <p>We will make use of the two successively nested domains located in the Nordic Seas, with the finest grid (1/6\u00b0) spanning the Denmark strait. This grandchild domain also benefits from \u201cvertical nesting\u201d, meaning that it has 75 geopotential z-coordinate levels, compared with 31 levels in its parent domain.</p> <pre><code>filepaths = nc.examples.get_filepaths(\"AGRIF_DEMO\")\n</code></pre> <p>Let's start by defining the <code>paths</code> dictionary for the ORCA2 global parent domain and its child and grandchild domains. Notice, that for <code>child</code> and <code>grandchild</code> domains, we must also specify a unique domain number, given that we could include further child or grandchild nests.</p> <pre><code>paths = {\"parent\": {\n        \"domain\": filepaths[\"domain_cfg.nc\"],\n        \"gridT\": filepaths[\"ORCA2_5d_00010101_00010110_grid_T.nc\"],\n        \"gridU\": filepaths[\"ORCA2_5d_00010101_00010110_grid_U.nc\"],\n        \"gridV\": filepaths[\"ORCA2_5d_00010101_00010110_grid_V.nc\"],\n        \"gridW\": filepaths[\"ORCA2_5d_00010101_00010110_grid_W.nc\"],\n        \"icemod\": filepaths[\"ORCA2_5d_00010101_00010110_icemod.nc\"]\n        },\n        \"child\": {\n        \"1\":{\n        \"domain\": filepaths[\"2_domain_cfg.nc\"],\n        \"gridT\": filepaths[\"2_Nordic_5d_00010101_00010110_grid_T.nc\"],\n        \"gridU\": filepaths[\"2_Nordic_5d_00010101_00010110_grid_U.nc\"],\n        \"gridV\": filepaths[\"2_Nordic_5d_00010101_00010110_grid_V.nc\"],\n        \"gridW\": filepaths[\"2_Nordic_5d_00010101_00010110_grid_W.nc\"],\n        \"icemod\": filepaths[\"2_Nordic_5d_00010101_00010110_icemod.nc\"]\n        }},\n        \"grandchild\": {\n        \"2\":{\n        \"domain\": filepaths[\"3_domain_cfg.nc\"],\n        \"gridT\": filepaths[\"3_Nordic_5d_00010101_00010110_grid_T.nc\"],\n        \"gridU\": filepaths[\"3_Nordic_5d_00010101_00010110_grid_U.nc\"],\n        \"gridV\": filepaths[\"3_Nordic_5d_00010101_00010110_grid_V.nc\"],\n        \"gridW\": filepaths[\"3_Nordic_5d_00010101_00010110_grid_W.nc\"],\n        \"icemod\": filepaths[\"3_Nordic_5d_00010101_00010110_icemod.nc\"]\n        }},\n        }\n</code></pre> <p>Next, we need to construct a <code>nests</code> dictionary which contains the properties which define each nested domain. These include:</p> <ul> <li>Unique domain number (mapping properties to entries in our <code>paths</code> directory).</li> <li>Parent domain (to which unique domain does this belong).</li> <li>Zonal periodicity of child / grandchild domain (<code>iperio</code>).</li> <li>Horizontal grid refinement factors (<code>rx</code>, <code>ry</code>).</li> <li>Start (<code>imin</code>, <code>jmin</code>) and end (<code>imax</code>, <code>jmax</code>) grid indices in both directions (i, j) of the parent grid.</li> </ul> <p>The latter information should be copied directly from the <code>AGRIF_FixedGrids.in</code> anicillary file used to define nested domains in NEMO.</p> <p><code>Example AGRIF_FixedGrids.in</code></p> <p>1 (Number of nested domains - parent).</p> <p>121 146 113 133 4 4 4 (imin, imax, jmin, jmax, rx, ry, rt)</p> <p>1 (Number of nested domains - child)</p> <p>20 60 27 60 3 3 3 (imin, imax, jmin, jmax, rx, ry, rt)</p> <p>0 (Number of nested domains - grandchild)</p> <p>Important: we must specify the start and end grid indices using Fortran (1-based) indexes rather than Python (0-based) indexes.</p> <pre><code>nests = {\n    \"1\": {\n    \"parent\": \"/\",\n    \"rx\": 4,\n    \"ry\": 4,\n    \"imin\": 121,\n    \"imax\": 146,\n    \"jmin\": 113,\n    \"jmax\": 133,\n    \"iperio\": False\n    },\n    \"2\": {\n    \"parent\": \"1\",\n    \"rx\": 3,\n    \"ry\": 3,\n    \"imin\": 20,\n    \"imax\": 60,\n    \"jmin\": 27,\n    \"jmax\": 60,\n    \"iperio\": False\n    }\n    }\n</code></pre> <p>Finally, we can construct a new <code>NEMODataTree</code> called <code>nemo</code> using the <code>.from_paths()</code> constructor.</p> <p>Again, we also need to specify that our global parent domain is zonally periodic (<code>iperio=True</code>) and north folding on T-points (<code>nftype = \"T\"</code>) rather than a closed (regional) domain.</p> <p>We can also include additional keyword arguments to pass onto <code>xarray.open_dataset</code> or <code>xr.open_mfdataset</code> when opening NEMO model output files.</p> <pre><code>nemo = NEMODataTree.from_paths(paths=paths, nests=nests, iperio=True, nftype=\"T\", engine=\"netcdf4\")\n\nnemo\n</code></pre> <pre><code>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:               (time_counter: 2, axis_nbounds: 2, ncatice: 5)\n\u2502   ...\n\u2502 \n\u251c\u2500\u2500 Group: /gridT\n\u2502   \u2502   Dimensions:               (time_counter: 2, axis_nbounds: 2, j: 148, i: 180,\n\u2502   \u2502                              ncatice: 5, k: 31)\n\u2502   \u2502   ...\n\u2502   \u2514\u2500\u2500 Group: /gridT/1_gridT\n\u2502       \u2502   Dimensions:               (time_counter: 2, axis_nbounds: 2, j1: 80, i1: 100,\n\u2502       \u2502                              ncatice: 5, k1: 29)\n\u2502       \u2502   ...\n\u2502       \u2514\u2500\u2500 Group: /gridT/1_gridT/2_gridT\n\u2502               Dimensions:               (time_counter: 2, axis_nbounds: 2, j2: 99, i2: 120,\n\u2502                                          ncatice: 5, k2: 60)\n\u2502               ...\n\u251c\u2500\u2500 Group: /gridU\n\u2502   \u2502   Dimensions:               (k: 31, axis_nbounds: 2, time_counter: 2, j: 148,\n\u2502   \u2502                              i: 180)\n\u2502   \u2502   ...\n\u2502   \u2514\u2500\u2500 Group: /gridU/1_gridU\n\u2502       \u2502   Dimensions:               (k1: 29, axis_nbounds: 2, time_counter: 2, j1: 80,\n\u2502       \u2502                              i1: 100)\n\u2502       \u2502   ...\n\u2502       \u2514\u2500\u2500 Group: /gridU/1_gridU/2_gridU\n\u2502               Dimensions:               (k2: 60, axis_nbounds: 2, time_counter: 2, j2: 99,\n\u2502                                          i2: 120)\n\u2502               ...\n\u251c\u2500\u2500 Group: /gridV\n\u2502   \u2502   Dimensions:               (k: 31, axis_nbounds: 2, time_counter: 2, j: 148,\n\u2502   \u2502                              i: 180)\n\u2502   \u2502   ...\n\u2502   \u2514\u2500\u2500 Group: /gridV/1_gridV\n\u2502       \u2502   Dimensions:               (k1: 29, axis_nbounds: 2, time_counter: 2, j1: 80,\n\u2502       \u2502                              i1: 100)\n\u2502       \u2502   ...\n\u2502       \u2514\u2500\u2500 Group: /gridV/1_gridV/2_gridV\n\u2502               Dimensions:               (k2: 60, axis_nbounds: 2, time_counter: 2, j2: 99,\n\u2502                                          i2: 120)\n\u2502               ...\n\u251c\u2500\u2500 Group: /gridW\n\u2502   \u2502   Dimensions:               (k: 31, axis_nbounds: 2, time_counter: 2, j: 148,\n\u2502   \u2502                              i: 180)\n\u2502   \u2502   ...\n\u2502   \u2514\u2500\u2500 Group: /gridW/1_gridW\n\u2502       \u2502   Dimensions:               (k1: 29, axis_nbounds: 2, time_counter: 2, j1: 80,\n\u2502       \u2502                              i1: 100)\n\u2502       \u2502   ...\n\u2502       \u2514\u2500\u2500 Group: /gridW/1_gridW/2_gridW\n\u2502               Dimensions:               (k2: 60, axis_nbounds: 2, time_counter: 2, j2: 99,\n\u2502                                          i2: 120)\n\u2502               ...\n\u2514\u2500\u2500 Group: /gridF\n    \u2502   Dimensions:       (j: 148, i: 180, k: 31)\n    \u2502   ...\n    \u2514\u2500\u2500 Group: /gridF/1_gridF\n        \u2502   Dimensions:       (j1: 80, i1: 100, k1: 29)\n        \u2502   ...\n        \u2514\u2500\u2500 Group: /gridF/1_gridF/2_gridF\n                Dimensions:       (j2: 99, i2: 120, k2: 60)\n                ...\n</code></pre>"},{"location":"nemodatatree/#coupled-climate-models","title":"Coupled Climate Models:","text":"<p><code>UKESM1-0-LL</code></p> <p>In addition to ocean-only and ocean sea-ice hindcast simulations (prescribing surface atmospheric forcing), NEMO models are also used as the ocean components in many coupled climate models, including the UK Earth System Model (UKESM) developed jointly by the UK Met Office and Natural Environment Research Council (NERC).</p> <p>Here, we show how to construct a <code>NEMODataTree</code> from the 1\u00b0 global ocean sea-ice component of UKESM1-0-LL included in the sixth Coupled Model Intercomparsion Project (CMIP6) using outputs accessible via the CEDA Archive.</p> <p>Since CMIP6 outputs are processed and formatted according to the CMIP Community Climate Model Output Rewriter (CMOR) software, we will need to include a few additional pre-processing steps to reformat our NEMO model outputs in order to construct a <code>NEMODataTree</code></p> <p>Important: only CMIP model outputs variables stored on their original NEMO ocean model grid (i.e, <code>gn</code>) can be used to construct a <code>NEMODataTree</code></p> <pre><code># Open domain_cfg:\nds_domain_cfg = xr.open_dataset(\"/path/to/MOHC/Ofx/domain_cfg_Ofx_UKESM1.nc\")\n\n# Define time decoder to handle CMIP6 time units:\ntime_decoder = xr.coders.CFDatetimeCoder(use_cftime=True)\n\n# Open potential temperature (\u00b0C) dataset:\nbase_filepath = \"/badc/cmip6/data/CMIP6/CMIP/MOHC/UKESM1-0-LL/historical/r4i1p1f2/Omon/thetao/gn/latest\"\nds_ukesm1_gridT = xr.open_mfdataset(f\"{base_filepath}/thetao_Omon_UKESM1-0-LL_historical_r4i1p1f2_gn_*.nc\",\n                                    data_vars='all',\n                                    decode_times=time_decoder\n                                   )\n\n# Adding mixed layer depth (m) to dataset:\nds_ukesm1_gridT['mlotst'] = xr.open_mfdataset(f\"{base_filepath}/mlotst_Omon_UKESM1-0-LL_historical_r4i1p1f2_gn_*.nc\",\n                                              data_vars='all',\n                                              decode_times=time_decoder\n                                              )['mlotst']\n</code></pre> <p>Now we have defined our <code>domain</code> and <code>gridT</code> datasets, let's define a <code>datasets</code> dictionary ensuring that we rename CMORISED dimensions to be consistent with standard NEMO model outputs.</p> <p>We can then define a <code>NEMODataTree</code> using the <code>.from_datasets()</code> constructor, specifying that our global parent domain is zonally periodic and north-folding on F-points.</p> <pre><code>datasets = {\"parent\": {\n                \"domain\": ds_domain_cfg.rename({'z':'nav_lev'}),\n                \"gridT\": ds_ukesm1_gridT.rename({'time':'time_counter', 'i':'x', 'j':'y', 'lev':'deptht'}),\n                }}\n\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</code></pre>"},{"location":"recipe_barotropic_sf/","title":"Barotropic Stream Functions","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport xarray as xr\nfrom nemo_cookbook import NEMODataTree\n\nimport cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\nimport cartopy.feature as cfeature\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import xarray as xr from nemo_cookbook import NEMODataTree  import cartopy.crs as ccrs import matplotlib.pyplot as plt import cartopy.feature as cfeature  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x165eedbe0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[2]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})\n             .squeeze()\n             .rename({'z': 'nav_lev'})\n             )\n# Open eORCA1 ocean basin masks:\nds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})              .squeeze()              .rename({'z': 'nav_lev'})              ) # Open eORCA1 ocean basin masks: ds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})  ds_domain Out[2]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (y: 331, x: 360, nav_lev: 75)\nDimensions without coordinates: y, x, nav_lev\nData variables: (12/54)\n    e1t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2v            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bottom_level   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2u            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bathy_metry    (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (nav_lev) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   float64 8B dask.array&lt;chunksize=(), meta=np.ndarray&gt;\n    top_level      (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we need to import the meridional velocity and vertical grid cell thicknesses stored at V-points in a single dataset.</p> <p>Typically, NEMO model outputs defined on V-grid points are stored together in netCDF files. In this case, you can replace <code>xr.merge()</code> with a single call to xarray's <code>open_dataset()</code> function passing the file path to your <code>_gridV.nc</code> file(s).</p> In\u00a0[3]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/V1y\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\")\n\nds_gridV\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/V1y\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\")  ds_gridV Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 4GB\nDimensions:        (depthv: 75, y: 331, x: 360, time_counter: 49)\nCoordinates:\n  * depthv         (depthv) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n  * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: y, x\nData variables:\n    e3v            (time_counter, depthv, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    vo             (time_counter, depthv, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean (interval: 3600 s)\n    interval_operation:  3600 s\n    interval_write:      1 yr\n    long_name:           V-cell thickness\n    online_operation:    average\n    standard_name:       cell_thickness\n    units:               m</pre> In\u00a0[4]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain, \"gridV\": ds_gridV}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain, \"gridV\": ds_gridV}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[4]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 49)\n\u2502   Coordinates:\n\u2502     * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n\u2502       time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level     (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level  (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           tmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           umaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:        (time_counter: 49, k: 75, j: 331, i: 360)\n\u2502       Coordinates:\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * depthv         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphiv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e3v            (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           vo             (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           e1v            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502           vmaskutil      (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           cell_methods:        time: mean (interval: 3600 s)\n\u2502           interval_operation:  3600 s\n\u2502           interval_write:      1 yr\n\u2502           long_name:           V-cell thickness\n\u2502           online_operation:    average\n\u2502           standard_name:       cell_thickness\n\u2502           units:               m\n\u2502           nftype:              F\n\u2502           iperio:              True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           wmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n            fmaskutil     (j, i) bool 119kB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> In\u00a0[5]: Copied! <pre># Define Atlantic Ocean basin mask:\natlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"}).astype(bool)\n# Assign (i,j) coordinates of V-points:\natlmask['i'] = atlmask['i'] + 1\natlmask['j'] = atlmask['j'] + 1.5\n\n# Compute barotropic stream function:\nbsf_atl = nemo.integral(grid=\"gridV\",\n                        var=\"vo\",\n                        dims=[\"k\", \"i\"], \n                        cum_dims=[\"i\"],\n                        dir=\"+1\",\n                        mask=atlmask\n                        )\n\nbsf_atl\n</pre> # Define Atlantic Ocean basin mask: atlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"}).astype(bool) # Assign (i,j) coordinates of V-points: atlmask['i'] = atlmask['i'] + 1 atlmask['j'] = atlmask['j'] + 1.5  # Compute barotropic stream function: bsf_atl = nemo.integral(grid=\"gridV\",                         var=\"vo\",                         dims=[\"k\", \"i\"],                          cum_dims=[\"i\"],                         dir=\"+1\",                         mask=atlmask                         )  bsf_atl Out[5]: <pre>&lt;xarray.DataArray 'vo' (time_counter: 49, j: 331, i: 360)&gt; Size: 47MB\ndask.array&lt;nancumsum, shape=(49, 331, 360), dtype=float64, chunksize=(1, 331, 360), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n  * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n  * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n    time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    gphiv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    glamv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean\n    interval_operation:  1 yr\n    interval_write:      1 yr\n    long_name:           ocean current along j-axis\n    online_operation:    average\n    standard_name:       sea_water_y_velocity\n    units:               m/s</pre> <p>Notice that the resulting DataArray includes a dask array, so we haven't actually computed the barotropic stream function yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[6]: Copied! <pre># Compute barotropic stream function in Sverdrups [1 Sv = 1E6 m3/s]:\nbsf_atl = 1E-6 * bsf_atl.compute()\n\nbsf_atl\n</pre> # Compute barotropic stream function in Sverdrups [1 Sv = 1E6 m3/s]: bsf_atl = 1E-6 * bsf_atl.compute()  bsf_atl Out[6]: <pre>&lt;xarray.DataArray 'vo' (time_counter: 49, j: 331, i: 360)&gt; Size: 47MB\narray([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        ...,\n        [ 0.        ,  0.        ,  0.        , ..., -0.93092196,\n         -0.93092196, -0.93092196],\n        [ 0.        ,  0.        ,  0.        , ..., -0.93177347,\n         -0.93177347, -0.93177347],\n        [ 0.        ,  0.        ,  0.        , ..., -0.93259213,\n         -0.93259213, -0.93259213]],\n\n       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n...\n        [ 0.        ,  0.        ,  0.        , ..., -0.87334578,\n         -0.87334578, -0.87334578],\n        [ 0.        ,  0.        ,  0.        , ..., -0.87397618,\n         -0.87397618, -0.87397618],\n        [ 0.        ,  0.        ,  0.        , ..., -0.87391507,\n         -0.87391507, -0.87391507]],\n\n       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        ...,\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ]]], shape=(49, 331, 360))\nCoordinates:\n  * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n  * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n  * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n    time_centered  (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n    gphiv          (j, i) float64 953kB -84.16 -84.16 -84.16 ... 50.23 50.01\n    glamv          (j, i) float64 953kB 73.5 74.5 75.5 76.5 ... 73.0 73.0 73.0\nAttributes:\n    cell_methods:        time: mean\n    interval_operation:  1 yr\n    interval_write:      1 yr\n    long_name:           ocean current along j-axis\n    online_operation:    average\n    standard_name:       sea_water_y_velocity\n    units:               m/s</pre> In\u00a0[7]: Copied! <pre># -- Create a figure with an orthographic (globe) projection -- #\nfig = plt.figure(figsize=(7, 7))\nproj = ccrs.Orthographic(central_longitude=-25, central_latitude=35)\nax = plt.axes(projection=proj)\nax.coastlines(resolution='110m', linewidth=0.8)\nax.add_feature(cfeature.LAND, facecolor='0.1', edgecolor='0.1', linewidth=0.2, zorder=4)\nax.gridlines(draw_labels=False, dms=True, x_inline=False, y_inline=False)\n\n# Plot eORCA1 JRA55v1 time-mean barotropic stream function:\nc_parent = ax.pcolormesh(bsf_atl.glamv, bsf_atl.gphiv, bsf_atl.mean(dim='time_counter'),\n                         transform=ccrs.PlateCarree(),\n                         cmap=\"RdBu_r\", shading=\"auto\",\n                         vmin=-30, vmax=30,\n                         zorder=1)\n\n# Plot eORCA1 JRA55v1 time-mean barotropic stream function contours:\nplt.contour(bsf_atl.glamv, bsf_atl.gphiv, bsf_atl.mean(dim='time_counter'),\n            levels=8, colors='k', linewidths=1,\n            transform=ccrs.PlateCarree(),\n            zorder=2)\n\n# Add colorbar with label:\ncb = plt.colorbar(c_parent, orientation=\"horizontal\", pad=0.05, shrink=0.7)\ncb.set_label(\"Barotropic Stream Function (Sv)\", fontsize=11)\n</pre> # -- Create a figure with an orthographic (globe) projection -- # fig = plt.figure(figsize=(7, 7)) proj = ccrs.Orthographic(central_longitude=-25, central_latitude=35) ax = plt.axes(projection=proj) ax.coastlines(resolution='110m', linewidth=0.8) ax.add_feature(cfeature.LAND, facecolor='0.1', edgecolor='0.1', linewidth=0.2, zorder=4) ax.gridlines(draw_labels=False, dms=True, x_inline=False, y_inline=False)  # Plot eORCA1 JRA55v1 time-mean barotropic stream function: c_parent = ax.pcolormesh(bsf_atl.glamv, bsf_atl.gphiv, bsf_atl.mean(dim='time_counter'),                          transform=ccrs.PlateCarree(),                          cmap=\"RdBu_r\", shading=\"auto\",                          vmin=-30, vmax=30,                          zorder=1)  # Plot eORCA1 JRA55v1 time-mean barotropic stream function contours: plt.contour(bsf_atl.glamv, bsf_atl.gphiv, bsf_atl.mean(dim='time_counter'),             levels=8, colors='k', linewidths=1,             transform=ccrs.PlateCarree(),             zorder=2)  # Add colorbar with label: cb = plt.colorbar(c_parent, orientation=\"horizontal\", pad=0.05, shrink=0.7) cb.set_label(\"Barotropic Stream Function (Sv)\", fontsize=11)  <pre>OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n</pre>"},{"location":"recipe_barotropic_sf/#description","title":"Description\u00b6","text":"<p>This recipe shows how to calculate the barotropic stream function for the North Atlantic Ocean using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_barotropic_sf/#background","title":"Background\u00b6","text":"<p>The barotropic stream function is routinely used to characterise the large-scale ocean circulation $\\psi_{xy}$ and can be defined using the meridional velocity field at time $t$ as follows:</p> <p>$$\\Psi_{xy}(\\lambda, \\phi, t) = \\int_{x_w}^{x} \\int_{-H}^{\\eta} v(\\lambda, \\phi, z, t) \\ dz \\ dx$$</p> <p>where the meridional velocity $v(\\lambda, \\phi, z, t)$ is first integrated from the sea surface $\\eta$ to the seafloor $-H$ before being accumulated zonally from the western ($x_w$) to the eastern ($x_e$) boundary of our model domain.</p>"},{"location":"recipe_barotropic_sf/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_barotropic_sf/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 JRA-55 model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_barotropic_sf/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_barotropic_sf/#calculating-the-barotropic-stream-function","title":"Calculating the Barotropic Stream Function\u00b6","text":"<p>Now we have constructed our <code>NEMODataTree</code>, let's calculate the time-mean barotropic stream function.</p> <p>$$\\psi_{xy}(t) = \\sum_{i^{*}=1}^{i} \\sum_{k} (e_{1v} . e_{3v}(t) . v(t))$$</p> <p>In this example, our eORCA1 model uses $z^{*}$ vertical coordinates, so we will use the <code>integral()</code> method to perform integration along the $i$ and $k$ dimensions of the NEMO model grid. The resulting 2-dimensional barotropic stream function represents the depth-integrated volume transport in the Atlantic Ocean.</p>"},{"location":"recipe_barotropic_sf/#visualising-the-time-mean-barotropic-stream-function","title":"Visualising the time-mean barotropic stream function\u00b6","text":"<p>Finally, let's visualise the results by plotting the time-mean barotropic stream function for the North Atlantic basin:</p>"},{"location":"recipe_extract_osnap/","title":"Extracting Hydrographic Sections","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport gsw\nimport numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import gsw import numpy as np import xarray as xr import matplotlib.pyplot as plt from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x1509490ba3c0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': '/dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/',\n                 'local_directory': '/dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/'\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=5, threads_per_worker=2, memory_limit='8GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': '/dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/',                  'local_directory': '/dssgfs01/working/otooth/Diagnostics/nemo_cookbook/recipes/'                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=5, threads_per_worker=2, memory_limit='8GB') client = Client(cluster) client In\u00a0[2]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca025-jra55v1/domain\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})\n             .squeeze()\n             .rename({'z': 'nav_lev'})\n             )\n\nds_domain.load()\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca025-jra55v1/domain\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})              .squeeze()              .rename({'z': 'nav_lev'})              )  ds_domain.load() Out[2]: <pre>&lt;xarray.Dataset&gt; Size: 8GB\nDimensions:       (y: 1206, x: 1440, nav_lev: 75)\nDimensions without coordinates: y, x, nav_lev\nData variables: (12/43)\n    e1v           (y, x) float64 14MB 1e+03 1e+03 1e+03 ... 5.653e+03 3.28e+03\n    closea_mask   (y, x) float64 14MB nan nan nan nan 11.0 ... nan nan nan nan\n    bottom_level  (y, x) int32 7MB 0 0 0 0 5 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n    e1u           (y, x) float64 14MB 1e+03 1e+03 1e+03 ... 6.277e+03 5.038e+03\n    e2t           (y, x) float64 14MB 1e+03 1e+03 1e+03 ... 683.6 925.0 1.135\n    e1t           (y, x) float64 14MB 1e+03 1e+03 1e+03 ... 6.516e+03 5.79e+03\n    ...            ...\n    nav_lat       (y, x) float32 7MB -89.5 -89.5 -89.5 ... 50.07 50.02 50.0\n    mask_opensea  (y, x) float64 14MB 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n    nav_lev       (nav_lev) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n    nav_lon       (y, x) float32 7MB 73.0 73.25 73.5 73.75 ... 73.0 73.0 73.0\n    top_level     (y, x) int32 7MB 0 0 0 0 1 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n    time_counter  float64 8B 0.0\nAttributes: (12/14)\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [1442, 1207]\n    DOMAIN_size_local:       [1442, 1207]\n    DOMAIN_position_first:   [1, 1]\n    ...                      ...\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    cn_cfg:                  orca\n    history:                 Thu Feb  3 15:18:00 2022: ncks --4 --no_abc --cn...\n    nn_cfg:                  25\n    NCO:                     netCDF Operators version 4.9.5 (Homepage = http:...</pre> <p>Next, we need to import the conservative temperature and absolute salinity stored at T-points in a single dataset.</p> <p>Typically, NEMO model outputs defined on T-grid points are stored together in netCDF files. In this case, you can replace <code>xr.merge()</code> with a single call to xarray's <code>open_dataset()</code> function passing the file path to your <code>_gridT.nc</code> file(s).</p> In\u00a0[3]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca025-jra55v1/T1y\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['thetao_con', 'so_abs']], compat=\"override\")\nds_gridT = ds_gridT.sel(time_counter=slice(\"2014-01\", \"2023-12\"))\n\n# Calculate potential density anomaly referenced to the sea surface (kg/m3):\nds_gridT['sigma0'] = gsw.density.sigma0(CT=ds_gridT['thetao_con'], SA=ds_gridT['so_abs'])\nds_gridT['sigma0'].name = 'sigma0'\n\nds_gridT\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca025-jra55v1/T1y\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['thetao_con', 'so_abs']], compat=\"override\") ds_gridT = ds_gridT.sel(time_counter=slice(\"2014-01\", \"2023-12\"))  # Calculate potential density anomaly referenced to the sea surface (kg/m3): ds_gridT['sigma0'] = gsw.density.sigma0(CT=ds_gridT['thetao_con'], SA=ds_gridT['so_abs']) ds_gridT['sigma0'].name = 'sigma0'  ds_gridT Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 21GB\nDimensions:        (deptht: 75, y: 1206, x: 1440, time_counter: 10)\nCoordinates:\n  * deptht         (deptht) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n  * time_counter   (time_counter) datetime64[ns] 80B 2014-07-02T12:00:00 ... ...\n    nav_lat        (y, x) float64 14MB dask.array&lt;chunksize=(603, 720), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 14MB dask.array&lt;chunksize=(603, 720), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 80B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: y, x\nData variables:\n    thetao_con     (time_counter, deptht, y, x) float32 5GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\n    so_abs         (time_counter, deptht, y, x) float32 5GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\n    sigma0         (time_counter, deptht, y, x) float64 10GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean\n    interval_operation:  1 yr\n    interval_write:      1 yr\n    long_name:           sea_water_conservative_temperature\n    online_operation:    average\n    standard_name:       sea_water_conservative_temperature\n    units:               degC</pre> <p>Next, we need to import the zonal &amp; meridional velocities and vertical grid cell thicknesses stored at U- &amp; V-points, respectively.</p> <p>Typically, NEMO model outputs defined on U- &amp; V-grid points are stored together in netCDF files. In this case, you can replace <code>xr.merge()</code> with a single call to xarray's <code>open_dataset()</code> function passing the file path to your <code>_gridV.nc</code> file(s).</p> In\u00a0[4]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca025-jra55v1/U1y\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridU = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3u', 'uo']], compat=\"override\")\nds_gridU = ds_gridU.sel(time_counter=slice(\"2014-01\", \"2023-12\"))\n\nds_gridU\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca025-jra55v1/U1y\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridU = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3u', 'uo']], compat=\"override\") ds_gridU = ds_gridU.sel(time_counter=slice(\"2014-01\", \"2023-12\"))  ds_gridU Out[4]: <pre>&lt;xarray.Dataset&gt; Size: 10GB\nDimensions:        (depthu: 75, y: 1206, x: 1440, time_counter: 10)\nCoordinates:\n  * depthu         (depthu) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n  * time_counter   (time_counter) datetime64[ns] 80B 2014-07-02T12:00:00 ... ...\n    nav_lat        (y, x) float64 14MB dask.array&lt;chunksize=(603, 720), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 14MB dask.array&lt;chunksize=(603, 720), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 80B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: y, x\nData variables:\n    e3u            (time_counter, depthu, y, x) float32 5GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\n    uo             (time_counter, depthu, y, x) float32 5GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean (interval: 1800 s)\n    interval_operation:  1800 s\n    interval_write:      1 yr\n    long_name:           U-cell thickness\n    online_operation:    average\n    standard_name:       cell_thickness\n    units:               m</pre> In\u00a0[5]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca025-jra55v1/V1y\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\")\nds_gridV = ds_gridV.sel(time_counter=slice(\"2014-01\", \"2023-12\"))\n\nds_gridV\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca025-jra55v1/V1y\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\") ds_gridV = ds_gridV.sel(time_counter=slice(\"2014-01\", \"2023-12\"))  ds_gridV Out[5]: <pre>&lt;xarray.Dataset&gt; Size: 10GB\nDimensions:        (depthv: 75, y: 1206, x: 1440, time_counter: 10)\nCoordinates:\n  * depthv         (depthv) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n  * time_counter   (time_counter) datetime64[ns] 80B 2014-07-02T12:00:00 ... ...\n    nav_lat        (y, x) float64 14MB dask.array&lt;chunksize=(603, 720), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 14MB dask.array&lt;chunksize=(603, 720), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 80B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: y, x\nData variables:\n    e3v            (time_counter, depthv, y, x) float32 5GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\n    vo             (time_counter, depthv, y, x) float32 5GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean (interval: 1800 s)\n    interval_operation:  1800 s\n    interval_write:      1 yr\n    long_name:           V-cell thickness\n    online_operation:    average\n    standard_name:       cell_thickness\n    units:               m</pre> In\u00a0[6]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\":\n            {\"domain\": ds_domain,\n             \"gridT\": ds_gridT,\n             \"gridU\": ds_gridU,\n             \"gridV\": ds_gridV\n             }\n            }\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"T\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\":             {\"domain\": ds_domain,              \"gridT\": ds_gridT,              \"gridU\": ds_gridU,              \"gridV\": ds_gridV              }             }  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"T\")  nemo Out[6]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 10)\n\u2502   Coordinates:\n\u2502     * time_counter   (time_counter) datetime64[ns] 80B 2014-07-02T12:00:00 ... ...\n\u2502       time_centered  (time_counter) datetime64[ns] 80B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502   Attributes:\n\u2502       nftype:   T\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:        (time_counter: 10, k: 75, j: 1206, i: 1440)\n\u2502       Coordinates:\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) int64 10kB 1 2 3 4 5 6 ... 1201 1202 1203 1204 1205 1206\n\u2502         * i              (i) int64 12kB 1 2 3 4 5 6 ... 1435 1436 1437 1438 1439 1440\n\u2502         * deptht         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 80B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 14MB -89.5 -89.5 -89.5 ... 50.07 50.02 50.0\n\u2502           glamt          (j, i) float64 14MB 73.0 73.25 73.5 73.75 ... 73.0 73.0 73.0\n\u2502       Data variables:\n\u2502           thetao_con     (time_counter, k, j, i) float32 5GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\n\u2502           so_abs         (time_counter, k, j, i) float32 5GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\n\u2502           sigma0         (time_counter, k, j, i) float64 10GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\n\u2502           e1t            (j, i) float64 14MB 1e+03 1e+03 1e+03 ... 6.516e+03 5.79e+03\n\u2502           e2t            (j, i) float64 14MB 1e+03 1e+03 1e+03 ... 683.6 925.0 1.135\n\u2502           top_level      (j, i) int32 7MB 0 0 0 0 1 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n\u2502           bottom_level   (j, i) int32 7MB 0 0 0 0 5 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n\u2502           tmask          (k, j, i) bool 130MB False False False ... False False False\n\u2502           tmaskutil      (j, i) bool 2MB False False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   T\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:        (time_counter: 10, k: 75, j: 1206, i: 1440)\n\u2502       Coordinates:\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) int64 10kB 1 2 3 4 5 6 ... 1201 1202 1203 1204 1205 1206\n\u2502         * i              (i) float64 12kB 1.5 2.5 3.5 ... 1.438e+03 1.44e+03 1.44e+03\n\u2502         * depthu         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 80B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphiu          (j, i) float64 14MB -89.5 -89.5 -89.5 ... 50.04 50.01 50.0\n\u2502           glamu          (j, i) float64 14MB 73.12 73.38 73.62 ... 73.0 73.0 73.0\n\u2502       Data variables:\n\u2502           e3u            (time_counter, k, j, i) float32 5GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\n\u2502           uo             (time_counter, k, j, i) float32 5GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\n\u2502           e1u            (j, i) float64 14MB 1e+03 1e+03 1e+03 ... 6.277e+03 5.038e+03\n\u2502           e2u            (j, i) float64 14MB 1e+03 1e+03 1e+03 ... 847.0 455.1 151.3\n\u2502           umask          (k, j, i) bool 130MB False False False ... False False False\n\u2502           umaskutil      (j, i) bool 2MB False False False False ... False False False\n\u2502       Attributes:\n\u2502           cell_methods:        time: mean (interval: 1800 s)\n\u2502           interval_operation:  1800 s\n\u2502           interval_write:      1 yr\n\u2502           long_name:           U-cell thickness\n\u2502           online_operation:    average\n\u2502           standard_name:       cell_thickness\n\u2502           units:               m\n\u2502           nftype:              T\n\u2502           iperio:              True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:        (time_counter: 10, k: 75, j: 1206, i: 1440)\n\u2502       Coordinates:\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) float64 10kB 1.5 2.5 3.5 ... 1.206e+03 1.206e+03\n\u2502         * i              (i) int64 12kB 1 2 3 4 5 6 ... 1435 1436 1437 1438 1439 1440\n\u2502         * depthv         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 80B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphiv          (j, i) float64 14MB -89.5 -89.5 -89.5 ... 50.07 50.02 50.0\n\u2502           glamv          (j, i) float64 14MB 73.0 73.25 73.5 73.75 ... 73.0 73.0 73.0\n\u2502       Data variables:\n\u2502           e3v            (time_counter, k, j, i) float32 5GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\n\u2502           vo             (time_counter, k, j, i) float32 5GB dask.array&lt;chunksize=(1, 25, 603, 720), meta=np.ndarray&gt;\n\u2502           e1v            (j, i) float64 14MB 1e+03 1e+03 1e+03 ... 5.653e+03 3.28e+03\n\u2502           e2v            (j, i) float64 14MB 1e+03 1e+03 1e+03 ... 699.8 710.5 221.8\n\u2502           vmask          (k, j, i) bool 130MB False False False ... False False False\n\u2502           vmaskutil      (j, i) bool 2MB False False False False ... False False False\n\u2502       Attributes:\n\u2502           cell_methods:        time: mean (interval: 1800 s)\n\u2502           interval_operation:  1800 s\n\u2502           interval_write:      1 yr\n\u2502           long_name:           V-cell thickness\n\u2502           online_operation:    average\n\u2502           standard_name:       cell_thickness\n\u2502           units:               m\n\u2502           nftype:              T\n\u2502           iperio:              True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 1206, i: 1440, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 10kB 1 2 3 4 5 6 7 ... 1201 1202 1203 1204 1205 1206\n\u2502         * i             (i) int64 12kB 1 2 3 4 5 6 7 ... 1435 1436 1437 1438 1439 1440\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502           gphit         (j, i) float64 14MB -89.5 -89.5 -89.5 ... 50.07 50.02 50.0\n\u2502           glamt         (j, i) float64 14MB 73.0 73.25 73.5 73.75 ... 73.0 73.0 73.0\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 14MB 1e+03 1e+03 1e+03 ... 6.516e+03 5.79e+03\n\u2502           e2t           (j, i) float64 14MB 1e+03 1e+03 1e+03 ... 683.6 925.0 1.135\n\u2502           wmask         (k, j, i) bool 130MB False False False ... False False False\n\u2502           wmaskutil     (j, i) bool 2MB False False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   T\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 1206, i: 1440, k: 75)\n        Coordinates:\n          * j             (j) float64 10kB 1.5 2.5 3.5 ... 1.204e+03 1.206e+03 1.206e+03\n          * i             (i) float64 12kB 1.5 2.5 3.5 ... 1.438e+03 1.44e+03 1.44e+03\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n            gphif         (j, i) float64 14MB -89.5 -89.5 -89.5 ... 50.04 50.01 50.0\n            glamf         (j, i) float64 14MB 73.12 73.38 73.62 73.88 ... 73.0 73.0 73.0\n        Data variables:\n            e1f           (j, i) float64 14MB 1e+03 1e+03 1e+03 ... 4.503e+03 2.721e+03\n            e2f           (j, i) float64 14MB 1e+03 1e+03 1e+03 ... 720.8 454.0 307.1\n            fmask         (k, j, i) bool 130MB False False False ... False False False\n            fmaskutil     (j, i) bool 2MB False False False False ... False False False\n        Attributes:\n            nftype:   T\n            iperio:   True</pre> In\u00a0[7]: Copied! <pre># Define S3 URL to OSNAP gridded observational data in JASMIN Object Store:\nurl = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/ocean-obs/OSNAP/OSNAP_Gridded_TSV_201408_202006_2023\"\nds_osnap = xr.open_zarr(url, consolidated=True, chunks={})\n\n#\u00a0Define OSNAP section coordinates (adding final land point - UK):\nlon_osnap = np.concatenate([ds_osnap['LONGITUDE'].values, np.array([-4.0])])\nlat_osnap = np.concatenate([ds_osnap['LATITUDE'].values, np.array([56.0])])\n</pre> # Define S3 URL to OSNAP gridded observational data in JASMIN Object Store: url = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/ocean-obs/OSNAP/OSNAP_Gridded_TSV_201408_202006_2023\" ds_osnap = xr.open_zarr(url, consolidated=True, chunks={})  #\u00a0Define OSNAP section coordinates (adding final land point - UK): lon_osnap = np.concatenate([ds_osnap['LONGITUDE'].values, np.array([-4.0])]) lat_osnap = np.concatenate([ds_osnap['LATITUDE'].values, np.array([56.0])]) In\u00a0[8]: Copied! <pre># Extract the OSNAP section from the NEMO model data:\nds_osnap = nemo.extract_section(lon_section=lon_osnap,\n                                lat_section=lat_osnap,\n                                uv_vars=[\"uo\", \"vo\"],\n                                vars=[\"sigma0\"],\n                                dom=\".\",\n                                )\n\nds_osnap\n</pre> # Extract the OSNAP section from the NEMO model data: ds_osnap = nemo.extract_section(lon_section=lon_osnap,                                 lat_section=lat_osnap,                                 uv_vars=[\"uo\", \"vo\"],                                 vars=[\"sigma0\"],                                 dom=\".\",                                 )  ds_osnap Out[8]: <pre>&lt;xarray.Dataset&gt; Size: 5MB\nDimensions:       (bdy: 277, time_counter: 10, k: 75)\nCoordinates:\n  * bdy           (bdy) int64 2kB 0 1 2 3 4 5 6 ... 270 271 272 273 274 275 276\n  * time_counter  (time_counter) datetime64[ns] 80B 2014-07-02T12:00:00 ... 2...\n  * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n    glamb         (bdy) float64 2kB -56.75 -56.5 -56.24 ... -4.712 -4.441 -4.171\n    gphib         (bdy) float64 2kB 52.09 52.11 52.13 ... 56.13 56.11 56.09\n    depthb        (k, bdy) float64 166kB 0.5058 0.5058 ... 5.902e+03 5.902e+03\nData variables:\n    i_bdy         (bdy) float64 2kB 927.0 928.0 929.0 ... 1.123e+03 1.124e+03\n    j_bdy         (bdy) float64 2kB 932.5 932.5 932.5 ... 955.5 955.5 955.5\n    flux_type     (bdy) &lt;U1 1kB 'V' 'V' 'V' 'V' 'V' 'V' ... 'V' 'U' 'V' 'V' 'V'\n    flux_dir      (bdy) int64 2kB 1 1 1 1 1 1 1 1 1 -1 1 ... 1 1 1 1 1 1 1 1 1 1\n    velocity      (time_counter, k, bdy) float64 2MB dask.array&lt;chunksize=(10, 75, 277), meta=np.ndarray&gt;\n    e1b           (bdy) float64 2kB dask.array&lt;chunksize=(277,), meta=np.ndarray&gt;\n    e3b           (time_counter, k, bdy) float64 2MB dask.array&lt;chunksize=(10, 75, 277), meta=np.ndarray&gt;\n    sigma0        (time_counter, k, bdy) float64 2MB dask.array&lt;chunksize=(10, 75, 277), meta=np.ndarray&gt;</pre> In\u00a0[9]: Copied! <pre># Plot the time-mean velocity along the OSNAP section:\nds_osnap['velocity'].mean(dim='time_counter').plot(yincrease=False)\nplt.axvline(x=ds_osnap['bdy'].where(ds_osnap['glamb'] &lt;= -44).max(), color='k', lw=2, ls='--')\n</pre> # Plot the time-mean velocity along the OSNAP section: ds_osnap['velocity'].mean(dim='time_counter').plot(yincrease=False) plt.axvline(x=ds_osnap['bdy'].where(ds_osnap['glamb'] &lt;= -44).max(), color='k', lw=2, ls='--') Out[9]: <pre>&lt;matplotlib.lines.Line2D at 0x150943475f90&gt;</pre> In\u00a0[10]: Copied! <pre>from nemo_cookbook.stats import compute_binned_statistic\n\n# Calculate volume transport in Sv:\nds_osnap['volume_transport'] = 1E-6 * (ds_osnap['velocity'] * ds_osnap['e1b'] * ds_osnap['e3b'])\n\n# Define potential density bins:\nsigma0_bins = np.arange(21, 28.2, 0.01)\n\n# Compute Total OSNAP diapycnal overturning stream function:\nds_osnap['moc_total'] = compute_binned_statistic(vars=[ds_osnap['sigma0']],\n                                                 values=ds_osnap['volume_transport'],\n                                                 keep_dims=['time_counter'],\n                                                 bins=[sigma0_bins],\n                                                 statistic='nansum',\n                                                 mask=None\n                                                 ).cumsum(dim='sigma0_bins')\n</pre> from nemo_cookbook.stats import compute_binned_statistic  # Calculate volume transport in Sv: ds_osnap['volume_transport'] = 1E-6 * (ds_osnap['velocity'] * ds_osnap['e1b'] * ds_osnap['e3b'])  # Define potential density bins: sigma0_bins = np.arange(21, 28.2, 0.01)  # Compute Total OSNAP diapycnal overturning stream function: ds_osnap['moc_total'] = compute_binned_statistic(vars=[ds_osnap['sigma0']],                                                  values=ds_osnap['volume_transport'],                                                  keep_dims=['time_counter'],                                                  bins=[sigma0_bins],                                                  statistic='nansum',                                                  mask=None                                                  ).cumsum(dim='sigma0_bins') <p>Next, let's calculate the meridional overturning stream functions for the OSNAP East and OSNAP West arrays separately.</p> In\u00a0[11]: Copied! <pre># Determine index to split OSNAP West &amp; OSNAP East sections:\nstation_OWest_OEast = ds_osnap['bdy'].where(ds_osnap['glamb'] &lt;= -44).max()\n\n# OSNAP East diapycnal overturning stream function:\nmask_OEast = ds_osnap['bdy'] &gt;= station_OWest_OEast\nds_osnap['moc_east'] = compute_binned_statistic(vars=[ds_osnap['sigma0']],\n                                                values=ds_osnap['volume_transport'],\n                                                keep_dims=['time_counter'],\n                                                bins=[sigma0_bins],\n                                                statistic='nansum',\n                                                mask=mask_OEast\n                                                ).cumsum(dim='sigma0_bins')\n\n# OSNAP West diapycnal overturning stream function:\nmask_OWest = ds_osnap['bdy'] &lt; station_OWest_OEast\nds_osnap['moc_west'] = compute_binned_statistic(vars=[ds_osnap['sigma0']],\n                                                values=ds_osnap['volume_transport'],\n                                                keep_dims=['time_counter'],\n                                                bins=[sigma0_bins],\n                                                statistic='nansum',\n                                                mask=mask_OWest\n                                                ).cumsum(dim='sigma0_bins')\n\nds_osnap\n</pre> # Determine index to split OSNAP West &amp; OSNAP East sections: station_OWest_OEast = ds_osnap['bdy'].where(ds_osnap['glamb'] &lt;= -44).max()  # OSNAP East diapycnal overturning stream function: mask_OEast = ds_osnap['bdy'] &gt;= station_OWest_OEast ds_osnap['moc_east'] = compute_binned_statistic(vars=[ds_osnap['sigma0']],                                                 values=ds_osnap['volume_transport'],                                                 keep_dims=['time_counter'],                                                 bins=[sigma0_bins],                                                 statistic='nansum',                                                 mask=mask_OEast                                                 ).cumsum(dim='sigma0_bins')  # OSNAP West diapycnal overturning stream function: mask_OWest = ds_osnap['bdy'] &lt; station_OWest_OEast ds_osnap['moc_west'] = compute_binned_statistic(vars=[ds_osnap['sigma0']],                                                 values=ds_osnap['volume_transport'],                                                 keep_dims=['time_counter'],                                                 bins=[sigma0_bins],                                                 statistic='nansum',                                                 mask=mask_OWest                                                 ).cumsum(dim='sigma0_bins')  ds_osnap Out[11]: <pre>&lt;xarray.Dataset&gt; Size: 7MB\nDimensions:           (bdy: 277, time_counter: 10, k: 75, sigma0_bins: 719)\nCoordinates:\n  * bdy               (bdy) int64 2kB 0 1 2 3 4 5 6 ... 271 272 273 274 275 276\n  * time_counter      (time_counter) datetime64[ns] 80B 2014-07-02T12:00:00 ....\n  * k                 (k) int64 600B 1 2 3 4 5 6 7 8 ... 68 69 70 71 72 73 74 75\n  * sigma0_bins       (sigma0_bins) float64 6kB 21.01 21.02 ... 28.18 28.19\n    glamb             (bdy) float64 2kB -56.75 -56.5 -56.24 ... -4.441 -4.171\n    gphib             (bdy) float64 2kB 52.09 52.11 52.13 ... 56.13 56.11 56.09\n    depthb            (k, bdy) float64 166kB 0.5058 0.5058 ... 5.902e+03\nData variables:\n    i_bdy             (bdy) float64 2kB 927.0 928.0 ... 1.123e+03 1.124e+03\n    j_bdy             (bdy) float64 2kB 932.5 932.5 932.5 ... 955.5 955.5 955.5\n    flux_type         (bdy) &lt;U1 1kB 'V' 'V' 'V' 'V' 'V' ... 'V' 'U' 'V' 'V' 'V'\n    flux_dir          (bdy) int64 2kB 1 1 1 1 1 1 1 1 1 -1 ... 1 1 1 1 1 1 1 1 1\n    velocity          (time_counter, k, bdy) float64 2MB dask.array&lt;chunksize=(10, 75, 277), meta=np.ndarray&gt;\n    e1b               (bdy) float64 2kB dask.array&lt;chunksize=(277,), meta=np.ndarray&gt;\n    e3b               (time_counter, k, bdy) float64 2MB dask.array&lt;chunksize=(10, 75, 277), meta=np.ndarray&gt;\n    sigma0            (time_counter, k, bdy) float64 2MB dask.array&lt;chunksize=(10, 75, 277), meta=np.ndarray&gt;\n    volume_transport  (time_counter, k, bdy) float64 2MB dask.array&lt;chunksize=(10, 75, 277), meta=np.ndarray&gt;\n    moc_total         (time_counter, sigma0_bins) float64 58kB dask.array&lt;chunksize=(10, 719), meta=np.ndarray&gt;\n    moc_east          (time_counter, sigma0_bins) float64 58kB dask.array&lt;chunksize=(10, 719), meta=np.ndarray&gt;\n    moc_west          (time_counter, sigma0_bins) float64 58kB dask.array&lt;chunksize=(10, 719), meta=np.ndarray&gt;</pre> <p>Notice that the resulting Dataset includes dask arrays, so we haven't actually computed the diapycnal overturning yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[13]: Copied! <pre>ds_osnap = ds_osnap.compute()\n</pre> ds_osnap = ds_osnap.compute() In\u00a0[14]: Copied! <pre># Plot time-mean diapycnal overturning stream functions along the OSNAP section:\nplt.figure(figsize=(3, 5))\nplt.grid(True, lw=1, color='0.5', alpha=0.3)\nds_osnap['moc_total'].mean(dim='time_counter').plot(yincrease=False, y='sigma0_bins', label='Total')\nds_osnap['moc_east'].mean(dim='time_counter').plot(yincrease=False, y='sigma0_bins', label='OEast')\nds_osnap['moc_west'].mean(dim='time_counter').plot(yincrease=False, y='sigma0_bins', label='OWest')\n\nplt.xlabel(\"$\\\\Psi_{\\\\sigma_0}$ (Sv)\", fontdict={\"size\": 10, \"weight\": \"bold\"})\nplt.ylabel(\"Potential Density $\\\\sigma_0$ (kg m$^{-3}$)\", fontdict={\"size\": 10, \"weight\": \"bold\"})\nplt.legend()\n</pre> # Plot time-mean diapycnal overturning stream functions along the OSNAP section: plt.figure(figsize=(3, 5)) plt.grid(True, lw=1, color='0.5', alpha=0.3) ds_osnap['moc_total'].mean(dim='time_counter').plot(yincrease=False, y='sigma0_bins', label='Total') ds_osnap['moc_east'].mean(dim='time_counter').plot(yincrease=False, y='sigma0_bins', label='OEast') ds_osnap['moc_west'].mean(dim='time_counter').plot(yincrease=False, y='sigma0_bins', label='OWest')  plt.xlabel(\"$\\\\Psi_{\\\\sigma_0}$ (Sv)\", fontdict={\"size\": 10, \"weight\": \"bold\"}) plt.ylabel(\"Potential Density $\\\\sigma_0$ (kg m$^{-3}$)\", fontdict={\"size\": 10, \"weight\": \"bold\"}) plt.legend() Out[14]: <pre>&lt;matplotlib.legend.Legend at 0x15099e7042f0&gt;</pre>"},{"location":"recipe_extract_osnap/#description","title":"Description\u00b6","text":"<p>Recipe showing how to extract the Overturning in the Subpolar North Atlantic (OSNAP) trans-basin hydrographic section using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using ERA-5 climatologically adjusted atmospheric forcing from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_extract_osnap/#background","title":"Background\u00b6","text":"<p>The Overturning in the Subpolar North Atlantic Program (OSNAP) is an international program designed to provide a continuous record of the full-water column, trans-basin fluxes of heat, mass and freshwater in the subpolar North Atlantic.</p> <p>The OSNAP observing system comprises of two trans-basin arrays: extending from southern Labrador to the southwestern tip of Greenland across the Labrador Sea (OSNAP West), and from the southeastern tip of Greenland to Scotland (OSNAP East).</p> <p>The diapycnal overturning stream function is used to characterise the strength and structure of the AMOC in density-space (e.g., $\\sigma_{0}$ or $\\sigma_{2}$) across OSNAP and can be defined at time $t$ as follows:</p> <p>$$\\Psi_{\\sigma}(\\sigma, t) = \\int_{\\sigma_{min}}^{\\sigma} \\int_{x_w}^{x_e} v(x, \\sigma, t) \\ dx \\ d\\sigma$$</p> <p>where the velocity field $v(x, \\sigma, t)$ normal to OSNAP is first integrated zonally between the western $x_w$ and eastern $x_e$ boundaries of the basin, before being accumulated from the sea surface $\\sigma_{min}$ to a specified isopycnal $\\sigma$.</p>"},{"location":"recipe_extract_osnap/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_extract_osnap/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 NEMO model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_extract_osnap/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and T, U &amp; V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_extract_osnap/#preparing-osnap-coordinates","title":"Preparing OSNAP Coordinates\u00b6","text":"<p>Next, we will prepare geographical (lat, lon) coordinates defining the Overturning in the Subpolar North Atlantic (OSNAP) array from the JASMIN Object Store.</p>"},{"location":"recipe_extract_osnap/#extracting-the-osnap-array-as-a-continuous-hydrographic-section","title":"Extracting the OSNAP array as a continuous hydrographic section\u00b6","text":"<p>Now, let's use the <code>extract_section()</code> function to extract the OSNAP array from our NEMO model output.</p> <p>We need to provide the names of the zonal &amp; meridional velocity variables (<code>uv_vars=[\"uo\", \"vo\"]</code>) and any scalar variables (e.g. potential density <code>vars=sigma0</code>) to extract along the secton.</p>"},{"location":"recipe_extract_osnap/#visualising-properties-along-the-osnap-array","title":"Visualising properties along the OSNAP array\u00b6","text":"<p>Next, let's plot the time-mean potential density along the OSNAP array:</p>"},{"location":"recipe_extract_osnap/#calculating-meridional-overturning-stream-functions-along-the-osnap-array","title":"Calculating Meridional Overturning Stream Functions along the OSNAP array\u00b6","text":"<p>Finally, let's calculate the meridional overturning stream function in potential density coordinates along the OSNAP array using the <code>.compute_binned_statistic()</code> function:</p>"},{"location":"recipe_extract_osnap/#visualising-the-time-mean-diapycnal-overturning-stream-functions","title":"Visualising the time-mean diapycnal overturning stream functions\u00b6","text":"<p>Finally, let's visualise the results by plotting the time-mean OSNAP overturning stream functions in potential density-coordinates:</p>"},{"location":"recipe_masked_stats/","title":"Regional Masked Statistics","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import numpy as np import xarray as xr import matplotlib.pyplot as plt from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x1482831ea270&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[2]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})\n             .squeeze()\n             .rename({'z': 'nav_lev'})\n             )\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})              .squeeze()              .rename({'z': 'nav_lev'})              )  ds_domain Out[2]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (y: 331, x: 360, nav_lev: 75)\nDimensions without coordinates: y, x, nav_lev\nData variables: (12/54)\n    e1t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2v            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bottom_level   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2u            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bathy_metry    (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (nav_lev) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   float64 8B dask.array&lt;chunksize=(), meta=np.ndarray&gt;\n    top_level      (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we will import the sea surface temperature and sea surface salinity stored at T-points in a single dataset.</p> <p>Typically, NEMO model outputs defined on T-grid points are stored together in netCDF files. In this case, you can replace <code>xr.merge()</code> with a single call to xarray's <code>open_dataset()</code> function passing the file path to your <code>_gridT.nc</code> file(s).</p> In\u00a0[3]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1m\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['tos_con', 'sos_abs']], compat=\"override\")\n\nds_gridT\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1m\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['tos_con', 'sos_abs']], compat=\"override\")  ds_gridT Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 552MB\nDimensions:        (y: 331, x: 360, time_counter: 577)\nCoordinates:\n  * time_counter   (time_counter) datetime64[ns] 5kB 1976-01-16T12:00:00 ... ...\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 5kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: y, x\nData variables:\n    tos_con        (time_counter, y, x) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    sos_abs        (time_counter, y, x) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean (interval: 3600 s)\n    interval_operation:  3600 s\n    interval_write:      1 month\n    long_name:           sea_surface_conservative_temperature\n    online_operation:    average\n    standard_name:       sea_surface_temperature\n    units:               degC</pre> In\u00a0[4]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[4]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 577)\n\u2502   Coordinates:\n\u2502     * time_counter   (time_counter) datetime64[ns] 5kB 1976-01-16T12:00:00 ... ...\n\u2502       time_centered  (time_counter) datetime64[ns] 5kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:        (time_counter: 577, j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           time_centered  (time_counter) datetime64[ns] 5kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           tos_con        (time_counter, j, i) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           sos_abs        (time_counter, j, i) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           e1t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level      (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level   (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502           tmaskutil      (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           umaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           vmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           wmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n            fmaskutil     (j, i) bool 119kB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> In\u00a0[5]: Copied! <pre># Define bounding box (lon_min, lon_max, lat_min, lat_max)\nbbox = (-80, 10, 20, 70)\n\n# Clip eORCA1 model T-grid to bounding box:\nnemo_clipped = nemo.clip_grid(grid='gridT', bbox=bbox)\n\n# Plotting time-mean sea surface temperature for the regional sub-domain:\nnemo_clipped['gridT']['tos_con'].mean(dim='time_counter').plot()\n\nnemo_clipped\n</pre> # Define bounding box (lon_min, lon_max, lat_min, lat_max) bbox = (-80, 10, 20, 70)  # Clip eORCA1 model T-grid to bounding box: nemo_clipped = nemo.clip_grid(grid='gridT', bbox=bbox)  # Plotting time-mean sea surface temperature for the regional sub-domain: nemo_clipped['gridT']['tos_con'].mean(dim='time_counter').plot()  nemo_clipped Out[5]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 577)\n\u2502   Coordinates:\n\u2502     * time_counter   (time_counter) datetime64[ns] 5kB 1976-01-16T12:00:00 ... ...\n\u2502       time_centered  (time_counter) datetime64[ns] 5kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:        (time_counter: 577, j: 83, i: 90, k: 75)\n\u2502       Coordinates:\n\u2502         * j              (j) int64 664B 223 224 225 226 227 ... 301 302 303 304 305\n\u2502         * i              (i) int64 720B 208 209 210 211 212 ... 293 294 295 296 297\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           time_centered  (time_counter) datetime64[ns] 5kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 60kB 20.54 20.54 20.55 ... 71.4 71.07 70.74\n\u2502           glamt          (j, i) float64 60kB -79.5 -78.5 -77.5 ... 30.06 31.15 32.2\n\u2502       Data variables:\n\u2502           tos_con        (time_counter, j, i) float32 17MB dask.array&lt;chunksize=(1, 83, 90), meta=np.ndarray&gt;\n\u2502           sos_abs        (time_counter, j, i) float32 17MB dask.array&lt;chunksize=(1, 83, 90), meta=np.ndarray&gt;\n\u2502           e1t            (j, i) float64 60kB dask.array&lt;chunksize=(83, 90), meta=np.ndarray&gt;\n\u2502           e2t            (j, i) float64 60kB dask.array&lt;chunksize=(83, 90), meta=np.ndarray&gt;\n\u2502           top_level      (j, i) int32 30kB dask.array&lt;chunksize=(83, 90), meta=np.ndarray&gt;\n\u2502           bottom_level   (j, i) int32 30kB dask.array&lt;chunksize=(83, 90), meta=np.ndarray&gt;\n\u2502           tmask          (k, j, i) bool 560kB True True True ... False False False\n\u2502           tmaskutil      (j, i) bool 7kB True True True False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   False\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           umaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           vmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           wmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n            fmaskutil     (j, i) bool 119kB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> In\u00a0[6]: Copied! <pre># Open OSNAP gridded observations dataset: \nds_osnap = xr.open_zarr(\"https://noc-msm-o.s3-ext.jc.rl.ac.uk/ocean-obs/OSNAP/OSNAP_Gridded_TSV_201408_202006_2023\")\n\n# Define a closed polygon which includes both the OSNAP West &amp; East arrays:\nlon_poly = np.concatenate([ds_osnap['LONGITUDE'].values, np.array([ds_osnap['LONGITUDE'][-1], ds_osnap['LONGITUDE'][0]])])\nlat_poly = np.concatenate([ds_osnap['LATITUDE'].values, np.array([ds_osnap['LATITUDE'][0], ds_osnap['LATITUDE'][0]])])\n</pre> # Open OSNAP gridded observations dataset:  ds_osnap = xr.open_zarr(\"https://noc-msm-o.s3-ext.jc.rl.ac.uk/ocean-obs/OSNAP/OSNAP_Gridded_TSV_201408_202006_2023\")  # Define a closed polygon which includes both the OSNAP West &amp; East arrays: lon_poly = np.concatenate([ds_osnap['LONGITUDE'].values, np.array([ds_osnap['LONGITUDE'][-1], ds_osnap['LONGITUDE'][0]])]) lat_poly = np.concatenate([ds_osnap['LATITUDE'].values, np.array([ds_osnap['LATITUDE'][0], ds_osnap['LATITUDE'][0]])]) <p>Now we have defined our polygon, we can use the <code>mask_with_polygon()</code> method to return the boolean mask classifying whether NEMO model grid points are inside (True) or outside (False) the polygon</p> In\u00a0[7]: Copied! <pre># Masking T-grid using polygon coordinates:\nmask_spg = nemo_clipped.mask_with_polygon(grid='gridT', lon_poly=lon_poly, lat_poly=lat_poly)\n\n# Plotting SPG polygon sub-domain:\nplt.figure()\nplt.pcolormesh(nemo_clipped['gridT']['glamt'], nemo_clipped['gridT']['gphit'], nemo_clipped['gridT']['tos_con'].mean(dim='time_counter'), cmap='RdBu_r')\nplt.plot(lon_poly, lat_poly, color='0.1', lw=2)\nplt.colorbar(label='Sea Surface Temperature (\u00b0C)')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n# Plotting time-mean sea surface temperature for the SPG polygon sub-domain:\nplt.figure()\nplt.pcolormesh(nemo_clipped['gridT']['glamt'], nemo_clipped['gridT']['gphit'], nemo_clipped['gridT']['tos_con'].mean(dim='time_counter').where(mask_spg), cmap='RdBu_r')\nplt.plot(lon_poly, lat_poly, color='0.1', lw=2)\nplt.colorbar(label='Sea Surface Temperature (\u00b0C)')\nplt.xlabel('Longitude')\nplt.xlim([-70, 5])\nplt.ylabel('Latitude')\nplt.ylim([40, 70])\nplt.show()\n</pre> # Masking T-grid using polygon coordinates: mask_spg = nemo_clipped.mask_with_polygon(grid='gridT', lon_poly=lon_poly, lat_poly=lat_poly)  # Plotting SPG polygon sub-domain: plt.figure() plt.pcolormesh(nemo_clipped['gridT']['glamt'], nemo_clipped['gridT']['gphit'], nemo_clipped['gridT']['tos_con'].mean(dim='time_counter'), cmap='RdBu_r') plt.plot(lon_poly, lat_poly, color='0.1', lw=2) plt.colorbar(label='Sea Surface Temperature (\u00b0C)') plt.xlabel('Longitude') plt.ylabel('Latitude') plt.show()  # Plotting time-mean sea surface temperature for the SPG polygon sub-domain: plt.figure() plt.pcolormesh(nemo_clipped['gridT']['glamt'], nemo_clipped['gridT']['gphit'], nemo_clipped['gridT']['tos_con'].mean(dim='time_counter').where(mask_spg), cmap='RdBu_r') plt.plot(lon_poly, lat_poly, color='0.1', lw=2) plt.colorbar(label='Sea Surface Temperature (\u00b0C)') plt.xlabel('Longitude') plt.xlim([-70, 5]) plt.ylabel('Latitude') plt.ylim([40, 70]) plt.show() In\u00a0[8]: Copied! <pre># Calculating the area weighted-mean sea surface temperature in the SPG region:\nsst_wmean = nemo_clipped.masked_statistic(grid=\"gridT\",\n                                          var=\"tos_con\",\n                                          lon_poly=lon_poly,\n                                          lat_poly=lat_poly,\n                                          statistic=\"weighted_mean\",\n                                          dims=[\"i\", \"j\"]\n                                          )\n\nsst_wmean= sst_wmean.compute()\n</pre> # Calculating the area weighted-mean sea surface temperature in the SPG region: sst_wmean = nemo_clipped.masked_statistic(grid=\"gridT\",                                           var=\"tos_con\",                                           lon_poly=lon_poly,                                           lat_poly=lat_poly,                                           statistic=\"weighted_mean\",                                           dims=[\"i\", \"j\"]                                           )  sst_wmean= sst_wmean.compute() In\u00a0[9]: Copied! <pre># Plotting the area weighted-mean sea surface temperature time series for the SPG region:\nsst_wmean.plot(lw=1, color='0.1', alpha=0.3)\nsst_wmean.rolling(time_counter=12, center=True).mean().plot(lw=3, color='0.1')\nplt.title('Area Weighted Mean SST for SPG Region', fontsize=12, fontweight='bold')\nplt.xlabel('Time', fontsize=12)\nplt.ylabel('Sea Surface Temperature (\u00b0C)', fontsize=12)\n</pre> # Plotting the area weighted-mean sea surface temperature time series for the SPG region: sst_wmean.plot(lw=1, color='0.1', alpha=0.3) sst_wmean.rolling(time_counter=12, center=True).mean().plot(lw=3, color='0.1') plt.title('Area Weighted Mean SST for SPG Region', fontsize=12, fontweight='bold') plt.xlabel('Time', fontsize=12) plt.ylabel('Sea Surface Temperature (\u00b0C)', fontsize=12) Out[9]: <pre>Text(0, 0.5, 'Sea Surface Temperature (\u00b0C)')</pre>"},{"location":"recipe_masked_stats/#description","title":"Description\u00b6","text":"<p>This recipe shows how to calculate statistics for regional sub-domains using monthly-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_masked_stats/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_masked_stats/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 JRA-55 model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_masked_stats/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_masked_stats/#defining-a-regional-sub-domain-using-a-bounding-box","title":"Defining a Regional Sub-Domain using a Bounding Box\u00b6","text":"<p>Now we have constructed our <code>NEMODataTree</code>, let's start by defining a regional sub-domain using a geographical bounding box.</p> <p>By using the <code>clip_grid()</code> method, we can modify the size of the specfied grid stored in our NEMODataTree.</p> <p>Alternatively, we can use <code>clip_domain()</code> to clip all of the grids associated with a given NEMO model domain to a given bounding box.</p>"},{"location":"recipe_masked_stats/#defining-a-regional-sub-domain-using-a-polygon","title":"Defining a Regional Sub-Domain using a Polygon\u00b6","text":"<p>Next, let's define a more complex regional sub-domain by constructing a mask using a polygon.</p> <p>Since we have already clipped the T-grid of our NEMODataTree parent domain, we will define a polygon comprised of longitude-latitude coordinates within this region.</p> <p>We will use the Overturning in the Subpolar North Atlantic Program (OSNAP) observational array coordinates made available via the JASMIN Object Store to construct a polygon enclosing the North Atlantic subpolar gyre.</p>"},{"location":"recipe_masked_stats/#calculating-statistics-for-a-regional-sub-domain","title":"Calculating statistics for a Regional Sub-Domain\u00b6","text":"<p>Finally, let's use our North Atlantic subpolar gyre polygon to calculate statistics for this regional sub-domain of the eORCA1 model.</p> <p>Given a closed polygon, we can use the <code>masked_statistic()</code> method to calculate statistics of a specified variable in the masked sub-domain</p>"},{"location":"recipe_moc_tracer/","title":"Meridional Overturning - Tracer Space","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport gsw\nimport numpy as np\nimport xarray as xr\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import gsw import numpy as np import xarray as xr from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x1794c16a0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[\u00a0]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})\n             .squeeze()\n             .rename({'z': 'nav_lev'})\n             )\n# Open eORCA1 ocean basin masks:\nds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})              .squeeze()              .rename({'z': 'nav_lev'})              ) # Open eORCA1 ocean basin masks: ds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})  ds_domain Out[\u00a0]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (y: 331, x: 360, nav_lev: 75)\nDimensions without coordinates: y, x, nav_lev\nData variables: (12/54)\n    e1t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2v            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bottom_level   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2u            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bathy_metry    (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (nav_lev) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   float64 8B dask.array&lt;chunksize=(), meta=np.ndarray&gt;\n    top_level      (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we need to import the conservative temperature and absolute salinity stored at T-points in a single dataset.</p> <p>Typically, NEMO model outputs defined on T-grid points are stored together in netCDF files. In this case, you can replace <code>xr.merge()</code> with a single call to xarray's <code>open_dataset()</code> function passing the file path to your <code>_gridT.nc</code> file(s).</p> In\u00a0[3]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['thetao_con', 'so_abs']], compat=\"override\")\nds_gridT = ds_gridT.sel(time_counter=slice(\"1976-01\", \"2023-12\"))\n\n# Calculate potential density anomaly referenced to the sea surface (kg/m3):\nds_gridT['sigma0'] = gsw.density.sigma0(CT=ds_gridT['thetao_con'], SA=ds_gridT['so_abs'])\nds_gridT['sigma0'].name = 'sigma0'\n\nds_gridT\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['thetao_con', 'so_abs']], compat=\"override\") ds_gridT = ds_gridT.sel(time_counter=slice(\"1976-01\", \"2023-12\"))  # Calculate potential density anomaly referenced to the sea surface (kg/m3): ds_gridT['sigma0'] = gsw.density.sigma0(CT=ds_gridT['thetao_con'], SA=ds_gridT['so_abs']) ds_gridT['sigma0'].name = 'sigma0'  ds_gridT Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 7GB\nDimensions:        (deptht: 75, y: 331, x: 360, time_counter: 48)\nCoordinates:\n  * deptht         (deptht) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n  * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: y, x\nData variables:\n    thetao_con     (time_counter, deptht, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    so_abs         (time_counter, deptht, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    sigma0         (time_counter, deptht, y, x) float64 3GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean\n    interval_operation:  1 yr\n    interval_write:      1 yr\n    long_name:           sea_water_conservative_temperature\n    online_operation:    average\n    standard_name:       sea_water_conservative_temperature\n    units:               degC</pre> <p>Next, we need to import the meridional velocity and vertical grid cell thicknesses stored at V-points in a single dataset.</p> <p>Typically, NEMO model outputs defined on V-grid points are stored together in netCDF files. In this case, you can replace <code>xr.merge()</code> with a single call to xarray's <code>open_dataset()</code> function passing the file path to your <code>_gridV.nc</code> file(s).</p> In\u00a0[4]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/V1y\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\")\nds_gridV = ds_gridV.sel(time_counter=slice(\"1976-01\", \"2023-12\"))\n\nds_gridV\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/V1y\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\") ds_gridV = ds_gridV.sel(time_counter=slice(\"1976-01\", \"2023-12\"))  ds_gridV Out[4]: <pre>&lt;xarray.Dataset&gt; Size: 3GB\nDimensions:        (depthv: 75, y: 331, x: 360, time_counter: 48)\nCoordinates:\n  * depthv         (depthv) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n  * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: y, x\nData variables:\n    e3v            (time_counter, depthv, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    vo             (time_counter, depthv, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean (interval: 3600 s)\n    interval_operation:  3600 s\n    interval_write:      1 yr\n    long_name:           V-cell thickness\n    online_operation:    average\n    standard_name:       cell_thickness\n    units:               m</pre> In\u00a0[5]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT, \"gridV\": ds_gridV}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT, \"gridV\": ds_gridV}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[5]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 48)\n\u2502   Coordinates:\n\u2502     * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\n\u2502       time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:        (time_counter: 48, k: 75, j: 331, i: 360)\n\u2502       Coordinates:\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * deptht         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           thetao_con     (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           so_abs         (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           sigma0         (time_counter, k, j, i) float64 3GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           e1t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level      (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level   (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502           tmaskutil      (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           umaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:        (time_counter: 48, k: 75, j: 331, i: 360)\n\u2502       Coordinates:\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * depthv         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphiv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e3v            (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           vo             (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           e1v            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502           vmaskutil      (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           cell_methods:        time: mean (interval: 3600 s)\n\u2502           interval_operation:  3600 s\n\u2502           interval_write:      1 yr\n\u2502           long_name:           V-cell thickness\n\u2502           online_operation:    average\n\u2502           standard_name:       cell_thickness\n\u2502           units:               m\n\u2502           nftype:              F\n\u2502           iperio:              True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           wmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n            fmaskutil     (j, i) bool 119kB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> In\u00a0[6]: Copied! <pre># Define Atlantic Ocean basin mask:\natlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"}).astype(bool)\n# Assign (i,j) coordinates of V-points:\natlmask['i'] = atlmask['i'] + 1\natlmask['j'] = atlmask['j'] + 1.5\n\n# Add meridional volume transport [m3/s] to NEMO V-grid - meridional velocity [m/s] * area of meridional grid cell face [m2]:\nnemo['gridV']['volume_transport'] = (nemo['gridV']['vo'] * nemo.cell_area(grid='gridV', dim='j'))\n\n# Transform potential density from NEMO T-grid to V-grid using linear interpolation:\nnemo['gridV']['sigma0'] = nemo.transform_to(grid='gridT', var='sigma0', to='V')\n</pre> # Define Atlantic Ocean basin mask: atlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"}).astype(bool) # Assign (i,j) coordinates of V-points: atlmask['i'] = atlmask['i'] + 1 atlmask['j'] = atlmask['j'] + 1.5  # Add meridional volume transport [m3/s] to NEMO V-grid - meridional velocity [m/s] * area of meridional grid cell face [m2]: nemo['gridV']['volume_transport'] = (nemo['gridV']['vo'] * nemo.cell_area(grid='gridV', dim='j'))  # Transform potential density from NEMO T-grid to V-grid using linear interpolation: nemo['gridV']['sigma0'] = nemo.transform_to(grid='gridT', var='sigma0', to='V') In\u00a0[\u00a0]: Copied! <pre># Define potential density bins [kg /m3]:\nsigma0_bins = np.arange(22, 29, 0.01)\n\n# Compute meridional volume transport in latitude-potential density coords:\nvt_sigma0_atl = nemo.binned_statistic(grid=\"gridV\",\n                                      vars=[\"sigma0\"],\n                                      values=\"volume_transport\",\n                                      keep_dims=[\"time_counter\", \"j\"],\n                                      bins=[sigma0_bins],\n                                      statistic=\"nansum\",\n                                      mask=atlmask\n                                      )\n\nvt_sigma0_atl\n</pre> # Define potential density bins [kg /m3]: sigma0_bins = np.arange(22, 29, 0.01)  # Compute meridional volume transport in latitude-potential density coords: vt_sigma0_atl = nemo.binned_statistic(grid=\"gridV\",                                       vars=[\"sigma0\"],                                       values=\"volume_transport\",                                       keep_dims=[\"time_counter\", \"j\"],                                       bins=[sigma0_bins],                                       statistic=\"nansum\",                                       mask=atlmask                                       )  vt_sigma0_atl Out[\u00a0]: <pre>&lt;xarray.DataArray 'volume_transport' (time_counter: 48, j: 331, sigma0_bins: 699)&gt; Size: 89MB\ndask.array&lt;reshape, shape=(48, 331, 699), dtype=float64, chunksize=(48, 331, 699), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time_counter  (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-0...\n  * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n  * sigma0_bins   (sigma0_bins) float64 6kB 22.01 22.02 22.03 ... 28.98 28.99\nAttributes:\n    interval_write:    1 yr\n    online_operation:  average</pre> <p>Notice that the resulting DataArray includes a dask array, so we haven't actually computed the diapycnal overturning yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[8]: Copied! <pre># Compute diapycnal overturning stream function in Sverdrups [1 Sv = 1E6 m3/s]:\n# Here, we accumulate diapycnal volume transports from the lightest to the densest\n# isopycnal surface.\nmoc_sigma0_atl = 1E-6 * vt_sigma0_atl.cumsum(dim='sigma0_bins').compute()\nmoc_sigma0_atl.name = 'moc_sigma0_atl'\n\nmoc_sigma0_atl\n</pre> # Compute diapycnal overturning stream function in Sverdrups [1 Sv = 1E6 m3/s]: # Here, we accumulate diapycnal volume transports from the lightest to the densest # isopycnal surface. moc_sigma0_atl = 1E-6 * vt_sigma0_atl.cumsum(dim='sigma0_bins').compute() moc_sigma0_atl.name = 'moc_sigma0_atl'  moc_sigma0_atl <pre>OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n</pre> Out[8]: <pre>&lt;xarray.DataArray 'moc_sigma0_atl' (time_counter: 48, j: 331, sigma0_bins: 699)&gt; Size: 89MB\narray([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        ...,\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.30921961e-01, -9.30921961e-01, -9.30921961e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.45353998e-01, -9.45353998e-01, -9.45353998e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n\n       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n...\n         -9.51691358e-01, -9.51691358e-01, -9.51691358e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.57064748e-01, -9.57064748e-01, -9.57064748e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n\n       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        ...,\n        [-1.24457492e-03, -1.24457492e-03, -1.24457492e-03, ...,\n         -9.02882356e-01, -9.02882356e-01, -9.02882356e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.11390452e-01, -9.11390452e-01, -9.11390452e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n      shape=(48, 331, 699))\nCoordinates:\n  * time_counter  (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-0...\n  * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n  * sigma0_bins   (sigma0_bins) float64 6kB 22.01 22.02 22.03 ... 28.98 28.99\nAttributes:\n    interval_write:    1 yr\n    online_operation:  average</pre> In\u00a0[9]: Copied! <pre>moc_sigma0_atl.mean(dim='time_counter').plot(y='sigma0_bins', yincrease=False)\n</pre> moc_sigma0_atl.mean(dim='time_counter').plot(y='sigma0_bins', yincrease=False) Out[9]: <pre>&lt;matplotlib.collections.QuadMesh at 0x17ff6f8c0&gt;</pre>"},{"location":"recipe_moc_tracer/#description","title":"Description\u00b6","text":"<p>This recipe shows how to calculate the Atlantic Meridional Overturning Circulation (AMOC) stream function in potential density-coordinates using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_moc_tracer/#background","title":"Background\u00b6","text":"<p>The diapycnal overturning stream function is routinely used to characterise the strength and structure of the AMOC in density-space (e.g., $\\sigma_{0}$ or $\\sigma{2}$) as a function of latitude $\\phi$ and can be defined at time $t$ as follows:</p> <p>$$\\Psi_{\\sigma_{0}}(\\phi, \\sigma_{0}, t) = \\int_{x_w}^{x_e} \\int_{z(\\lambda, \\phi, \\sigma_{0})}^{\\eta} v(\\lambda, \\phi, z', t) \\ dz' \\ dx$$</p> <p>where the meridional velocity $v(\\lambda, \\phi, z, t)$ is first accumulated vertically from the sea surface $\\eta$ to a specified isopycnal depth $z(\\lambda, \\phi, \\sigma_{0})$ (decreasing downward) before being integrated zonally between the western $x_w$ and eastern $x_e$ boundaries of the basin.</p>"},{"location":"recipe_moc_tracer/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_moc_tracer/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 NEMO model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_moc_tracer/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and T- &amp; V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_moc_tracer/#calculating-the-amoc-diapycnal-overturning-stream-function","title":"Calculating the AMOC diapycnal overturning stream function\u00b6","text":"<p>Now we have constructed our <code>NEMODataTree</code>, let's calculate the diapycnal overturning stream function.</p>"},{"location":"recipe_moc_tracer/#visualising-the-time-mean-amoc-diapycnal-overturning-stream-function","title":"Visualising the time-mean AMOC diapycnal overturning stream function\u00b6","text":"<p>Finally, let's visualise the results by plotting the time-mean Atlantic Meridional Overturning stream function in potential density-coordinates:</p>"},{"location":"recipe_moc_z/","title":"Meridional Overturning - Depth Space","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport xarray as xr\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import xarray as xr from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x16ab81400&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[2]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})\n             .squeeze()\n             .rename({'z': 'nav_lev'})\n             )\nds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})              .squeeze()              .rename({'z': 'nav_lev'})              ) ds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})  ds_domain Out[2]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (y: 331, x: 360, nav_lev: 75)\nDimensions without coordinates: y, x, nav_lev\nData variables: (12/54)\n    e1t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2v            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bottom_level   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2u            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bathy_metry    (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (nav_lev) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   float64 8B dask.array&lt;chunksize=(), meta=np.ndarray&gt;\n    top_level      (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we need to import the meridional velocity and vertical grid cell thicknesses stored at V-points in a single dataset.</p> <p>Typically, NEMO model outputs defined on V-grid points are stored together in netCDF files. In this case, you can replace <code>xr.merge()</code> with a single call to xarray's <code>open_dataset()</code> function passing the file path to your <code>_gridV.nc</code> file(s).</p> In\u00a0[3]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/V1y\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\")\n\nds_gridV\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/V1y\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridV = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['e3v', 'vo']], compat=\"override\")  ds_gridV Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 4GB\nDimensions:        (depthv: 75, y: 331, x: 360, time_counter: 49)\nCoordinates:\n  * depthv         (depthv) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n  * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: y, x\nData variables:\n    e3v            (time_counter, depthv, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    vo             (time_counter, depthv, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean (interval: 3600 s)\n    interval_operation:  3600 s\n    interval_write:      1 yr\n    long_name:           V-cell thickness\n    online_operation:    average\n    standard_name:       cell_thickness\n    units:               m</pre> In\u00a0[4]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain, \"gridV\": ds_gridV}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain, \"gridV\": ds_gridV}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[4]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 49)\n\u2502   Coordinates:\n\u2502     * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n\u2502       time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level     (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level  (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           tmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           umaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:        (time_counter: 49, k: 75, j: 331, i: 360)\n\u2502       Coordinates:\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * depthv         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphiv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e3v            (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           vo             (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           e1v            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502           vmaskutil      (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           cell_methods:        time: mean (interval: 3600 s)\n\u2502           interval_operation:  3600 s\n\u2502           interval_write:      1 yr\n\u2502           long_name:           V-cell thickness\n\u2502           online_operation:    average\n\u2502           standard_name:       cell_thickness\n\u2502           units:               m\n\u2502           nftype:              F\n\u2502           iperio:              True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           wmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n            fmaskutil     (j, i) bool 119kB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> In\u00a0[5]: Copied! <pre># Define Atlantic Ocean basin mask:\natlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"}).astype(bool)\n# Assign (i,j) coordinates of V-points:\natlmask['i'] = atlmask['i'] + 1\natlmask['j'] = atlmask['j'] + 1.5\n\n# Compute vertical meridional overturning stream function:\nmoc_z_atl = nemo.integral(grid=\"gridV\",\n                          var=\"vo\",\n                          dims=[\"i\", \"k\"], \n                          cum_dims=[\"k\"],\n                          dir=\"+1\",\n                          mask=atlmask\n                          )\n\nmoc_z_atl\n</pre> # Define Atlantic Ocean basin mask: atlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"}).astype(bool) # Assign (i,j) coordinates of V-points: atlmask['i'] = atlmask['i'] + 1 atlmask['j'] = atlmask['j'] + 1.5  # Compute vertical meridional overturning stream function: moc_z_atl = nemo.integral(grid=\"gridV\",                           var=\"vo\",                           dims=[\"i\", \"k\"],                            cum_dims=[\"k\"],                           dir=\"+1\",                           mask=atlmask                           )  moc_z_atl Out[5]: <pre>&lt;xarray.DataArray 'vo' (time_counter: 49, k: 75, j: 331)&gt; Size: 10MB\ndask.array&lt;nancumsum, shape=(49, 75, 331), dtype=float64, chunksize=(1, 25, 331), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n  * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n  * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n  * depthv         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n    time_centered  (time_counter) datetime64[ns] 392B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean\n    interval_operation:  1 yr\n    interval_write:      1 yr\n    long_name:           ocean current along j-axis\n    online_operation:    average\n    standard_name:       sea_water_y_velocity\n    units:               m/s</pre> <p>Notice that the resulting DataArray includes a dask array, so we haven't actually computed the vertical overturning yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[6]: Copied! <pre># Compute vertical overturning stream function in Sverdrups [1 Sv = 1E6 m3/s]:\nmoc_z_atl = 1E-6 * moc_z_atl.compute()\n\nmoc_z_atl\n</pre> # Compute vertical overturning stream function in Sverdrups [1 Sv = 1E6 m3/s]: moc_z_atl = 1E-6 * moc_z_atl.compute()  moc_z_atl Out[6]: <pre>&lt;xarray.DataArray 'vo' (time_counter: 49, k: 75, j: 331)&gt; Size: 10MB\narray([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -5.93256017e-03, -5.98465019e-03, -4.70669708e-03],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -1.23823036e-02, -1.24593425e-02, -9.82934168e-03],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -1.93505099e-02, -1.93588036e-02, -1.51586968e-02],\n        ...,\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.30921961e-01, -9.31773471e-01, -9.32592128e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.30921961e-01, -9.31773471e-01, -9.32592128e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.30921961e-01, -9.31773471e-01, -9.32592128e-01]],\n\n       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -9.31946621e-03, -9.62942149e-03, -1.12506309e-02],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -1.87225095e-02, -1.92967880e-02, -2.25915142e-02],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -2.81349402e-02, -2.89098083e-02, -3.37560596e-02],\n...\n         -8.73345777e-01, -8.73976184e-01, -8.73915069e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -8.73345777e-01, -8.73976184e-01, -8.73915069e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -8.73345777e-01, -8.73976184e-01, -8.73915069e-01]],\n\n       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        ...,\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n      shape=(49, 75, 331))\nCoordinates:\n  * time_counter   (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\n  * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n  * j              (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n  * depthv         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n    time_centered  (time_counter) datetime64[ns] 392B 1976-07-02 ... 2024-07-02\nAttributes:\n    cell_methods:        time: mean\n    interval_operation:  1 yr\n    interval_write:      1 yr\n    long_name:           ocean current along j-axis\n    online_operation:    average\n    standard_name:       sea_water_y_velocity\n    units:               m/s</pre> In\u00a0[7]: Copied! <pre>moc_z_atl.mean(dim='time_counter').plot(y='depthv', yincrease=False)\n</pre> moc_z_atl.mean(dim='time_counter').plot(y='depthv', yincrease=False) <pre>OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n</pre> Out[7]: <pre>&lt;matplotlib.collections.QuadMesh at 0x178f4b230&gt;</pre>"},{"location":"recipe_moc_z/#description","title":"Description\u00b6","text":"<p>This recipe shows how to calculate the Atlantic Meridional Overturning Circulation (AMOC) stream function in depth-coordinates using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_moc_z/#background","title":"Background\u00b6","text":"<p>The vertical overturning stream function is routinely used to characterise the strength and structure of the AMOC in depth-space as a function of latitude $\\phi$ and can be defined at time $t$ as follows:</p> <p>$$\\Psi_{z}(\\phi, z, t) = \\int_{z}^{\\eta} \\int_{x_w}^{x_e} v(\\lambda, \\phi, z, t) \\ dx \\ dz$$</p> <p>where the meridional velocity $v(\\lambda, \\phi, z, t)$ is first integrated zonally between the western $x_w$ and eastern $x_e$ boundaries of the basin before being accumulated vertically from the sea surface $\\eta$ to a specified depth $z(\\lambda, \\phi)$ (decreasing downward).</p>"},{"location":"recipe_moc_z/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_moc_z/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 JRA-55 model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_moc_z/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_moc_z/#calculating-the-amoc-vertical-overturning-stream-function","title":"Calculating the AMOC vertical overturning stream function\u00b6","text":"<p>Now we have constructed our <code>NEMODataTree</code>, let's calculate the vertical overturning stream function.</p> <p>In this example, our eORCA1 model uses $z^{*}$ vertical coordinates, so using <code>integral()</code>, which supports integration along the $i$, $j$, $k$ dimensions of the NEMO model grid, is appropriate. However, this would not be the case if using a NEMO model with geopotential / terrain-following coordinates.**</p>"},{"location":"recipe_moc_z/#visualising-the-time-mean-amoc-vertical-overturning-stream-function","title":"Visualising the time-mean AMOC vertical overturning stream function\u00b6","text":"<p>Finally, let's visualise the results by plotting the time-mean Atlantic Meridional Overturning stream function in depth-coordinates:</p>"},{"location":"recipe_sfwmt_sigma0/","title":"Surface-Forced Water Mass Transformation","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport gsw\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nimport matplotlib.pyplot as plt\nimport nemo_cookbook as ncb\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import gsw import numpy as np import pandas as pd import xarray as xr import matplotlib.pyplot as plt import nemo_cookbook as ncb from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x14bf355663c0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[2]: Copied! <pre># Open IHO World Seas polygons from GitHub as Pandas DataFrame:\nfilepaths = ncb.examples.get_filepaths(\"IHO\")\n\ndf_IHO_World_Seas = pd.read_parquet(filepaths['IHO_World_Seas_v3_polygons.parquet'])\ndf_IHO_World_Seas\n</pre> # Open IHO World Seas polygons from GitHub as Pandas DataFrame: filepaths = ncb.examples.get_filepaths(\"IHO\")  df_IHO_World_Seas = pd.read_parquet(filepaths['IHO_World_Seas_v3_polygons.parquet']) df_IHO_World_Seas Out[2]: ID Name MRGID Longitudes Latitudes 0 0 Rio de La Plata 4325 [[-54.943023652717045, -54.978746687192626, -5... [[-34.947906883078645, -34.97439280639835, -35... 1 1 Bass Strait 4366 [[149.90464234356938, 149.9049998519617, 149.9... [[-37.54324781853184, -37.54805552943908, -37.... 2 2 Great Australian Bight 4276 [[143.53250818354263, 143.54855731580784, 143.... [[-38.855345058560204, -38.89580867390668, -38... 3 3 Tasman Sea 4365 [[159.03333000000018, 159.03983414634163, 159.... [[-29.999999999999986, -30.043495934959335, -3... 4 4 Mozambique Channel 4261 [[43.38217926066437, 43.426910578414024, 43.47... [[-11.370205640977488, -11.374667237992885, -1... ... ... ... ... ... ... 96 96 Laccadive Sea 4269 [[79.19056582495296, 79.20560240772511, 79.205... [[9.28162992038466, 9.280296445224849, 9.28018... 97 97 Skagerrak 2379 [[10.66160702664314, 10.662945270907699, 10.66... [[59.91287636715083, 59.910394549469004, 59.90... 98 98 Norwegian Sea 2353 [[16.72106314339885, 16.78890655530549, 16.856... [[76.5645473926769, 76.50603497544391, 76.4475... 99 99 Ligurian Sea 3363 [[9.834412487214706, 9.835301503777828, 9.8349... [[44.0485148685363, 44.04729517147973, 44.0472... 100 100 Gulf of Guinea 4286 [[8.975150969002156, 8.974166710829394, 8.9742... [[-0.935921075698605, -0.9360325715092586, -0.... <p>101 rows \u00d7 5 columns</p> In\u00a0[3]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})\n             .squeeze()\n             .rename({'z': 'nav_lev'})\n             )\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})              .squeeze()              .rename({'z': 'nav_lev'})              )  ds_domain Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (y: 331, x: 360, nav_lev: 75)\nDimensions without coordinates: y, x, nav_lev\nData variables: (12/54)\n    e1t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2v            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bottom_level   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2u            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bathy_metry    (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (nav_lev) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   float64 8B dask.array&lt;chunksize=(), meta=np.ndarray&gt;\n    top_level      (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we need to import the sea surface temperature and salinity and net surface heat and freshwater fluxes stored at T-points in a single dataset.</p> In\u00a0[4]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1m\"\n\n# Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s):\nds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['tos_con', 'sos_abs', 'hfds', 'sowaflup']], compat=\"override\")\n\nds_gridT\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1m\"  # Construct NEMO model grid dataset, including vertical grid cell thicknesses (m) and meridional velocities (m/s): ds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['tos_con', 'sos_abs', 'hfds', 'sowaflup']], compat=\"override\")  ds_gridT Out[4]: <pre>&lt;xarray.Dataset&gt; Size: 1GB\nDimensions:        (y: 331, x: 360, time_counter: 577)\nCoordinates:\n  * time_counter   (time_counter) datetime64[ns] 5kB 1976-01-16T12:00:00 ... ...\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 5kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: y, x\nData variables:\n    tos_con        (time_counter, y, x) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    sos_abs        (time_counter, y, x) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    hfds           (time_counter, y, x) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n    sowaflup       (time_counter, y, x) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean (interval: 3600 s)\n    interval_operation:  3600 s\n    interval_write:      1 month\n    long_name:           sea_surface_conservative_temperature\n    online_operation:    average\n    standard_name:       sea_surface_temperature\n    units:               degC</pre> <p>Next, let's calculate the surface potential density anomaly referenced to the sea surface alongside the thermal expansion and haline contraction coefficients of seawater.</p> In\u00a0[5]: Copied! <pre># Calculate potential density anomaly referenced to the sea surface (kg/m3):\nds_gridT['sigma0'] = gsw.density.sigma0(CT=ds_gridT['tos_con'], SA=ds_gridT['sos_abs'])\nds_gridT['sigma0'].name = 'sigma0'\n\n# Calculate thermal expansion coefficient at sea surface:\nds_gridT['alpha'] = gsw.density.alpha(SA=ds_gridT['sos_abs'], CT=ds_gridT['tos_con'], p=0)\nds_gridT['alpha'].name = 'alpha'\n\n# Calculate haline contraction coefficient at sea surface:\nds_gridT['beta'] = gsw.density.beta(SA=ds_gridT['sos_abs'], CT=ds_gridT['tos_con'], p=0)\nds_gridT['beta'].name = 'beta'\n</pre> # Calculate potential density anomaly referenced to the sea surface (kg/m3): ds_gridT['sigma0'] = gsw.density.sigma0(CT=ds_gridT['tos_con'], SA=ds_gridT['sos_abs']) ds_gridT['sigma0'].name = 'sigma0'  # Calculate thermal expansion coefficient at sea surface: ds_gridT['alpha'] = gsw.density.alpha(SA=ds_gridT['sos_abs'], CT=ds_gridT['tos_con'], p=0) ds_gridT['alpha'].name = 'alpha'  # Calculate haline contraction coefficient at sea surface: ds_gridT['beta'] = gsw.density.beta(SA=ds_gridT['sos_abs'], CT=ds_gridT['tos_con'], p=0) ds_gridT['beta'].name = 'beta' In\u00a0[6]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[6]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 577)\n\u2502   Coordinates:\n\u2502     * time_counter   (time_counter) datetime64[ns] 5kB 1976-01-16T12:00:00 ... ...\n\u2502       time_centered  (time_counter) datetime64[ns] 5kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:        (time_counter: 577, j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           time_centered  (time_counter) datetime64[ns] 5kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables: (12/13)\n\u2502           tos_con        (time_counter, j, i) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           sos_abs        (time_counter, j, i) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           hfds           (time_counter, j, i) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           sowaflup       (time_counter, j, i) float32 275MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           sigma0         (time_counter, j, i) float64 550MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           alpha          (time_counter, j, i) float64 550MB dask.array&lt;chunksize=(1, 331, 360), meta=np.ndarray&gt;\n\u2502           ...             ...\n\u2502           e1t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level      (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level   (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502           tmaskutil      (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           umaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           vmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           wmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n            fmaskutil     (j, i) bool 119kB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> <p>Now, we will use the IHO World Seas polygons to extract the Labrador Sea from the eORCA1 model domain.</p> In\u00a0[7]: Copied! <pre># Define IHO World Seas Labrador Sea polygon:\nlon_poly = df_IHO_World_Seas[df_IHO_World_Seas['Name'] == 'Labrador Sea']['Longitudes'].item()[0]\nlat_poly = df_IHO_World_Seas[df_IHO_World_Seas['Name'] == 'Labrador Sea']['Latitudes'].item()[0]\n\n# Define boolean mask for Labrador Sea:\nmask = nemo.mask_with_polygon(grid='gridT', lon_poly=lon_poly, lat_poly=lat_poly)\n</pre> # Define IHO World Seas Labrador Sea polygon: lon_poly = df_IHO_World_Seas[df_IHO_World_Seas['Name'] == 'Labrador Sea']['Longitudes'].item()[0] lat_poly = df_IHO_World_Seas[df_IHO_World_Seas['Name'] == 'Labrador Sea']['Latitudes'].item()[0]  # Define boolean mask for Labrador Sea: mask = nemo.mask_with_polygon(grid='gridT', lon_poly=lon_poly, lat_poly=lat_poly) In\u00a0[8]: Copied! <pre># Plotting Labrador Sea sub-domain:\nplt.figure()\nplt.pcolormesh(nemo['gridT']['glamt'], nemo['gridT']['gphit'], nemo['gridT']['tos_con'].where(mask).mean(dim='time_counter'), cmap='RdBu_r')\nplt.plot(lon_poly, lat_poly, color='0.1', lw=2)\nplt.colorbar(label='Sea Surface Temperature (\u00b0C)')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.xlim([-80, 0])\nplt.ylim([45, 65])\n</pre> # Plotting Labrador Sea sub-domain: plt.figure() plt.pcolormesh(nemo['gridT']['glamt'], nemo['gridT']['gphit'], nemo['gridT']['tos_con'].where(mask).mean(dim='time_counter'), cmap='RdBu_r') plt.plot(lon_poly, lat_poly, color='0.1', lw=2) plt.colorbar(label='Sea Surface Temperature (\u00b0C)') plt.xlabel('Longitude') plt.ylabel('Latitude') plt.xlim([-80, 0]) plt.ylim([45, 65])  <pre>/tmp/ipykernel_2662064/3602607019.py:3: UserWarning: The input coordinates to pcolormesh are interpreted as cell centers, but are not monotonically increasing or decreasing. This may lead to incorrectly calculated cell edges, in which case, please supply explicit cell edges to pcolormesh.\n  plt.pcolormesh(nemo['gridT']['glamt'], nemo['gridT']['gphit'], nemo['gridT']['tos_con'].where(mask).mean(dim='time_counter'), cmap='RdBu_r')\n</pre> Out[8]: <pre>(45.0, 65.0)</pre> In\u00a0[9]: Copied! <pre># Define specific heat capacity of sea water [J kg-1 K-1]:\ncp0 = 3991.86795711963\n\n# Add sea surface density fluxes due to heat and freshwater fluxes to T-grid of NEMODataTree:\nnemo['gridT']['f_hf'] = -(nemo['gridT']['alpha'] / cp0) * nemo['gridT']['hfds']\nnemo['gridT']['f_fw'] = nemo['gridT']['beta'] * (nemo['gridT']['sos_abs'] / (1 - nemo['gridT']['sos_abs'])) * nemo['gridT']['sowaflup']\n</pre> # Define specific heat capacity of sea water [J kg-1 K-1]: cp0 = 3991.86795711963  # Add sea surface density fluxes due to heat and freshwater fluxes to T-grid of NEMODataTree: nemo['gridT']['f_hf'] = -(nemo['gridT']['alpha'] / cp0) * nemo['gridT']['hfds'] nemo['gridT']['f_fw'] = nemo['gridT']['beta'] * (nemo['gridT']['sos_abs'] / (1 - nemo['gridT']['sos_abs'])) * nemo['gridT']['sowaflup'] In\u00a0[10]: Copied! <pre># Define potential density bins [kg m-3]:\nsigma0_bins = np.arange(22, 29.05, 0.05)\ndsigma0 = 0.05\n\n# Compute surface forced water mass transformation across each surface T-grid cell [m3 s-1].\nnemo['gridT']['sfwmt'] = (1 / dsigma0) * (nemo['gridT']['f_hf'] + nemo['gridT']['f_fw']) * nemo.cell_area(grid='gridT', dim='k')\n\n# Compute total surface-force water mass transformation in discrete potential density coords:\nsfwmt_sigma0_atl = nemo.binned_statistic(grid=\"gridT\",\n                                         vars=[\"sigma0\"],\n                                         values=\"sfwmt\",\n                                         keep_dims=[\"time_counter\"],\n                                         bins=[sigma0_bins],\n                                         statistic=\"nansum\",\n                                         mask=mask\n                                         )\n\nsfwmt_sigma0_atl\n</pre> # Define potential density bins [kg m-3]: sigma0_bins = np.arange(22, 29.05, 0.05) dsigma0 = 0.05  # Compute surface forced water mass transformation across each surface T-grid cell [m3 s-1]. nemo['gridT']['sfwmt'] = (1 / dsigma0) * (nemo['gridT']['f_hf'] + nemo['gridT']['f_fw']) * nemo.cell_area(grid='gridT', dim='k')  # Compute total surface-force water mass transformation in discrete potential density coords: sfwmt_sigma0_atl = nemo.binned_statistic(grid=\"gridT\",                                          vars=[\"sigma0\"],                                          values=\"sfwmt\",                                          keep_dims=[\"time_counter\"],                                          bins=[sigma0_bins],                                          statistic=\"nansum\",                                          mask=mask                                          )  sfwmt_sigma0_atl Out[10]: <pre>&lt;xarray.DataArray 'sfwmt' (time_counter: 577, sigma0_bins: 140)&gt; Size: 646kB\ndask.array&lt;reshape, shape=(577, 140), dtype=float64, chunksize=(577, 140), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time_counter  (time_counter) datetime64[ns] 5kB 1976-01-16T12:00:00 ... 2...\n  * sigma0_bins   (sigma0_bins) float64 1kB 22.02 22.08 22.12 ... 28.93 28.98</pre> <p>Notice that the resulting DataArray includes a dask array, so we haven't actually computed the surface-forced water mass transformation yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[11]: Copied! <pre># Compute diapycnal surface-forced water mass transformation in Sverdrups [1 Sv = 1E6 m3/s]:\nsfwmt_sigma0_atl = (sfwmt_sigma0_atl / 1E6).compute()\nsfwmt_sigma0_atl.name = 'sfwmt_sigma0_atl'\n\nsfwmt_sigma0_atl\n</pre> # Compute diapycnal surface-forced water mass transformation in Sverdrups [1 Sv = 1E6 m3/s]: sfwmt_sigma0_atl = (sfwmt_sigma0_atl / 1E6).compute() sfwmt_sigma0_atl.name = 'sfwmt_sigma0_atl'  sfwmt_sigma0_atl Out[11]: <pre>&lt;xarray.DataArray 'sfwmt_sigma0_atl' (time_counter: 577, sigma0_bins: 140)&gt; Size: 646kB\narray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], shape=(577, 140))\nCoordinates:\n  * time_counter  (time_counter) datetime64[ns] 5kB 1976-01-16T12:00:00 ... 2...\n  * sigma0_bins   (sigma0_bins) float64 1kB 22.02 22.08 22.12 ... 28.93 28.98</pre> In\u00a0[12]: Copied! <pre>sfwmt_sigma0_atl.groupby('time_counter.month').mean().plot(y='sigma0_bins', yincrease=False)\n# Include tick labels for months:\nplt.xticks(ticks=np.arange(1, 13, 2), labels=['Jan', 'Mar', 'May', 'Jul', 'Sep', 'Nov'])\n</pre> sfwmt_sigma0_atl.groupby('time_counter.month').mean().plot(y='sigma0_bins', yincrease=False) # Include tick labels for months: plt.xticks(ticks=np.arange(1, 13, 2), labels=['Jan', 'Mar', 'May', 'Jul', 'Sep', 'Nov']) Out[12]: <pre>([&lt;matplotlib.axis.XTick at 0x14beee81e990&gt;,\n  &lt;matplotlib.axis.XTick at 0x14beee600a50&gt;,\n  &lt;matplotlib.axis.XTick at 0x14beee601810&gt;,\n  &lt;matplotlib.axis.XTick at 0x14beee600410&gt;,\n  &lt;matplotlib.axis.XTick at 0x14beee8fbc50&gt;,\n  &lt;matplotlib.axis.XTick at 0x14beee8f8410&gt;],\n [Text(1, 0, 'Jan'),\n  Text(3, 0, 'Mar'),\n  Text(5, 0, 'May'),\n  Text(7, 0, 'Jul'),\n  Text(9, 0, 'Sep'),\n  Text(11, 0, 'Nov')])</pre>"},{"location":"recipe_sfwmt_sigma0/#description","title":"Description\u00b6","text":"<p>This recipe shows how to calculate the surface-forced water mass transformation in potential density-coordinates using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_sfwmt_sigma0/#background","title":"Background\u00b6","text":"<p>The surface-forced diapycnal water mass transformation is used to quantify the volume flux across isopycnal outcrops due to surface buoyancy fluxes and can be defined at time $t$ as follows:</p> <p>First, we computing the surface density flux due to the fluxes of heat $Q_H$ (W m-2) and freshwater $Q_{FW}$ (kg m-2 s-1) at the sea surface following Speer and Tziperman (1992):</p> <p>$$f(\\lambda, \\phi, t) = -\\frac{\\alpha}{c_{p}} Q_{H}(\\lambda, \\phi, t) + \\beta \\frac{S(\\lambda, \\phi, t)}{1 - S(\\lambda, \\phi, t)} Q_{FW}(\\lambda, \\phi, t)$$</p> <p>where $\\alpha$ is the thermal expansion coefficient, $\\beta$ is the haline contraction coefficient, $c_p$ is the specific heat capacity of seawater and $S$ is the sea surface salinity. Notably, a positive surface density flux (i.e., $f(\\lambda, \\phi, t)$ &gt; 0 kg m\u22122 s\u22121) represents an increase in sea surface density.</p> <p>We then calculate the surface-forced diapycnal water mass transformation $H(\\sigma^{*}, t)$ across an outcropping isopycnal surface by integrating the surface density flux over the area of each surface density outcrop $\\sigma^{*}$:</p> <p>$$H(\\sigma^{*}, t) = \\frac{1}{\\Delta \\sigma} \\int \\int f(\\lambda, \\phi, t) \\ \\Pi(\\sigma^{*}(\\lambda, \\phi, t)) \\ \\ dx \\ dy$$</p> <p>where the $\\Pi(\\sigma^{*}(\\lambda, \\phi, t))$ operator is 1 when $|\\sigma^{*}(\\lambda, \\phi, t) - \\sigma| \\leq \\frac{\\Delta \\sigma}{2}$ and 0 elsewhere.</p>"},{"location":"recipe_sfwmt_sigma0/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_sfwmt_sigma0/#accessing-iho-world-seas-polygons","title":"Accessing IHO World Seas polygons\u00b6","text":"<p>Let's begin by loading the polygons defining the IHO World Seas regions.</p>"},{"location":"recipe_sfwmt_sigma0/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 NEMO model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_sfwmt_sigma0/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Using our outputs, let's create a NEMODataTree to store our domain and T-grid variables for the eORCA1 model.</p>"},{"location":"recipe_sfwmt_sigma0/#calculating-surface-forced-water-mass-transformation","title":"Calculating surface-forced water mass transformation\u00b6","text":"<p>Now we have constructed our <code>NEMODataTree</code>, let's calculate the diapycnal surface-forced water mass trasformation from the surface density flux due to surface heat and freshwater fluxes.</p>"},{"location":"recipe_sfwmt_sigma0/#visualising-the-seasonal-cycle-of-the-surface-forced-diapycnal-overturning-stream-function","title":"Visualising the seasonal cycle of the surface-forced diapycnal overturning stream function\u00b6","text":"<p>Finally, let's visualise the results by plotting the seasonal cycle of the surface-forced overturning stream function in potential density-coordinates for the Atlantic Ocean:</p>"},{"location":"recipe_transform_vertical_coords/","title":"Vertical Coordinate Transformation","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport numpy as np\nimport xarray as xr\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import numpy as np import xarray as xr from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x1469f7ea8980&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[2]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})\n             .squeeze()\n             .rename({'z': 'nav_lev'})\n             )\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})              .squeeze()              .rename({'z': 'nav_lev'})              )  ds_domain Out[2]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (y: 331, x: 360, nav_lev: 75)\nDimensions without coordinates: y, x, nav_lev\nData variables: (12/54)\n    e1t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2v            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bottom_level   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2u            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bathy_metry    (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (nav_lev) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   float64 8B dask.array&lt;chunksize=(), meta=np.ndarray&gt;\n    top_level      (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we need to import the sea water conservative temperature and absolute salinity stored at T-points in a single dataset.</p> In\u00a0[3]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"\n\n# Construct NEMO model grid dataset, including seawater conservative temperature (C) and absolute salinity (g/kg):\nds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={'deptht': 75})[var] for var in ['thetao_con', 'e3t']], compat=\"override\")\n\n# Subsetting the time_counter dimension: \nds_gridT = ds_gridT.sel(time_counter=slice('2000-01', '2010-12'))\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"  # Construct NEMO model grid dataset, including seawater conservative temperature (C) and absolute salinity (g/kg): ds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={'deptht': 75})[var] for var in ['thetao_con', 'e3t']], compat=\"override\")  # Subsetting the time_counter dimension:  ds_gridT = ds_gridT.sel(time_counter=slice('2000-01', '2010-12')) In\u00a0[4]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[4]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 11)\n\u2502   Coordinates:\n\u2502     * time_counter   (time_counter) datetime64[ns] 88B 2000-07-02 ... 2010-07-0...\n\u2502       time_centered  (time_counter) datetime64[ns] 88B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:        (time_counter: 11, k: 75, j: 331, i: 360)\n\u2502       Coordinates:\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * deptht         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 88B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           thetao_con     (time_counter, k, j, i) float32 393MB dask.array&lt;chunksize=(1, 75, 331, 360), meta=np.ndarray&gt;\n\u2502           e3t            (time_counter, k, j, i) float32 393MB dask.array&lt;chunksize=(1, 75, 331, 360), meta=np.ndarray&gt;\n\u2502           e1t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level      (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level   (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502           tmaskutil      (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           umaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           vmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           wmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n            fmaskutil     (j, i) bool 119kB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> <p>By examining the vertical profile &amp; the size of the <code>k</code> grid coordinate variable, we can see that our eORCA1 configuration has 75 unevenly-spaced z*-coordinate levels.</p> In\u00a0[5]: Copied! <pre># Plot an example time-mean vertical conservative temperature profile in the subpolar North Atlantic:\nnemo['gridT']['thetao_con'].isel(i=260, j=260, time_counter=0).plot(y='deptht', ylim=(3600, 0), marker='o')\n\n# Size of the vertical coordinate dimension:\nprint(nemo['gridT']['k'].size)\n</pre> # Plot an example time-mean vertical conservative temperature profile in the subpolar North Atlantic: nemo['gridT']['thetao_con'].isel(i=260, j=260, time_counter=0).plot(y='deptht', ylim=(3600, 0), marker='o')  # Size of the vertical coordinate dimension: print(nemo['gridT']['k'].size) <pre>75\n</pre> In\u00a0[6]: Copied! <pre># Define our target vertical grid coordinate:\ne3t_target = xr.DataArray(np.repeat(200.0, 30), dims=['k_new'])\n\ne3t_target\n</pre> # Define our target vertical grid coordinate: e3t_target = xr.DataArray(np.repeat(200.0, 30), dims=['k_new'])  e3t_target Out[6]: <pre>&lt;xarray.DataArray (k_new: 30)&gt; Size: 240B\narray([200., 200., 200., 200., 200., 200., 200., 200., 200., 200., 200.,\n       200., 200., 200., 200., 200., 200., 200., 200., 200., 200., 200.,\n       200., 200., 200., 200., 200., 200., 200., 200.])\nDimensions without coordinates: k_new</pre> In\u00a0[7]: Copied! <pre># Transform eORCA1 3-dimensional conservative temperature field to new vertical coordinate system:\nds_k_transform = nemo.transform_vertical_grid(grid = 'gridT',\n                                              var = 'thetao_con',\n                                              e3_new = e3t_target\n                                              )\n\nds_k_transform\n</pre> # Transform eORCA1 3-dimensional conservative temperature field to new vertical coordinate system: ds_k_transform = nemo.transform_vertical_grid(grid = 'gridT',                                               var = 'thetao_con',                                               e3_new = e3t_target                                               )  ds_k_transform Out[7]: <pre>&lt;xarray.Dataset&gt; Size: 631MB\nDimensions:        (time_counter: 11, j: 331, i: 360, k_new: 30)\nCoordinates:\n  * time_counter   (time_counter) datetime64[ns] 88B 2000-07-02 ... 2010-07-0...\n  * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n  * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n    time_centered  (time_counter) datetime64[ns] 88B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    deptht_new     (k_new) float64 240B 200.0 400.0 600.0 ... 5.8e+03 6e+03\nDimensions without coordinates: k_new\nData variables:\n    thetao_con     (time_counter, k_new, j, i) float64 315MB dask.array&lt;chunksize=(1, 30, 331, 360), meta=np.ndarray&gt;\n    e3t_new        (time_counter, j, i, k_new) float64 315MB dask.array&lt;chunksize=(1, 331, 360, 30), meta=np.ndarray&gt;</pre> <p>Notice that the output above returns a Dataset containing two DataArrays: the vertically remapped conservative temperature <code>thetao_con</code> and the vertical grid cell thicknesses <code>e3t_out</code> (accounting for partial grid cell at the sea floor).</p> <p>Since both of these DataArrays contain dask arrays, we haven't actually computed anything yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[8]: Copied! <pre>ds_k_transform = ds_k_transform.compute()\n</pre> ds_k_transform = ds_k_transform.compute() In\u00a0[9]: Copied! <pre># Plot our original time-mean vertical conservative temperature profile in the subpolar North Atlantic:\nnemo['gridT']['thetao_con'].isel(i=260, j=260, time_counter=0).plot(y='deptht', ylim=(3600, 0), marker='o', color='dodgerblue')\n\n# Plot our vertically transformed time-mean vertical conservative temperature profile in the subpolar North Atlantic:\nds_k_transform['thetao_con'].isel(i=260, j=260, time_counter=0).plot(y='deptht_new', ylim=(3600, 0), marker='o', color='coral')\n</pre> # Plot our original time-mean vertical conservative temperature profile in the subpolar North Atlantic: nemo['gridT']['thetao_con'].isel(i=260, j=260, time_counter=0).plot(y='deptht', ylim=(3600, 0), marker='o', color='dodgerblue')  # Plot our vertically transformed time-mean vertical conservative temperature profile in the subpolar North Atlantic: ds_k_transform['thetao_con'].isel(i=260, j=260, time_counter=0).plot(y='deptht_new', ylim=(3600, 0), marker='o', color='coral') Out[9]: <pre>[&lt;matplotlib.lines.Line2D at 0x1469f5327110&gt;]</pre> <p>We can also verify that the product of the vertical grid cell thickness (m) and conservative temperature (C) is conserved following the transformation.</p> <p>Note that we need to transform all variables to a consistent <code>dtype</code> (in this case float64) before making the comparison.</p> In\u00a0[10]: Copied! <pre># Calculate the sum of the product of the transformed conservative temperature and cell thickness at our example location:\nprint((ds_k_transform['thetao_con'].isel(time_counter=0, i=260, j=260).astype(np.float64) * ds_k_transform['e3t_new'].isel(time_counter=0, i=260, j=260).astype(np.float64)).sum().compute())\n\n# Calculate the sum of the product of the original conservative temperature and cell thickness at our example location:\nprint((nemo['gridT']['thetao_con'].isel(time_counter=0, i=260, j=260).astype(np.float64) * nemo['gridT']['e3t'].isel(time_counter=0, i=260, j=260).astype(np.float64)).sum().compute())\n</pre> # Calculate the sum of the product of the transformed conservative temperature and cell thickness at our example location: print((ds_k_transform['thetao_con'].isel(time_counter=0, i=260, j=260).astype(np.float64) * ds_k_transform['e3t_new'].isel(time_counter=0, i=260, j=260).astype(np.float64)).sum().compute())  # Calculate the sum of the product of the original conservative temperature and cell thickness at our example location: print((nemo['gridT']['thetao_con'].isel(time_counter=0, i=260, j=260).astype(np.float64) * nemo['gridT']['e3t'].isel(time_counter=0, i=260, j=260).astype(np.float64)).sum().compute()) <pre>&lt;xarray.DataArray ()&gt; Size: 8B\narray(14272.51116587)\nCoordinates:\n    time_counter   datetime64[ns] 8B 2000-07-02\n    time_centered  datetime64[ns] 8B 2000-07-02\n    gphit          float64 8B 51.34\n    glamt          float64 8B -26.44\n    j              int64 8B 261\n    i              int64 8B 261\n&lt;xarray.DataArray ()&gt; Size: 8B\narray(14272.51116587)\nCoordinates:\n    time_counter   datetime64[ns] 8B 2000-07-02\n    time_centered  datetime64[ns] 8B 2000-07-02\n    gphit          float64 8B 51.34\n    glamt          float64 8B -26.44\n    j              int64 8B 261\n    i              int64 8B 261\n</pre>"},{"location":"recipe_transform_vertical_coords/#description","title":"Description\u00b6","text":"<p>Recipe showing how to conservatively transform the vertical coordinate system on which a variable is stored using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using ERA-5 climatologically adjusted atmospheric forcing from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_transform_vertical_coords/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note: Although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_transform_vertical_coords/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 NEMO model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_transform_vertical_coords/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and T- &amp; V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_transform_vertical_coords/#exploring-our-eorca1-nemo-model-vertical-coordinate-system","title":"Exploring our eORCA1 NEMO model vertical coordinate system\u00b6","text":"<p>Let's begin by visualising the conservative temperature in the original vertical coordinates of our eORCA1 NPD simulation by plotting a vertical profile at a location in the North Atlantic Ocean:</p>"},{"location":"recipe_transform_vertical_coords/#transforming-the-eorca1-vertical-coordinate-system","title":"Transforming the eORCA1 vertical coordinate system\u00b6","text":"<p>Next, let's apply a conservative vertical coordinate transformation to remap our conservative temperature output to a new regularly-spaced (200 m) vertical grid:</p>"},{"location":"recipe_transform_vertical_coords/#visualising-the-vertically-transformed-conservative-temperature-field","title":"Visualising the vertically transformed conservative temperature field\u00b6","text":"<p>Let's plot the original and vertically transformed conservative temperature profiles together.</p>"},{"location":"recipe_volume_census/","title":"Volume Census in T-S Space","text":"In\u00a0[1]: Copied! <pre># -- Import required packages -- #\nimport numpy as np\nimport xarray as xr\nimport matplotlib.colors as colors\nfrom nemo_cookbook import NEMODataTree\n\nxr.set_options(display_style=\"text\")\n</pre> # -- Import required packages -- # import numpy as np import xarray as xr import matplotlib.colors as colors from nemo_cookbook import NEMODataTree  xr.set_options(display_style=\"text\") Out[1]: <pre>&lt;xarray.core.options.set_options at 0x1543cc440&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># -- Initialise Dask Local Cluster -- #\nimport os\nimport dask\nfrom dask.distributed import Client, LocalCluster\n\n# Update temporary directory for Dask workers:\ndask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",\n                 'local_directory': f\"{os.getcwd()}/dask_tmp\"\n                 })\n\n# Create Local Cluster:\ncluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB')\nclient = Client(cluster)\nclient\n</pre> # -- Initialise Dask Local Cluster -- # import os import dask from dask.distributed import Client, LocalCluster  # Update temporary directory for Dask workers: dask.config.set({'temporary_directory': f\"{os.getcwd()}/dask_tmp\",                  'local_directory': f\"{os.getcwd()}/dask_tmp\"                  })  # Create Local Cluster: cluster = LocalCluster(n_workers=4, threads_per_worker=3, memory_limit='5GB') client = Client(cluster) client In\u00a0[2]: Copied! <pre># Define directory path to ancillary files:\ndomain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"\n\n# Open eORCA1 NEMO model domain_cfg:\nds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})\n             .squeeze()\n             .rename({'z': 'nav_lev'})\n             )\nds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})\n\nds_domain\n</pre> # Define directory path to ancillary files: domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"  # Open eORCA1 NEMO model domain_cfg: ds_domain = (xr.open_zarr(f\"{domain_filepath}/domain_cfg\", consolidated=True, chunks={})              .squeeze()              .rename({'z': 'nav_lev'})              ) ds_subbasins = xr.open_zarr(f\"{domain_filepath}/subbasins\", consolidated=True, chunks={})  ds_domain Out[2]: <pre>&lt;xarray.Dataset&gt; Size: 667MB\nDimensions:        (y: 331, x: 360, nav_lev: 75)\nDimensions without coordinates: y, x, nav_lev\nData variables: (12/54)\n    e1t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2v            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bottom_level   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2t            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    e2u            (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    bathy_metry    (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    ...             ...\n    nav_lev        (nav_lev) float32 300B dask.array&lt;chunksize=(75,), meta=np.ndarray&gt;\n    mask_csundef   (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lat        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_counter   float64 8B dask.array&lt;chunksize=(), meta=np.ndarray&gt;\n    top_level      (y, x) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\nAttributes:\n    DOMAIN_number_total:     1\n    DOMAIN_number:           0\n    DOMAIN_dimensions_ids:   [1, 2]\n    DOMAIN_size_global:      [362, 332]\n    DOMAIN_size_local:       [362, 332]\n    DOMAIN_position_first:   [1, 1]\n    DOMAIN_position_last:    [362, 332]\n    DOMAIN_halo_size_start:  [0, 0]\n    DOMAIN_halo_size_end:    [0, 0]\n    DOMAIN_type:             BOX\n    history:                 Mon Jun  5 12:41:32 2023: ncks -A mask.nc ORCA1_...\n    NCO:                     4.4.7</pre> <p>Next, we need to import the sea water conservative temperature and absolute salinity stored at T-points in a single dataset.</p> In\u00a0[3]: Copied! <pre># Define directory path to model output files:\noutput_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"\n\n# Construct NEMO model grid dataset, including seawater conservative temperature (C) and absolute salinity (g/kg):\nds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['thetao_con', 'so_abs', 'e3t']], compat=\"override\")\n\nds_gridT\n</pre> # Define directory path to model output files: output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/T1y\"  # Construct NEMO model grid dataset, including seawater conservative temperature (C) and absolute salinity (g/kg): ds_gridT = xr.merge([xr.open_zarr(f\"{output_dir}/{var}\", consolidated=True, chunks={})[var] for var in ['thetao_con', 'so_abs', 'e3t']], compat=\"override\")  ds_gridT Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 5GB\nDimensions:        (deptht: 75, y: 331, x: 360, time_counter: 48)\nCoordinates:\n  * deptht         (deptht) float32 300B 0.5058 1.556 ... 5.698e+03 5.902e+03\n  * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\n    nav_lat        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    nav_lon        (y, x) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n    time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: y, x\nData variables:\n    thetao_con     (time_counter, deptht, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    so_abs         (time_counter, deptht, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n    e3t            (time_counter, deptht, y, x) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\nAttributes:\n    cell_methods:        time: mean\n    interval_operation:  1 yr\n    interval_write:      1 yr\n    long_name:           sea_water_conservative_temperature\n    online_operation:    average\n    standard_name:       sea_water_conservative_temperature\n    units:               degC</pre> In\u00a0[4]: Copied! <pre># Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests:\n# Note: domain_cfg z-dimension is expected to be named 'nav_lev'.\ndatasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}\n\n# Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points:\nnemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")\n\nnemo\n</pre> # Define dictionary of grid datasets defining eORCA1 parent model domain with no child/grand-child nests: # Note: domain_cfg z-dimension is expected to be named 'nav_lev'. datasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}  # Initialise a new NEMODataTree whose parent domain is zonally periodic &amp; north-folding on F-points: nemo = NEMODataTree.from_datasets(datasets=datasets, iperio=True, nftype=\"F\")  nemo Out[4]: <pre>&lt;xarray.DataTree&gt;\nGroup: /\n\u2502   Dimensions:        (time_counter: 48)\n\u2502   Coordinates:\n\u2502     * time_counter   (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-07-...\n\u2502       time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502   Attributes:\n\u2502       nftype:   F\n\u2502       iperio:   True\n\u251c\u2500\u2500 Group: /gridT\n\u2502       Dimensions:        (time_counter: 48, k: 75, j: 331, i: 360)\n\u2502       Coordinates:\n\u2502         * k              (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502         * j              (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i              (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * deptht         (k) float32 300B 0.5058 1.556 2.668 ... 5.698e+03 5.902e+03\n\u2502           time_centered  (time_counter) datetime64[ns] 384B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n\u2502           gphit          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt          (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           thetao_con     (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           so_abs         (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           e3t            (time_counter, k, j, i) float32 2GB dask.array&lt;chunksize=(1, 25, 331, 360), meta=np.ndarray&gt;\n\u2502           e1t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t            (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           top_level      (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           bottom_level   (j, i) int32 477kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           tmask          (k, j, i) bool 9MB False False False ... False False False\n\u2502           tmaskutil      (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridU\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamu         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2u           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           umask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           umaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridV\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n\u2502           gphiv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamv         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2v           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           vmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           vmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u251c\u2500\u2500 Group: /gridW\n\u2502       Dimensions:       (j: 331, i: 360, k: 75)\n\u2502       Coordinates:\n\u2502         * j             (j) int64 3kB 1 2 3 4 5 6 7 8 ... 325 326 327 328 329 330 331\n\u2502         * i             (i) int64 3kB 1 2 3 4 5 6 7 8 ... 354 355 356 357 358 359 360\n\u2502         * k             (k) float64 600B 0.5 1.5 2.5 3.5 4.5 ... 71.5 72.5 73.5 74.5\n\u2502           gphit         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           glamt         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502       Data variables:\n\u2502           e1t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           e2t           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n\u2502           wmask         (k, j, i) bool 9MB False False False ... False False False\n\u2502           wmaskutil     (j, i) bool 119kB False False False ... False False False\n\u2502       Attributes:\n\u2502           nftype:   F\n\u2502           iperio:   True\n\u2514\u2500\u2500 Group: /gridF\n        Dimensions:       (j: 331, i: 360, k: 75)\n        Coordinates:\n          * j             (j) float64 3kB 1.5 2.5 3.5 4.5 ... 328.5 329.5 330.5 331.5\n          * i             (i) float64 3kB 1.5 2.5 3.5 4.5 ... 357.5 358.5 359.5 360.5\n          * k             (k) int64 600B 1 2 3 4 5 6 7 8 9 ... 68 69 70 71 72 73 74 75\n            gphif         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            glamf         (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n        Data variables:\n            e1f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            e2f           (j, i) float64 953kB dask.array&lt;chunksize=(331, 360), meta=np.ndarray&gt;\n            fmask         (k, j, i) bool 9MB False False False ... False False False\n            fmaskutil     (j, i) bool 119kB False False False ... False False False\n        Attributes:\n            nftype:   F\n            iperio:   True</pre> In\u00a0[5]: Copied! <pre># Define Atlantic Ocean basin mask:\natlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"}).astype(bool)\n</pre> # Define Atlantic Ocean basin mask: atlmask = ds_subbasins['atlmsk'].rename({\"x\":\"i\", \"y\":\"j\"}).astype(bool) In\u00a0[6]: Copied! <pre># Define discrete conservative temperature [C] and absolute salinity [g/kg] bins:\nthetao_bins = np.arange(-2, 35, 0.5)\nso_bins = np.arange(20, 38, 0.1)\n\n# Compute volume of each T-grid cell [m3].\nnemo['gridT']['volcello'] = nemo.cell_volume(grid='gridT')\n\n# Compute total volume in discrete conservative temperature - absolute salinity coords:\nvol_thetao_so_atl = nemo.binned_statistic(grid=\"gridT\",\n                                          vars=[\"thetao_con\", \"so_abs\"],\n                                          values=\"volcello\",\n                                          keep_dims=[\"time_counter\"],\n                                          bins=[thetao_bins, so_bins],\n                                          statistic=\"nansum\",\n                                          mask=atlmask\n                                          )\n\nvol_thetao_so_atl\n</pre> # Define discrete conservative temperature [C] and absolute salinity [g/kg] bins: thetao_bins = np.arange(-2, 35, 0.5) so_bins = np.arange(20, 38, 0.1)  # Compute volume of each T-grid cell [m3]. nemo['gridT']['volcello'] = nemo.cell_volume(grid='gridT')  # Compute total volume in discrete conservative temperature - absolute salinity coords: vol_thetao_so_atl = nemo.binned_statistic(grid=\"gridT\",                                           vars=[\"thetao_con\", \"so_abs\"],                                           values=\"volcello\",                                           keep_dims=[\"time_counter\"],                                           bins=[thetao_bins, so_bins],                                           statistic=\"nansum\",                                           mask=atlmask                                           )  vol_thetao_so_atl Out[6]: <pre>&lt;xarray.DataArray 'volcello' (time_counter: 48, thetao_con_bins: 73,\n                              so_abs_bins: 179)&gt; Size: 5MB\ndask.array&lt;reshape, shape=(48, 73, 179), dtype=float64, chunksize=(48, 73, 179), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time_counter     (time_counter) datetime64[ns] 384B 1976-07-02 ... 2023-0...\n  * thetao_con_bins  (thetao_con_bins) float64 584B -1.75 -1.25 ... 33.75 34.25\n  * so_abs_bins      (so_abs_bins) float64 1kB 20.05 20.15 20.25 ... 37.75 37.85\nAttributes:\n    cell_methods:        time: mean (interval: 3600 s)\n    interval_operation:  3600 s\n    interval_write:      1 yr\n    long_name:           T-cell thickness\n    online_operation:    average\n    standard_name:       cell_thickness\n    units:               m</pre> <p>Notice that the output above contains dask arrays, so we haven't actually computed the volume census yet. To do this, we need to call the <code>.compute()</code> method:</p> In\u00a0[7]: Copied! <pre>vol_thetao_so_atl = vol_thetao_so_atl.compute()\n</pre> vol_thetao_so_atl = vol_thetao_so_atl.compute() <pre>OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n</pre> In\u00a0[8]: Copied! <pre>plt_data = vol_thetao_so_atl.mean(dim='time_counter')\n\nplt_data.plot(norm=colors.LogNorm(vmin=plt_data.min(),\n                                  vmax=plt_data.max()),\n                                  cmap=\"turbo\",\n                                  cbar_kwargs={\"label\": \"Volume ($\\\\log_{10}$[m$^3$])\"}\n                                  )\n</pre> plt_data = vol_thetao_so_atl.mean(dim='time_counter')  plt_data.plot(norm=colors.LogNorm(vmin=plt_data.min(),                                   vmax=plt_data.max()),                                   cmap=\"turbo\",                                   cbar_kwargs={\"label\": \"Volume ($\\\\log_{10}$[m$^3$])\"}                                   ) Out[8]: <pre>&lt;matplotlib.collections.QuadMesh at 0x16a139e80&gt;</pre>"},{"location":"recipe_volume_census/#description","title":"Description\u00b6","text":"<p>This recipe shows how to calculate the volume census in discrete temperature-salinity coordinates using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.</p> <p>For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation here.</p>"},{"location":"recipe_volume_census/#using-dask","title":"Using Dask\u00b6","text":"<p>Optional: Connect Client to Dask Local Cluster to run analysis in parallel.</p> <p>Note: Although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process.</p>"},{"location":"recipe_volume_census/#accessing-nemo-model-data","title":"Accessing NEMO Model Data\u00b6","text":"<p>Let's begin by loading the grid variables for our eORCA1 NEMO model from the JASMIN Object Store.</p> <p>Alternatively, you can replace the <code>domain_filepath</code> below with a file path to your domain_cfg.nc file and read this with xarray's <code>open_dataset()</code> function.</p>"},{"location":"recipe_volume_census/#creating-a-nemodatatree","title":"Creating a NEMODataTree\u00b6","text":"<p>Next, let's create a NEMODataTree to store our domain and T- &amp; V-grid variables for the eORCA1 model.</p>"},{"location":"recipe_volume_census/#calculating-volume-census","title":"Calculating Volume Census\u00b6","text":"<p>Now we have constructed our <code>NEMODataTree</code>, let's calculate the volume census in in T-S coordinates using the <code>.binned_statistic()</code> method:</p>"},{"location":"recipe_volume_census/#visualising-the-time-mean-volume-census-in-t-s-coordinates","title":"Visualising the time-mean volume census in T-S coordinates\u00b6","text":"<p>Finally, let's visualise the results by plotting the time-mean volume census in conservative temperature - absolute salinity space using a logarithmic scale:</p>"},{"location":"recipes/","title":"Summary","text":""},{"location":"recipes/#summary","title":"Summary","text":""},{"location":"recipes/#available-recipes","title":"Available Recipes","text":"<ul> <li> <p>Meridional Overturning - Tracer</p> <p>Meridional overturning stream function in an arbitrary tracer coordinates.</p> <p> Recipe</p> </li> <li> <p>Meridional Overturning - Vertical</p> <p>Meridional overturning stream function in vertical coordinates (z/z*).</p> <p> Recipe</p> </li> <li> <p>Ocean Transports</p> <p>Seawater volume, heat and freshwater transports.</p> <p> Recipe</p> </li> <li> <p>Volume Census</p> <p>Seawater volume census in discrete temperature - salinity coordinates.</p> <p> Recipe</p> </li> <li> <p>Water Mass Transformation</p> <p>Surface-forced water mass transformation in discrete potential density coordinates.</p> <p> Recipe</p> </li> <li> <p>Masked Statistics</p> <p>Grid-aware masked statistics using bounding boxes and geographical polyons.</p> <p> Recipe</p> </li> <li> <p>Barotropic Stream Function</p> <p>Regional barotropic stream functions using grid-aware integration.</p> <p> Recipe</p> </li> <li> <p>Vertical Coordinate Transformations</p> <p>Transforming vertical coordinates using conservative remapping.</p> <p> Recipe</p> </li> <li> <p>Extracting Hydrographic Sections</p> <p>Extracting volume transports and properties along the Overturning in the Subpolar North Atlantic array.</p> <p> Recipe</p> </li> </ul>"},{"location":"recipes/#recipes-in-development","title":"Recipes In Development","text":"<ol> <li> <p>Meridional overturning stream functions in multi-envelope sigma coordinates.</p> </li> <li> <p>Ocean heat content &amp; mixed layer heat content. </p> </li> <li> <p>Sea ice diagnostics.</p> </li> <li> <p>Vorticity diagnostics.</p> </li> </ol>"},{"location":"recipes/#contributing-new-recipes","title":"Contributing New Recipes...","text":"<p>If you've used <code>NEMODataTree</code> to calculate a commonly used diagnostic not currently included in the Recipe Lists above, we'd strongly encourage you to visit the Contributing page to learn more about contributing to the NEMO Cookbook.</p>"},{"location":"reference/","title":"API","text":""},{"location":"reference/#nemodatatree-api","title":"NEMODataTree API","text":""},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree","title":"nemo_cookbook.nemodatatree.NEMODataTree","text":"<p>               Bases: <code>DataTree</code></p> <p>A hierarchical data structure containing collections of NEMO ocean model outputs.</p> <p>This class extends <code>xarray.DataTree</code> to provide methods for processing and analysing NEMO output xarray objects defining one or more model domains.</p> <p>It supports NEMO discrete scalar and vector operators such as computing gradients, divergence, curl, weighted averages, integrals, cumulative integrals, and transforming variables between grids.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Access child nodes, variables, or coordinates stored in this NEMODataTree.</p> <code>__init__</code> <p>Create a single node of a NEMODataTree.</p> <code>add_geoindex</code> <p>Add geographical index variables to a given NEMO model grid.</p> <code>binned_statistic</code> <p>Calculate binned statistic of a variable defined on a NEMO model grid.</p> <code>cell_area</code> <p>Calculate grid cell areas orthogonal to a given dimension of a NEMO model grid.</p> <code>cell_volume</code> <p>Calculate grid cell volumes for a given NEMO model grid.</p> <code>clip_domain</code> <p>Clip a NEMO model domain to specified longitude and latitude range.</p> <code>clip_grid</code> <p>Clip a NEMO model grid to specified longitude and latitude range.</p> <code>curl</code> <p>Calculate the vertical (k) curl component of a vector field on a NEMO model grid.</p> <code>depth_integral</code> <p>Integrate a variable in depth coordinates between two limits.</p> <code>divergence</code> <p>Calculate the horizontal divergence of a vector field defined on a NEMO model grid.</p> <code>extract_mask_boundary</code> <p>Extract the boundary of a masked region defined on a NEMO model grid.</p> <code>extract_section</code> <p>Extract hydrographic section from a NEMO model domain.</p> <code>from_datasets</code> <p>Create a NEMODataTree from a dictionary of <code>xarray.Dataset</code> objects created from NEMO model output files,</p> <code>from_paths</code> <p>Create a NEMODataTree from a dictionary of paths to NEMO model output files,</p> <code>gradient</code> <p>Calculate the gradient of a scalar variable along one dimension (e.g., 'i', 'j', 'k') of a NEMO model grid.</p> <code>integral</code> <p>Integrate a variable along one or more dimensions of a NEMO model grid.</p> <code>mask_with_polygon</code> <p>Create mask of NEMO model grid points contained within a polygon.</p> <code>masked_statistic</code> <p>Masked statistic of a variable defined on a NEMO model grid.</p> <code>transform_to</code> <p>Transform variable defined on a NEMO model grid to a neighbouring</p> <code>transform_vertical_grid</code> <p>Transform variable defined on a NEMO model grid to a new vertical grid using conservative interpolation.</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>class NEMODataTree(xr.DataTree):\n    \"\"\"\n    A hierarchical data structure containing collections of NEMO ocean model outputs.\n\n    This class extends `xarray.DataTree` to provide methods for processing\n    and analysing NEMO output xarray objects defining one or more model domains.\n\n    It supports NEMO discrete scalar and vector operators such as computing gradients,\n    divergence, curl, weighted averages, integrals, cumulative integrals, and\n    transforming variables between grids.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Create a single node of a NEMODataTree.\n\n        The node may optionally contain data in the form of data\n        and coordinate variables, stored in the same way as data\n        is stored in an `xarray.Dataset`.\n\n        Parameters\n        ----------\n        *args : tuple\n            Positional arguments to pass to the parent class.\n        **kwargs : dict\n            Keyword arguments to pass to the parent class.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n\n    @classmethod\n    def from_paths(\n        cls,\n        paths: dict[str, str],\n        nests: dict[str, str] | None = None,\n        iperio: bool = False,\n        nftype: str | None = None,\n        read_mask: bool = False,\n        nbghost_child: int = 4,\n        **open_kwargs: dict[str, any],\n    ) -&gt; Self:\n        \"\"\"\n        Create a NEMODataTree from a dictionary of paths to NEMO model output files,\n        organised into a hierarchy of domains (i.e., 'parent', 'child', 'grandchild').\n\n        Parameters\n        ----------\n        paths : dict[str, str]\n            Dictionary containing paths to NEMO grid files, structured as:\n            {\n                'parent': {'domain': 'path/to/domain.nc',\n                           'gridT': 'path/to/gridT.nc',\n                            , ... ,\n                            'icemod': 'path/to/icemod.nc',\n                            },\n                'child': {'1': {'domain': 'path/to/child_domain.nc',\n                                'gridT': 'path/to/child_gridT.nc',\n                                , ... ,\n                                'icemod': 'path/to/child_icemod.nc',\n                                },\n                          },\n                'grandchild': {'2': {'domain': 'path/to/grandchild_domain.nc',\n                                     'gridT': 'path/to/grandchild_gridT.nc',\n                                     , ...,\n                                     'icemod': 'path/to/grandchild_icemod.nc',\n                                     },\n                               }\n            }\n\n        nests : dict[str, str], optional\n            Dictionary describing the properties of nested domains, structured as:\n            {\n                \"1\": {\n                    \"parent\": \"/\",\n                    \"rx\": rx,\n                    \"ry\": ry,\n                    \"imin\": imin,\n                    \"imax\": imax,\n                    \"jmin\": jmin,\n                    \"jmax\": jmax,\n                    \"iperio\": iperio,\n                    },\n            }\n            where `rx` and `ry` are the horizontal refinement factors, and `imin`, `imax`, `jmin`, `jmax`\n            define the indices of the child (grandchild) domain within the parent (child) domain. Zonally\n            periodic nested domains should be specified with `iperio=True`.\n\n        iperio: bool = False\n            Zonal periodicity of the parent domain. Default is False.\n\n        nftype: str, optional\n            Type of north fold lateral boundary condition to apply. Options are 'T' for T-point pivot or 'F' for F-point\n            pivot. By default, no north fold lateral boundary condition is applied (None).\n\n        read_mask: bool = False\n            If True, read NEMO model land/sea mask from domain files. Default is False, meaning masks are computed from top_level and bottom_level domain variables.\n\n        nbghost_child : int = 4\n            Number of ghost cells to remove from the western/southern boundaries of the (grand)child domains. Default is 4.\n\n        **open_kwargs : dict, optional\n            Additional keyword arguments to pass to `xarray.open_dataset` or `xr.open_mfdataset` when opening NEMO model output files.\n        Returns\n        -------\n        NEMODataTree\n            A hierarchical DataTree storing NEMO model outputs.\n\n        Examples\n        --------\n        Create a `NEMODataTree` from a dictionary of paths to local netCDF files:\n\n        &gt;&gt;&gt; from nemo_cookbook import NEMODataTree\n\n        &gt;&gt;&gt; paths = {\"parent\": {\n        ...          \"domain\": \"/path/to/domain_cfg.nc\",\n        ...          \"gridT\": \"path/to/*_gridT.nc\",\n        ...          \"gridU\": \"path/to/*_gridV.nc\",\n        ...          \"gridV\": \"path/to/*_gridV.nc\",\n        ...          \"gridW\": \"path/to/*_gridW.nc\",\n        ...          \"icemod\": \"path/to/*_icemod.nc\",\n        ...          }}\n\n        &gt;&gt;&gt; NEMODataTree.from_paths(paths, iperio=True, nftype=\"T\")\n\n        See Also\n        --------\n        from_datasets\n        \"\"\"\n        if not isinstance(paths, dict):\n            raise TypeError(\"paths must be a dictionary or nested dictionary.\")\n        if not isinstance(nests, (dict, type(None))):\n            raise TypeError(\"nests must be a dictionary or None.\")\n        if not isinstance(iperio, bool):\n            raise TypeError(\"zonal periodicity of parent domain must be a boolean.\")\n        if nftype is not None and nftype not in (\"T\", \"F\"):\n            raise ValueError(\n                \"north fold type of parent domain must be 'T' (T-pivot fold), 'F' (F-pivot fold), or None.\"\n            )\n        if not isinstance(read_mask, bool):\n            raise TypeError(\"read_mask must be a boolean.\")\n        if not isinstance(nbghost_child, int):\n            raise TypeError(\n                \"number of ghost cells along the western/southern boundaries must be an integer.\"\n            )\n        if not isinstance(open_kwargs, dict):\n            raise TypeError(\"open_kwargs must be a dictionary.\")\n\n        # Define parent, child, grandchild filepath collections:\n        d_child, d_grandchild = None, None\n        if \"parent\" in paths.keys() and isinstance(paths[\"parent\"], dict):\n            for key in paths.keys():\n                if key not in (\"parent\", \"child\", \"grandchild\"):\n                    raise KeyError(f\"Unexpected key '{key}' in paths dictionary.\")\n                if key == \"parent\":\n                    d_parent = paths[\"parent\"]\n                elif key == \"child\":\n                    d_child = paths[\"child\"]\n                elif key == \"grandchild\":\n                    d_grandchild = paths[\"grandchild\"]\n        else:\n            raise ValueError(\n                \"Invalid paths structure. Expected a nested dictionary defining NEMO 'parent', 'child' and 'grandchild' domains.\"\n            )\n\n        # Construct DataTree from parent / child / grandchild domains:\n        d_tree = create_datatree_dict(\n            d_parent=d_parent,\n            d_child=d_child,\n            d_grandchild=d_grandchild,\n            nests=nests,\n            iperio=iperio,\n            nftype=nftype,\n            read_mask=read_mask,\n            nbghost_child=nbghost_child,\n            open_kwargs=dict(**open_kwargs),\n        )\n\n        datatree = super().from_dict(d_tree)\n\n        return datatree\n\n    @classmethod\n    def from_datasets(\n        cls,\n        datasets: dict[str, dict[str, xr.Dataset]],\n        nests: dict[str, dict[str, str]] | None = None,\n        iperio: bool = False,\n        nftype: str | None = None,\n        read_mask: bool = False,\n        nbghost_child: int = 4,\n    ) -&gt; Self:\n        \"\"\"\n        Create a NEMODataTree from a dictionary of `xarray.Dataset` objects created from NEMO model output files,\n        organised into a hierarchy of domains (i.e., 'parent', 'child', 'grandchild').\n\n        Parameters\n        ----------\n        datasets : dict[str, dict[str, xr.Dataset]]\n            Dictionary containing `xarray.Datasets` created from NEMO grid files, structured as:\n            {\n                'parent': {'domain': ds_domain, 'gridT': ds_gridT, ... , 'icemod': ds_icemod.nc},\n                'child': {'1': {'domain': ds_domain_1, 'gridT': d_gridT_1, ...}},\n                'grandchild': {'2': {'domain': ds_domain_2, 'gridT': ds_gridT_2, ...}}\n            }\n\n        nests : dict[str, dict[str, str]], optional\n            Dictionary describing the properties of nested domains, structured as:\n            {\n                \"1\": {\n                    \"parent\": \"/\",\n                    \"rx\": rx,\n                    \"ry\": ry,\n                    \"imin\": imin,\n                    \"imax\": imax,\n                    \"jmin\": jmin,\n                    \"jmax\": jmax,\n                    },\n            }\n            where `rx` and `ry` are the horizontal refinement factors, and `imin`, `imax`, `jmin`, `jmax`\n            define the indices of the child (grandchild) domain within the parent (child) domain.\n\n        iperio: bool = False\n            Zonal periodicity of the parent domain.\n\n        nftype: str, optional\n            Type of north fold lateral boundary condition to apply. Options are 'T' for T-point pivot or 'F' for F-point\n            pivot. By default, no north fold lateral boundary condition is applied (None).\n\n        read_mask: bool = False\n            If True, read NEMO model land/sea mask from domain files. Default is False, meaning masks are computed from top_level and bottom_level domain variables.\n\n        nbghost_child : int = 4\n            Number of ghost cells to remove from the western/southern boundaries of the (grand)child domains. Default is 4.\n\n        Returns\n        -------\n        NEMODataTree\n            A hierarchical data tree of NEMO model outputs.\n\n        Examples\n        --------\n        Create a `NEMODataTree` from a dictionary of xarray.Dataset objects:\n\n        &gt;&gt;&gt; import xarray as xr\n        &gt;&gt;&gt; from nemo_cookbook import NEMODataTree\n\n        &gt;&gt;&gt; ds_domain = xr.open_zarr(\"https://some_remote_data/domain_cfg.zarr\")\n        &gt;&gt;&gt; ds_gridT = xr.open_zarr(\"https://some_remote_data/my_model_gridT.zarr\")\n\n        &gt;&gt;&gt; datasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}\n\n        &gt;&gt;&gt; nemo = NEMODataTree.from_datasets(datasets=datasets)\n\n        See Also\n        --------\n        from_paths\n        \"\"\"\n        if not isinstance(datasets, dict):\n            raise TypeError(\"datasets must be a dictionary or nested dictionary.\")\n        if not isinstance(nests, (dict, type(None))):\n            raise TypeError(\"nests must be a dictionary or None.\")\n        if not isinstance(iperio, bool):\n            raise TypeError(\"zonal periodicity of parent domain must be a boolean.\")\n        if nftype is not None and nftype not in (\"T\", \"F\"):\n            raise ValueError(\n                \"north fold type of parent domain must be 'T' (T-pivot fold), 'F' (F-pivot fold), or None.\"\n            )\n        if not isinstance(read_mask, bool):\n            raise TypeError(\"read_mask must be a boolean.\")\n        if not isinstance(nbghost_child, int):\n            raise TypeError(\n                \"number of ghost cells along the western/southern boundaries must be an integer.\"\n            )\n\n        # Define parent, child, grandchild dataset collections:\n        d_child, d_grandchild = None, None\n        if \"parent\" in datasets.keys() and isinstance(datasets[\"parent\"], dict):\n            for key in datasets.keys():\n                if key not in (\"parent\", \"child\", \"grandchild\"):\n                    raise KeyError(f\"Unexpected key '{key}' in datasets dictionary.\")\n                if key == \"parent\":\n                    d_parent = datasets[\"parent\"]\n                elif key == \"child\":\n                    d_child = datasets[\"child\"]\n                elif key == \"grandchild\":\n                    d_grandchild = datasets[\"grandchild\"]\n        else:\n            raise ValueError(\n                \"Invalid datasets structure. Expected a nested dictionary defining NEMO 'parent', 'child' and 'grandchild' domains.\"\n            )\n\n        # Construct DataTree from parent / child / grandchild domains:\n        d_tree = create_datatree_dict(\n            d_parent=d_parent,\n            d_child=d_child,\n            d_grandchild=d_grandchild,\n            nests=nests,\n            iperio=iperio,\n            nftype=nftype,\n            read_mask=read_mask,\n            nbghost_child=nbghost_child,\n        )\n        datatree = super().from_dict(d_tree)\n\n        return datatree\n\n    def __getitem__(self, key: str) -&gt; Self | xr.DataArray:\n        \"\"\"\n        Access child nodes, variables, or coordinates stored in this NEMODataTree.\n\n        Returned object will be either a DataTree or DataArray object depending on\n        whether the key given points to a child or variable.\n\n        Overloads the __getitem__() method of xarray.DataTree to apply grid masks\n        to returned DataArrays accessed via variable paths (i.e, /grid/var).\n\n        Parameters\n        ----------\n        key : str\n            Name of variable / child within this node, or unix-like path to variable\n            / child within another node.\n\n        Returns\n        -------\n        NEMODataTree | xr.DataArray\n        \"\"\"\n        # -- Access child node or variable -- #\n        item = super().__getitem__(key=key)\n        is_gridpath = key.startswith(\"/grid\") or key.startswith(\"grid\")\n\n        if isinstance(item, xr.DataArray) &amp; is_gridpath:\n            # -- Get NEMO model grid properties -- #\n            var_name = key.split(\"/\")[-1]\n            grid = key.replace(f\"/{var_name}\", \"\")\n            _, dom_prefix, _, grid_suffix = self._get_properties(\n                grid=grid, infer_dom=True\n            )\n\n            # -- Apply NEMO model grid mask -- #\n            # Masking only non-mask variables:\n            if (var_name != f\"{grid_suffix}mask\") and (\n                var_name != f\"{grid_suffix}maskutil\"\n            ):\n                if f\"{dom_prefix}depth{grid_suffix}\" in item.coords:\n                    # Get 3-dimensional t/u/v/f mask:\n                    mask = self[grid][f\"{grid_suffix}mask\"]\n                else:\n                    # Get 2-dimensional t/u/v/f/w mask (unique points):\n                    mask = self[grid][f\"{grid_suffix}maskutil\"]\n\n                item = item.where(mask, drop=False)\n\n        return item\n\n    def _get_properties(\n        self, dom: str | None = None, grid: str | None = None, infer_dom: bool = False\n    ) -&gt; str:\n        \"\"\"\n        Get NEMO model domain and grid properties.\n\n        The domain prefix &amp; suffix (e.g., '1_', '1') are returned\n        if only the NEMO model domain (`dom`) is specified.\n\n        The grid suffix (e.g., 't', 'u', 'v', 'w') is returned if\n        only the NEMO model grid (`grid`) is specified.\n\n        The domain number, domain prefix &amp; suffix, and grid suffix\n        are returned if both the NEMO model grid (`grid`) and\n        `infer_dom = True` are specified.\n\n        Parameters\n        ----------\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        grid : str, optional\n            Path to NEMO model grid (e.g., 'gridT').\n        infer_dom : bool, optional\n            Whether to infer the domain number &amp; domain name from only the\n            grid path. Default is False.\n\n        Returns\n        -------\n        tuple[str]\n            NEMO model domain and grid properties.\n        \"\"\"\n        if (grid is None) &amp; (dom is not None):\n            dom_prefix = \"\" if dom == \".\" else f\"{dom}_\"\n            dom_suffix = \"\" if dom == \".\" else f\"{dom}\"\n            return dom_prefix, dom_suffix\n        else:\n            grid_keys = list(dict(self.subtree_with_keys).keys())\n            if grid not in grid_keys:\n                raise KeyError(\n                    f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n                )\n            grid_suffix = f\"{grid.lower()[-1]}\"\n\n            if infer_dom:\n                dom_inds = [char for char in grid if char.isdigit()]\n                dom_prefix = f\"{dom_inds[-1]}_\" if len(dom_inds) != 0 else \"\"\n                dom = dom_prefix[:-1] if dom_prefix != \"\" else \".\"\n                dom_suffix = dom if dom != \".\" else \"\"\n                return dom, dom_prefix, dom_suffix, grid_suffix\n            else:\n                return grid_suffix\n\n    def _get_grid_paths(self, dom: str) -&gt; str:\n        \"\"\"\n        Get paths to NEMO model grids in a given domain.\n\n        Parameters\n        ----------\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n\n        Returns\n        -------\n        dict[str, str]\n            Dictionary of NEMO model grid paths.\n        \"\"\"\n        # Collect paths to all NEMO model grids:\n        grid_paths = list(dict(self.subtree_with_keys).keys())\n\n        if dom == \".\":\n            grid_paths = [\n                path for path in grid_paths if (\"_\" not in path) &amp; (\"grid\" in path)\n            ]\n        else:\n            grid_paths = [path for path in grid_paths if dom in path]\n\n        d_paths = {path.split(\"/\")[0]: path for path in grid_paths}\n\n        return d_paths\n\n    def _get_ijk_names(self, dom: str | None = None, grid: str | None = None) -&gt; str:\n        \"\"\"\n        Get (i, j, k) grid index names for given NEMO model domain.\n\n        If path to NEMO model grid is provided, domain is inferred.\n\n        Parameters\n        ----------\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        grid : str, optional\n            Path to NEMO model grid (e.g., 'gridT').\n\n        Returns\n        -------\n        dict[str, str]\n            NEMO model grid index names.\n        \"\"\"\n        if grid is not None:\n            dom, _, dom_suffix, _ = self._get_properties(grid=grid, infer_dom=True)\n        else:\n            _, dom_suffix = self._get_properties(dom=dom)\n\n        indexes = [\"i\", \"j\", \"k\"]\n        if dom == \".\":\n            d_ijk = {index: index for index in indexes}\n        else:\n            d_ijk = {index: f\"{index}{dom_suffix}\" for index in indexes}\n\n        return d_ijk\n\n    def _get_weights(self, grid: str, dims: list, fillna: bool = True) -&gt; xr.DataArray:\n        \"\"\"\n        Get the weights (scale factors) for specified dimensions of a NEMO model grid.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where weights are stored (e.g., 'gridT').\n        dims : list\n            Dimensions to collect weights for.\n        fillna : bool, optional\n            Fill NaN values in weights with zeros. Default is True.\n\n        Returns\n        -------\n        xr.DataArray\n            Weights (scale factors) for the specified dimensions of the NEMO model grid.\n        \"\"\"\n        if any(dim not in [\"i\", \"j\", \"k\"] for dim in dims):\n            raise ValueError(\n                \"dims must be a list containing one or more of the following dimensions: ['i', 'j', 'k'].\"\n            )\n\n        grid_suffix = self._get_properties(grid=grid)\n\n        weights_dict = {\n            \"i\": f\"e1{grid_suffix}\",\n            \"j\": f\"e2{grid_suffix}\",\n            \"k\": f\"e3{grid_suffix}\",\n        }\n        try:\n            weights_list = [self[f\"{grid}/{weights_dict[dim]}\"] for dim in dims]\n        except KeyError as e:\n            raise KeyError(\n                f\"weights missing for dimensions {dims} of NEMO model grid {grid}\"\n            ) from e\n\n        if len(weights_list) == 1:\n            weights = weights_list[0]\n        elif len(weights_list) == 2:\n            weights = weights_list[0] * weights_list[1]\n        elif len(weights_list) == 3:\n            weights = weights_list[0] * weights_list[1] * weights_list[2]\n\n        if fillna:\n            weights = weights.fillna(value=0)\n\n        return weights\n\n    def add_geoindex(\n        self,\n        grid: str,\n    ) -&gt; Self:\n        \"\"\"\n        Add geographical index variables to a given NEMO model grid.\n\n        This enables users to index grid variables using geographical\n        coordinates (e.g., glamt, gphit) in addition to their (i, j, k)\n        dimensions.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid to add geographical indexes (e.g., 'gridT').\n\n        Returns\n        -------\n        NEMODataTree\n            NEMO DataTree with geographical indexes added to specified model grid.\n\n        Examples\n        --------\n        Add glamt, gphit as geographical indexes to the T-grid of the NEMO parent domain:\n\n        &gt;&gt;&gt; nemo.add_geoindex(grid=\"gridT\")\n\n        \"\"\"\n        # -- Set geographical indexes -- #\n        _, dom_prefix, _, grid_suffix = self._get_properties(grid=grid, infer_dom=True)\n        lon_name = f\"{dom_prefix}glam{grid_suffix}\"\n        lat_name = f\"{dom_prefix}gphi{grid_suffix}\"\n        self_copy = self.copy()\n        self_copy[grid] = (\n            self_copy[grid]\n            .dataset.assign_coords(\n                {lat_name: self_copy[grid][lat_name], lon_name: self_copy[grid][lon_name]}\n            )\n            .set_xindex(\n                (lat_name, lon_name),\n                NDPointIndex,\n                tree_adapter_self=SklearnGeoBallTreeAdapter,\n            )\n        )\n\n        return self_copy\n\n    def cell_area(\n        self,\n        grid: str,\n        dim: str,\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Calculate grid cell areas orthogonal to a given dimension of a NEMO model grid.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid from which to calculate grid cell areas\n            (e.g., 'gridT').\n        dim : str\n            Dimension orthogonal to grid cell area to\n            calculate (e.g., 'k' returns e1 * e2).\n\n        Returns\n        -------\n        xr.DataArray\n            Grid cell areas (m^2) for the specified NEMO model grid.\n\n        Examples\n        --------\n        Compute the volume of each grid cell centered on a V-grid point\n        in the NEMO parent domain:\n\n        &gt;&gt;&gt; nemo.cell_area(grid=\"gridT\", dim=\"k\")\n\n        Note, `dim` represents the dimension orthogonal to the grid cell\n        area to be computed.\n\n        See Also\n        --------\n        cell_volume\n        \"\"\"\n        grid_suffix = self._get_properties(grid=grid)\n\n        if dim not in [\"i\", \"j\", \"k\"]:\n            raise ValueError(f\"dim {dim} must be one of ['i', 'j', 'k'].\")\n\n        match dim:\n            case \"i\":\n                cell_area = (\n                    self[f\"{grid}/e3{grid_suffix}\"] * self[f\"{grid}/e2{grid_suffix}\"]\n                )\n            case \"j\":\n                cell_area = (\n                    self[f\"{grid}/e3{grid_suffix}\"] * self[f\"{grid}/e1{grid_suffix}\"]\n                )\n            case \"k\":\n                cell_area = (\n                    self[f\"{grid}/e1{grid_suffix}\"] * self[f\"{grid}/e2{grid_suffix}\"]\n                )\n        cell_area.name = \"areacello\"\n\n        return cell_area\n\n    def cell_volume(self, grid: str) -&gt; xr.DataArray:\n        \"\"\"\n        Calculate grid cell volumes for a given NEMO model grid.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid to calculate grid cell volumes\n            (e.g., 'gridT').\n\n        Returns\n        -------\n        xr.DataArray\n            Grid cell volumes for the specified NEMO model grid.\n\n        Examples\n        --------\n        Compute the volume of each grid cell centered on a V-grid point\n        in the NEMO parent domain:\n\n        &gt;&gt;&gt; nemo.cell_volumes(grid=\"gridV\")\n\n        See Also\n        --------\n        cell_area\n        \"\"\"\n        grid_suffix = self._get_properties(grid=grid)\n\n        cell_volume = (\n            self[f\"{grid}/e3{grid_suffix}\"]\n            * self[f\"{grid}/e1{grid_suffix}\"]\n            * self[f\"{grid}/e2{grid_suffix}\"]\n        )\n        cell_volume.name = \"volcello\"\n\n        return cell_volume\n\n    def gradient(\n        self,\n        var: str,\n        dim: str,\n        dom: str = \".\",\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Calculate the gradient of a scalar variable along one dimension (e.g., 'i', 'j', 'k') of a NEMO model grid.\n\n        Parameters\n        ----------\n        var : str\n            Name of the scalar variable.\n        dim : str\n            Dimension along which to calculate gradient (e.g., 'i', 'j', 'k').\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n            Default is '.' for the parent domain.\n\n        Returns\n        -------\n        xr.DataArray\n            Gradient of scalar variable defined on a NEMO model grid.\n\n        Examples\n        --------\n        Compute the 'meridional' gradient of sea surface temperature `tos_con`\n        along the NEMO parent domain `j` dimension:\n\n        &gt;&gt;&gt; nemo.gradient(dom='.', var=\"tos_con\", dim=\"j\")\n\n        Compute the vertical gradient of absolute salinity in the first NEMO\n        nested child domain:\n\n        &gt;&gt;&gt; nemo.gradient(dom=\"1\", var=\"so_abs\", dim=\"k\")\n\n        See Also\n        --------\n        integral\n        \"\"\"\n        # -- Validate input -- #\n        if not isinstance(var, str):\n            raise ValueError(\n                \"var must be a string specifying name of the scalar variable.\"\n            )\n        if not isinstance(dim, str):\n            raise ValueError(\n                \"dim must be a string specifying dimension along which to calculate the gradient (e.g., 'i', 'j', 'k').\"\n            )\n        if not isinstance(dom, str):\n            raise ValueError(\n                \"dom must be a string specifying prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\"\n            )\n\n        # -- Get NEMO model grid properties -- #\n        dom_prefix, dom_suffix = self._get_properties(dom=dom)\n        grid_paths = self._get_grid_paths(dom=dom)\n        gridT, gridU, gridV, gridW = (\n            grid_paths[\"gridT\"],\n            grid_paths[\"gridU\"],\n            grid_paths[\"gridV\"],\n            grid_paths[\"gridW\"],\n        )\n\n        if var not in self[gridT].data_vars:\n            raise KeyError(f\"variable '{var}' not found in grid '{gridT}'.\")\n\n        da = self[f\"{gridT}/{var}\"]\n        dim_name = f\"{dim}{dom_suffix}\"\n        if dim_name not in da.dims:\n            raise KeyError(\n                f\"dimension '{dim_name}' not found in variable '{var}'. Dimensions available: {da.dims}.\"\n            )\n\n        match dim:\n            case \"i\":\n                if f\"{dom_prefix}deptht\" in da.coords:\n                    # 3-dimensional umask:\n                    umask = self[gridU][\"umask\"]\n                else:\n                    # 2-dimensional umask:\n                    umask = self[gridU][\"umaskutil\"]\n\n                # Zonally Periodic Domain:\n                if self[gridT].attrs.get(\"iperio\", False):\n                    da_end = da.isel(dim_name=0)\n                    da_end[dim_name] = da[dim_name].max() + 1\n                    da = xr.concat([da, da_end], dim=dim_name)\n                    dvar = da.diff(dim=dim_name, label=\"lower\")\n                else:\n                    # Non-Periodic: pad with NaN values after differencing:\n                    dvar = da.diff(dim=dim_name, label=\"lower\").pad({dim_name: (0, 1)})\n                # Apply u-mask &amp; transform coords -&gt; calculate gradient:\n                dvar.coords[dim_name] = dvar.coords[dim_name] + 0.5\n                gradient = dvar.where(umask) / self[f\"{gridU}/e1u\"]\n\n                # Remove redundant depth coordinates:\n                if f\"{dom_prefix}deptht\" in gradient.coords:\n                    gradient = gradient.drop_vars(\n                        [f\"{dom_prefix}deptht\"]\n                    ).assign_coords(\n                        {f\"{dom_prefix}depthu\": self[gridU][f\"{dom_prefix}depthu\"]}\n                    )\n            case \"j\":\n                # 3-dimensional vmask:\n                if f\"{dom_prefix}deptht\" in da.coords:\n                    vmask = self[gridV][\"vmask\"]\n                else:\n                    # 2-dimensional vmask (unique points):\n                    vmask = self[gridV][\"vmaskutil\"]\n\n                # Pad with zeros after differencing (zero gradient at jmaxdom):\n                dvar = da.diff(dim=dim_name, label=\"lower\").pad(\n                    {dim_name: (0, 1)}, constant_values=0\n                )\n                # Apply vmask &amp; transform coords -&gt; calculate gradient:\n                dvar.coords[dim_name] = dvar.coords[dim_name] + 0.5\n                gradient = dvar.where(vmask) / self[f\"{gridV}/e2v\"]\n\n                if f\"{dom_prefix}deptht\" in gradient.coords:\n                    gradient = gradient.drop_vars(\n                        [f\"{dom_prefix}deptht\"]\n                    ).assign_coords(\n                        {f\"{dom_prefix}depthv\": self[gridV][f\"{dom_prefix}depthv\"]}\n                    )\n\n            case \"k\":\n                dvar = da.diff(dim=dim_name, label=\"lower\")\n                # Transform coords &amp; apply w-mask -&gt; calculate gradient:\n                dvar.coords[dim_name] = dvar.coords[dim_name] + 0.5\n                dvar = dvar.where(self[gridW][\"wmask\"].isel({dim_name: slice(1, None)}))\n                try:\n                    gradient = -dvar / self[f\"{gridW}/e3w\"].isel(\n                        {dim_name: slice(1, None)}\n                    )\n                    gradient = gradient.drop_vars([f\"{dom_prefix}deptht\"])\n                except KeyError as e:\n                    raise KeyError(\n                        f\"NEMO model grid: '{gridW}' does not contain vertical scale factor 'e3w' required to calculate gradients along the k-dimension.\"\n                    ) from e\n\n        # Update DataArray properties:\n        gradient.name = f\"grad_{var}_{dim_name}\"\n        gradient = gradient.drop_vars([f\"{dom_prefix}glamt\", f\"{dom_prefix}gphit\"])\n\n        return gradient\n\n    def divergence(\n        self,\n        vars: list[str],\n        dom: str = \".\",\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Calculate the horizontal divergence of a vector field defined on a NEMO model grid.\n\n        Parameters\n        ----------\n        vars : list[str]\n            Name of vector variables, structured as: ['u', 'v'], where\n            'u' and 'v' are the i and j components of the vector field,\n            respectively.\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n            Default is '.' for the parent domain.\n\n        Returns\n        -------\n        xr.DataArray\n            Horizontal divergence of vector field defined on a NEMO model grid.\n\n        Examples\n        --------\n        Compute the horizontal divergence of the seawater velocity field in the\n        NEMO parent domain:\n\n        &gt;&gt;&gt; nemo.divergence(dom=\".\", vars=[\"uo\", \"vo\"])\n\n        Note, `vars` expects a list of the `i` and `j` components of the vector\n        field, respectively.\n\n        See Also\n        --------\n        divergence\n        \"\"\"\n        # -- Validate input -- #\n        if not isinstance(vars, list) or len(vars) != 2:\n            raise ValueError(\n                \"vars must be a list of two elements structured as ['u', 'v'].\"\n            )\n        if not isinstance(dom, str):\n            raise ValueError(\n                \"dom must be a string specifying the prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\"\n            )\n\n        # -- Get NEMO model grid properties -- #\n        dom_prefix, _ = self._get_properties(dom=dom)\n        grid_paths = self._get_grid_paths(dom=dom)\n        gridT, gridU, gridV = (\n            grid_paths[\"gridT\"],\n            grid_paths[\"gridU\"],\n            grid_paths[\"gridV\"],\n        )\n        ijk_names = self._get_ijk_names(dom=dom)\n        i_name, j_name = ijk_names[\"i\"], ijk_names[\"j\"]\n\n        # -- Define i,j vector components -- #\n        var_i, var_j = vars[0], vars[1]\n        if var_i not in self[gridU].data_vars:\n            raise KeyError(f\"variable '{var_i}' not found in grid '{gridU}'.\")\n        if var_j not in self[gridV].data_vars:\n            raise KeyError(f\"variable '{var_j}' not found in grid '{gridV}'.\")\n\n        da_i = self[f\"{gridU}/{var_i}\"]\n        da_j = self[f\"{gridV}/{var_j}\"]\n\n        # -- Collect mask -- #\n        if (f\"{dom_prefix}depthu\" in da_i.coords) &amp; (\n            f\"{dom_prefix}depthv\" in da_j.coords\n        ):\n            # 3-dimensional tmask:\n            tmask = self[gridT][\"tmask\"]\n        else:\n            # 2-dimensional tmask (unique points):\n            tmask = self[gridT][\"tmaskutil\"]\n\n        # -- Neglecting the first T-grid points along i, j dimensions -- #\n        e1t = self[f\"{gridT}/e1t\"].isel({i_name: slice(1, None), j_name: slice(1, None)})\n        e2t = self[f\"{gridT}/e2t\"].isel({i_name: slice(1, None), j_name: slice(1, None)})\n        e3t = self[f\"{gridT}/e3t\"].isel({i_name: slice(1, None), j_name: slice(1, None)})\n\n        e2u, e3u = self[f\"{gridU}/e2u\"], self[f\"{gridU}/e3u\"]\n        e1v, e3v = self[f\"{gridV}/e1v\"], self[f\"{gridV}/e3v\"]\n\n        # -- Calculate divergence on T-points -- #\n        dvar_i = (e2u * e3u * da_i).diff(dim=i_name, label=\"lower\")\n        dvar_i.coords[i_name] = dvar_i.coords[i_name] + 0.5\n\n        dvar_j = (e1v * e3v * da_j).diff(dim=j_name, label=\"lower\")\n        dvar_j.coords[j_name] = dvar_j.coords[j_name] + 0.5\n\n        divergence = (1 / (e1t * e2t * e3t)) * (dvar_i + dvar_j).where(tmask)\n\n        # -- Update DataArray properties -- #\n        divergence.name = f\"div_{var_i}_{var_j}\"\n        divergence = divergence.drop_vars(\n            [\n                f\"{dom_prefix}glamu\",\n                f\"{dom_prefix}gphiu\",\n                f\"{dom_prefix}glamv\",\n                f\"{dom_prefix}gphiv\",\n                f\"{dom_prefix}depthu\",\n                f\"{dom_prefix}depthv\",\n            ]\n        )\n\n        return divergence\n\n    def curl(\n        self,\n        vars: list[str],\n        dom: str = \".\",\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Calculate the vertical (k) curl component of a vector field on a NEMO model grid.\n\n        Parameters\n        ----------\n        vars : list[str]\n            Name of the vector variables, structured as: ['u', 'v'], where 'u' and 'v' are\n            the i and j components of the vector field, respectively.\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n            Default is '.' for the parent domain.\n\n        Returns\n        -------\n        xr.DataArray\n            Vertical curl component of vector field defined on a NEMO model grid.\n\n        Examples\n        --------\n        Compute the vertical component of the curl of the seawater velocity field in\n        the second NEMO nested child domain:\n\n        &gt;&gt;&gt; nemo.curl(dom=\"2\", vars=[\"uo\", \"vo\"])\n\n        Note, `vars` expects a list of the `i` and `j` components of the vector field,\n        respectively.\n\n        See Also\n        --------\n        divergence\n        \"\"\"\n        # -- Validate input -- #\n        if not isinstance(vars, list) or len(vars) != 2:\n            raise ValueError(\n                \"vars must be a list of two elements structured as ['u', 'v'].\"\n            )\n        if not isinstance(dom, str):\n            raise ValueError(\n                \"dom must be a string specifying the prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\"\n            )\n\n        # -- Get NEMO model grid properties -- #\n        dom_prefix, _ = self._get_properties(dom=dom)\n        grid_paths = self._get_grid_paths(dom=dom)\n        gridU, gridV, gridF = (\n            grid_paths[\"gridU\"],\n            grid_paths[\"gridV\"],\n            grid_paths[\"gridF\"],\n        )\n        ijk_names = self._get_ijk_names(dom=dom)\n        i_name, j_name = ijk_names[\"i\"], ijk_names[\"j\"]\n\n        # -- Define i,j vector components -- #\n        var_i, var_j = vars[0], vars[1]\n        if var_i not in self[gridU].data_vars:\n            raise KeyError(f\"variable '{var_i}' not found in grid '{gridU}'.\")\n        if var_j not in self[gridV].data_vars:\n            raise KeyError(f\"variable '{var_j}' not found in grid '{gridV}'.\")\n\n        da_i = self[f\"{gridU}/{var_i}\"]\n        da_j = self[f\"{gridV}/{var_j}\"]\n\n        # -- Collect mask -- #\n        if (f\"{dom_prefix}depthu\" in da_i.coords) &amp; (\n            f\"{dom_prefix}depthv\" in da_j.coords\n        ):\n            # 3-dimensional fmask\n            fmask = self[gridF][\"fmask\"]\n        else:\n            # 2-dimensional fmask (unique points):\n            fmask = self[gridF][\"fmaskutil\"]\n\n        # -- Neglecting the final F-grid points along i, j dimensions -- #\n        e1f = self[f\"{gridF}/e1f\"].isel(\n            {i_name: slice(None, -1), j_name: slice(None, -1)}\n        )\n        e2f = self[f\"{gridF}/e2f\"].isel(\n            {i_name: slice(None, -1), j_name: slice(None, -1)}\n        )\n\n        e1u = self[f\"{gridU}/e1u\"]\n        e2v = self[f\"{gridV}/e2v\"]\n        # -- Calculate vertical curl component on F-points -- #\n        dvar_i = (e2v * da_j).diff(dim=i_name, label=\"lower\")\n        dvar_i.coords[i_name] = dvar_i.coords[i_name] + 0.5\n\n        dvar_j = (e1u * da_i).diff(dim=j_name, label=\"lower\")\n        dvar_j.coords[j_name] = dvar_j.coords[j_name] + 0.5\n\n        curl = (1 / (e1f * e2f)) * (dvar_i - dvar_j).where(fmask)\n\n        # -- Update DataArray properties -- #\n        curl.name = f\"curl_{var_i}_{var_j}\"\n        curl = curl.drop_vars(\n            [\n                f\"{dom_prefix}glamu\",\n                f\"{dom_prefix}gphiu\",\n                f\"{dom_prefix}glamv\",\n                f\"{dom_prefix}gphiv\",\n            ]\n        )\n\n        return curl\n\n    def integral(\n        self,\n        grid: str,\n        var: str,\n        dims: list,\n        cum_dims: list | None = None,\n        dir: str | None = None,\n        mask: xr.DataArray | None = None,\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Integrate a variable along one or more dimensions of a NEMO model grid.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where variable is stored (e.g., 'gridT').\n        var : str\n            Name of variable to integrate.\n        dims : list\n            Dimensions over which to integrate (e.g., ['i', 'k']).\n        cum_dims : list, optional\n            Dimensions over which to cumulatively integrate (e.g., ['k']).\n            Specified dimensions must also be included in `dims`.\n        dir : str, optional\n            Direction of cumulative integration. Options are '+1' (along\n            increasing cum_dims) or '-1' (along decreasing cum_dims).\n        mask: xr.DataArray, optional\n            Boolean mask identifying NEMO model grid points to be included (1)\n            or neglected (0) from integration.\n\n        Returns\n        -------\n        xr.DataArray\n            Variable integrated along specified dimensions of the NEMO model grid.\n\n\n        Examples\n        --------\n        Compute the integral of conservative temperature `thetao_con` along the vertical\n        `k` dimension in the NEMO parent domain:\n\n\n        &gt;&gt;&gt; nemo.integral(grid=\"gridT\",\n        ...               var=\"thetao_con\",\n        ...               dims=[\"k\"]\n        ...               )\n\n        Compute the vertical meridional overturning stream function from the meridional\n        velocity `vo` (zonally integrated meridional velocity accumulated with increasing\n        depth):\n\n        &gt;&gt;&gt; nemo.integral(grid=\"gridV\",\n        ...               var=\"vo\",\n        ...               dims=[\"i\", \"k\"],\n        ...               cum_dims=[\"k\"],\n        ...               dir=\"+1\",\n        ...               )\n\n        See Also\n        --------\n        gradient\n        \"\"\"\n        # -- Validate input -- #\n        grid_keys = list(dict(self.subtree_with_keys).keys())\n        if grid not in grid_keys:\n            raise KeyError(\n                f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n            )\n        if var not in self[grid].data_vars:\n            raise KeyError(f\"variable '{var}' not found in grid '{grid}'.\")\n        if cum_dims is not None:\n            for dim in cum_dims:\n                if dim not in dims:\n                    raise ValueError(\n                        f\"cumulative integration dimension '{dim}' not included in `dims`.\"\n                    )\n            if dir not in [\"+1\", \"-1\"]:\n                raise ValueError(\n                    f\"invalid direction of cumulative integration '{dir}'. Expected '+1' or '-1'.\"\n                )\n        if mask is not None:\n            if not isinstance(mask, xr.DataArray):\n                raise ValueError(\"mask must be an xarray.DataArray.\")\n            if any(dim not in self[grid].dims for dim in mask.dims):\n                raise ValueError(\n                    f\"mask must have dimensions subset from {self[grid].dims}.\"\n                )\n\n        # -- Collect variable, weights &amp; mask -- #\n        da = (\n            self[f\"{grid}/{var}\"].where(mask)\n            if mask is not None\n            else self[f\"{grid}/{var}\"]\n        )\n        weights = self._get_weights(grid=grid, dims=dims)\n\n        # -- Perform integration -- #\n        if cum_dims is not None:\n            sum_dims = [dim for dim in dims if dim not in cum_dims]\n            if dir == \"+1\":\n                # Cumulative integration along ordered dimension:\n                result = (\n                    da.weighted(weights)\n                    .sum(dim=sum_dims, skipna=True)\n                    .cumsum(dim=cum_dims, skipna=True)\n                )\n            elif dir == \"-1\":\n                # Cumulative integration along reversed dimension:\n                result = (\n                    da.weighted(weights)\n                    .sum(dim=sum_dims, skipna=True)\n                    .reindex({dim: self[grid][dim][::-1] for dim in cum_dims})\n                    .cumsum(dim=cum_dims, skipna=True)\n                )\n        else:\n            # Integration only:\n            result = da.weighted(weights).sum(dim=dims, skipna=True)\n\n        return result\n\n    def depth_integral(\n        self, grid: str, var: str, limits: tuple[int | float]\n    ) -&gt; xr.Dataset:\n        \"\"\"\n        Integrate a variable in depth coordinates between two limits.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where variable is stored (e.g., 'gridT').\n        var : str\n            Name of the variable to vertically integrate.\n        limits : tuple[int | float]\n            Limits of depth integration given as a tuple of the form\n            (depth_lower, depth_upper) where depth_lower and depth_upper are\n            the lower and upper limits of vertical integration, respectively.\n\n        Returns\n        -------\n        xr.DataArray\n            Vertical integral of chosen variable between depth surfaces (depth_lower, depth_upper).\n\n        Examples\n        --------\n        Vertically integrate the conservative temperature variable `thetao_con` defined in a\n        NEMO model parent domain from the sea surface to 100 m depth:\n\n        &gt;&gt;&gt; nemo.depth_integral(grid='gridT',\n        ...                     var='thetao_con',\n        ...                     limits=(0, 100)\n        ...                              )\n\n        See Also\n        --------\n        integral\n        \"\"\"\n        # -- Validate input -- #\n        grid_keys = list(dict(self.subtree_with_keys).keys())\n        if grid not in grid_keys:\n            raise KeyError(\n                f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n            )\n        if var not in self[grid].data_vars:\n            raise KeyError(f\"Variable '{var}' not found in grid '{grid}'.\")\n        if (not isinstance(limits, tuple)) | (len(limits) != 2):\n            raise TypeError(\n                \"depth limits of integration should be given by a tuple of the form (depth_lower, depth_upper)\"\n            )\n        if (limits[0] &lt; 0) | (limits[1] &lt; 0):\n            raise ValueError(\"depth limits of integration must be non-negative.\")\n        if limits[0] &gt;= limits[1]:\n            raise ValueError(\n                \"lower depth limit must be less than upper depth limit.\"\n            )\n\n        # -- Get NEMO model grid properties -- #\n        dom, _, _, grid_suffix = self._get_properties(grid=grid, infer_dom=True)\n        ijk_names = self._get_ijk_names(dom=dom)\n        i_name, j_name, k_name = ijk_names[\"i\"], ijk_names[\"j\"], ijk_names[\"k\"]\n\n        # -- Define input variables -- #\n        var_in = self[f\"{grid}/{var}\"]\n        e3_in = self[f\"{grid}/e3{grid_suffix}\"]\n\n        # -- Vertically integrate w.r.t depth -- #\n        result = xr.apply_ufunc(\n            compute_depth_integral,\n            e3_in,\n            var_in,\n            np.array([limits[1]]),\n            np.array([limits[0]]),\n            input_core_dims=[[k_name], [k_name], [None], [None]],\n            output_core_dims=[[\"k_new\"]],\n            dask=\"allowed\",\n        )\n\n        # -- Create variable integral DataArray -- #\n        t_name = var_in.dims[0]\n        result = result.transpose(t_name, \"k_new\", j_name, i_name).squeeze()\n        result.name = f\"{var}_integral\"\n\n        return result\n\n    def clip_grid(\n        self,\n        grid: str,\n        bbox: tuple,\n    ) -&gt; Self:\n        \"\"\"\n        Clip a NEMO model grid to specified longitude and latitude range.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid to clip (e.g., 'gridT').\n        bbox : tuple\n            Bounding box to clip to (lon_min, lon_max, lat_min, lat_max).\n\n        Returns\n        -------\n        NEMODataTree\n            NEMO DataTree with specified model grid clipped to bounding box.\n\n        Examples\n        --------\n        Clip T-grid in a NEMO parent domain in the bounding box (-80\u00b0E, 0\u00b0E, 40\u00b0N, 80\u00b0N):\n\n        &gt;&gt;&gt; bbox = (-80, 0, 40, 80)\n\n        &gt;&gt;&gt; nemo.clip_grid(grid=\"gridT\", bbox=bbox)\n\n        See Also\n        --------\n        clip_domain\n        \"\"\"\n        # -- Validate input -- #\n        if not isinstance(bbox, tuple) or len(bbox) != 4:\n            raise ValueError(\n                \"bounding box must be a tuple (lon_min, lon_max, lat_min, lat_max).\"\n            )\n\n        # -- Get NEMO model grid properties -- #\n        _, dom_prefix, _, grid_suffix = self._get_properties(grid=grid, infer_dom=True)\n        hgrid_type = grid_suffix if \"w\" not in grid_suffix else \"t\"\n\n        # -- Clip the grid to given bounding box -- #\n        # Indexing with a mask requires loading coords into memory:\n        glam = self[grid][f\"{dom_prefix}glam{hgrid_type}\"].load()\n        gphi = self[grid][f\"{dom_prefix}gphi{hgrid_type}\"].load()\n\n        grid_clipped = self[grid].dataset.where(\n            (glam &gt;= bbox[0])\n            &amp; (glam &lt;= bbox[1])\n            &amp; (gphi &gt;= bbox[2])\n            &amp; (gphi &lt;= bbox[3]),\n            drop=True,\n        )\n\n        d_dtypes = {var: self[grid][var].dtype for var in self[grid].dataset.data_vars}\n        for var, dtype in d_dtypes.items():\n            if dtype in [np.int32, np.int64, bool]:\n                grid_clipped[var] = grid_clipped[var].fillna(0).astype(dtype)\n\n        if bbox != (-180, 180, -90, 90):\n            grid_clipped = grid_clipped.assign_attrs({\"iperio\": False})\n\n        # Update shallow copy of NEMODataTree:\n        self_copy = self.copy()\n        self_copy[grid].dataset = grid_clipped\n\n        return self_copy\n\n    def clip_domain(\n        self,\n        dom: str,\n        bbox: tuple,\n    ) -&gt; Self:\n        \"\"\"\n        Clip a NEMO model domain to specified longitude and latitude range.\n\n        Parameters\n        ----------\n        dom : str\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n            Default is '.' for the parent domain.\n        bbox : tuple\n            Bounding box to clip to (lon_min, lon_max, lat_min, lat_max).\n\n        Returns\n        -------\n        NEMODataTree\n            NEMO DataTree with specified model domain clipped to bounding box.\n\n        Examples\n        --------\n        Clip all model grids in a NEMO parent domain in the bounding box\n        (-80\u00b0E, 0\u00b0E, 40\u00b0N, 80\u00b0N):\n\n        &gt;&gt;&gt; bbox = (-80, 0, 40, 80)\n\n        &gt;&gt;&gt; nemo.clip_domain(dom=\".\", bbox=bbox)\n\n        See Also\n        --------\n        clip_grid\n        \"\"\"\n        # -- Validate input -- #\n        if not isinstance(dom, str):\n            raise ValueError(\n                \"dom must be a string specifying the prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\"\n            )\n        if not isinstance(bbox, tuple) or len(bbox) != 4:\n            raise ValueError(\n                \"bounding box must be a tuple: (lon_min, lon_max, lat_min, lat_max).\"\n            )\n\n        # -- Get NEMO model grid properties -- #\n        grid_paths = self._get_grid_paths(dom=dom)\n        ijk_names = self._get_ijk_names(dom=dom)\n        i_name, j_name = ijk_names[\"i\"], ijk_names[\"j\"]\n\n        # -- Clip grids to given bounding box -- #\n        if not grid_paths:\n            raise ValueError(f\"NEMO model domain '{dom}' not found in the DataTree.\")\n        else:\n            for grid in grid_paths.values():\n                # Identify grid type:\n                grid_suffix = self._get_properties(grid=grid)\n\n                if grid_suffix == \"t\":\n                    # Clip shallow copy of NEMODataTree T-grid using lon/lat bbox:\n                    self_copy = self.copy().clip_grid(grid=grid, bbox=bbox)\n                    # Store (i, j) coords of bbox on T-grid:\n                    i_bbox = self_copy[grid][i_name]\n                    j_bbox = self_copy[grid][j_name]\n\n                else:\n                    # Clip adjacent horizontal grid using (i, j) coords of clipped T-grid:\n                    match grid_suffix:\n                        case \"u\":\n                            grid_clipped = self[grid].dataset.sel(i=i_bbox + 0.5, j=j_bbox)\n                        case \"v\":\n                            grid_clipped = self[grid].dataset.sel(i=i_bbox, j=j_bbox + 0.5)\n                        case \"w\":\n                            grid_clipped = self[grid].dataset.sel(i=i_bbox, j=j_bbox)\n                        case \"f\":\n                            grid_clipped = self[grid].dataset.sel(i=i_bbox + 0.5, j=j_bbox + 0.5)\n\n                    if bbox != (-180, 180, -90, 90):\n                        grid_clipped = grid_clipped.assign_attrs({\"iperio\": False})\n                    # Update shallow copy of NEMODataTree:\n                    self_copy[grid].dataset = grid_clipped\n\n        return self_copy\n\n    def mask_with_polygon(\n        self,\n        grid: str,\n        lon_poly: list | np.ndarray,\n        lat_poly: list | np.ndarray,\n    ):\n        \"\"\"\n        Create mask of NEMO model grid points contained within a polygon.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where longitude and latitude coordinates\n            are stored (e.g., 'gridT').\n        lon_poly : list | ndarray\n            Longitudes of closed polygon.\n        lat_poly : list | ndarray\n            Latitudes of closed polygon.\n\n        Returns\n        -------\n        xr.DataArray\n            Boolean mask identifying NEMO model grid points which are inside\n            the polygon.\n\n        Examples\n        --------\n        Create a regional boolean mask using the geographical coordinates of a closed\n        polygon `lon_poly` and `lat_poly` in a NEMO parent domain:\n\n\n        &gt;&gt;&gt; nemo.mask_with_polygon(grid=\"gridT\",\n        ...                        lon_poly=lon_poly,\n        ...                        lat_poly=lat_poly,\n        ...                        )\n\n        See Also\n        --------\n        masked_statistic\n        \"\"\"\n        # -- Validate input -- #\n        if not isinstance(lon_poly, (np.ndarray, list)) or not isinstance(\n            lat_poly, (np.ndarray, list)\n        ):\n            raise TypeError(\n                \"longitude &amp; latitude coordinates of polygon must be numpy arrays or lists.\"\n            )\n        if (lon_poly[0] != lon_poly[-1]) or (lat_poly[0] != lat_poly[-1]):\n            raise ValueError(\n                \"longitude &amp; latitude coordinates must form a closed polygon.\"\n            )\n\n        # -- Get NEMO model grid properties -- #\n        dom, dom_prefix, _, grid_suffix = self._get_properties(grid=grid, infer_dom=True)\n        hgrid_type = grid_suffix if \"w\" not in grid_suffix else \"t\"\n        ijk_names = self._get_ijk_names(grid=grid)\n        i_name, j_name = ijk_names[\"i\"], ijk_names[\"j\"]\n\n        if dom == \".\":\n            lon_name = f\"glam{hgrid_type}\"\n            lat_name = f\"gphi{hgrid_type}\"\n        else:\n            lon_name = f\"{dom_prefix}glam{hgrid_type}\"\n            lat_name = f\"{dom_prefix}gphi{hgrid_type}\"\n\n        # -- Create mask using polygon coordinates -- #\n        mask = create_polygon_mask(\n            lon_grid=self[grid][lon_name],\n            lat_grid=self[grid][lat_name],\n            lon_poly=lon_poly,\n            lat_poly=lat_poly,\n            dims=(j_name, i_name),\n        )\n\n        return mask\n\n    def masked_statistic(\n        self,\n        grid: str,\n        var: str,\n        lon_poly: list | np.ndarray,\n        lat_poly: list | np.ndarray,\n        statistic: str,\n        dims: list,\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Masked statistic of a variable defined on a NEMO model grid.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where variable is stored (e.g., 'gridT').\n        var : str\n            Name of the variable to compute statistic.\n        lon_poly : list | np.ndarray\n            Longitudes of closed polygon.\n        lat_poly : list | np.ndarray\n            Latitudes of closed polygon.\n        statistic : str\n            Name of the statistic to calculate (e.g., 'mean', 'weighted_mean' 'sum').\n        dims : list\n            Dimensions over which to apply statistic (e.g., ['i', 'j']).\n\n        Returns\n        -------\n        xr.DataArray\n            Masked statistic of specified variable.\n\n        Examples\n        --------\n        Compute the grid cell area-weighted mean sea surface temperature `tos_con` for a\n        region enclosed in a polygon defined by `lon_poly` and `lat_poly` in a NEMO nested\n        child domain:\n\n        &gt;&gt;&gt; nemo.masked_statistic(grid=\"gridT/1_gridT\",\n        ...                       var=\"tos_con\",\n        ...                       lon_poly=lon_poly,\n        ...                       lat_poly=lat_poly,\n        ...                       statistic=\"weighted_mean\",\n        ...                       dims=[\"i\", \"j\"]\n        ...                       )\n\n        See Also\n        --------\n        binned_statistic\n        \"\"\"\n        # -- Validate input -- #\n        grid_keys = list(dict(self.subtree_with_keys).keys())\n        if grid not in grid_keys:\n            raise KeyError(\n                f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n            )\n        if var not in self[grid].data_vars:\n            raise KeyError(f\"variable '{var}' not found in grid '{grid}'.\")\n\n        # -- Create polygon mask using coordinates -- #\n        mask_poly = self.mask_with_polygon(\n            lon_poly=lon_poly, lat_poly=lat_poly, grid=grid\n        )\n\n        # -- Get NEMO model grid properties -- #\n        _, _, dom_suffix, _ = self._get_properties(grid=grid, infer_dom=True)\n\n        # -- Apply masks &amp; calculate statistic -- #\n        da = self[f\"{grid}/{var}\"].where(mask_poly)\n\n        match statistic:\n            case \"mean\":\n                result = da.mean(dim=dims, skipna=True)\n\n            case \"weighted_mean\":\n                weight_dims = [dim.replace(dom_suffix, \"\") for dim in dims]\n                weights = self._get_weights(grid=grid, dims=weight_dims)\n                result = da.weighted(weights).mean(dim=dims, skipna=True)\n\n            case \"min\":\n                result = da.min(dim=dims, skipna=True)\n\n            case \"max\":\n                result = da.max(dim=dims, skipna=True)\n\n            case \"sum\":\n                result = da.sum(dim=dims, skipna=True)\n\n            case _:\n                raise ValueError(\n                    f\"Unsupported statistic '{statistic}'. Supported statistics are: 'mean', 'weighted_mean', 'min', 'max', 'sum'.\"\n                )\n\n        return result\n\n    def extract_mask_boundary(\n        self,\n        mask: xr.DataArray,\n        uv_vars: list | None = None,\n        vars: list | None = None,\n        dom: str = \".\",\n    ) -&gt; xr.Dataset:\n        \"\"\"\n        Extract the boundary of a masked region defined on a NEMO model grid.\n\n        Parameters\n        ----------\n        mask : xr.DataArray\n            Boolean mask identifying NEMO model grid points which\n            are inside the region of interest.\n        uv_vars : list, optional\n            Names of velocity variables to extract along the boundary.\n            Default is ['uo', 'vo'].\n        vars : list, optional\n            Names of scalar variables to extract along the boundary.\n        dom : str, optional\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n            Default is '.' for the parent domain.\n\n        Returns\n        -------\n        xr.Dataset\n            Dataset containing variables and NEMO model coordinates\n            extracted along the boundary of the mask.\n\n        Examples\n        --------\n        Extract normal velocities and absolute salinity along the boundary of\n        a masked region in the NEMO parent domain:\n\n        &gt;&gt;&gt; nemo.extract_mask_boundary(mask=mask_osnap,\n        ...                            uv_vars=[\"uo\", \"vo\"],\n        ...                            vars=[\"so_abs\"],\n        ...                            dom=\".\",\n        ...                            )\n\n        See Also\n        --------\n        extract_section\n        \"\"\"\n        # -- Validate input -- #\n        if not isinstance(mask, xr.DataArray):\n            raise ValueError(\"mask must be an xarray DataArray\")\n        if not isinstance(dom, str):\n            raise ValueError(\n                \"dom must be a string specifying prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\"\n            )\n        if uv_vars is None:\n            uv_vars = [\"uo\", \"vo\"]\n        else:\n            if not isinstance(uv_vars, list) or len(uv_vars) != 2:\n                raise ValueError(\n                    \"uv_vars must be a list of velocity variables to extract (e.g., ['u', 'v']).\"\n                )\n\n        # -- Get NEMO model grid properties -- #\n        dom_prefix, dom_suffix = self._get_properties(dom=dom)\n        grid_paths = self._get_grid_paths(dom=dom)\n        gridT, gridU, gridV = (\n            grid_paths[\"gridT\"],\n            grid_paths[\"gridU\"],\n            grid_paths[\"gridV\"],\n        )\n        ijk_names = self._get_ijk_names(dom=dom)\n        k_name = ijk_names[\"k\"]\n\n        # -- Extract mask boundary -- #\n        if f\"i{dom_suffix}\" not in mask.dims or f\"j{dom_suffix}\" not in mask.dims:\n            raise ValueError(\n                f\"mask must have dimensions f'i{dom_suffix}' and 'j{dom_suffix}'\"\n            )\n        i_bdy, j_bdy, flux_type, flux_dir = get_mask_boundary(mask)\n\n        # -- Construct boundary dataset -- #\n        time_name = [dim for dim in self[gridU].dims if \"time\" in dim][0]\n\n        ds = xr.Dataset(\n            data_vars={\n                \"i_bdy\": ([\"bdy\"], i_bdy[::-1]),\n                \"j_bdy\": ([\"bdy\"], j_bdy[::-1]),\n                \"flux_type\": ([\"bdy\"], flux_type[::-1]),\n                \"flux_dir\": ([\"bdy\"], flux_dir[::-1]),\n            },\n            coords={\n                time_name: self[gridU][time_name].values,\n                k_name: self[gridU][k_name].values,\n                \"bdy\": np.arange(len(i_bdy)),\n            },\n        )\n\n        # Add velocities normal to boundary:\n        if uv_vars[0] not in self[gridU].data_vars:\n            raise KeyError(f\"variable '{uv_vars[0]}' not found in grid '{gridU}'.\")\n        if uv_vars[1] not in self[gridV].data_vars:\n            raise KeyError(f\"variable '{uv_vars[1]}' not found in grid '{gridV}'.\")\n\n        ubdy_mask = ds[\"flux_type\"] == \"U\"\n        vbdy_mask = ds[\"flux_type\"] == \"V\"\n\n        dim_sizes = [\n            self[gridU][time_name].size,\n            self[gridU][k_name].size,\n            ds[\"bdy\"].size,\n        ]\n\n        ds[\"velocity\"] = xr.DataArray(\n            data=dask.array.zeros(dim_sizes), dims=[time_name, k_name, \"bdy\"]\n        )\n        ds[\"velocity\"][:, :, ubdy_mask] = (\n            self[f\"{gridU}/{uv_vars[0]}\"].sel(\n                i=ds[\"i_bdy\"][ubdy_mask], j=ds[\"j_bdy\"][ubdy_mask]\n            )\n            * ds[\"flux_dir\"][ubdy_mask]\n        )\n        ds[\"velocity\"][:, :, vbdy_mask] = (\n            self[f\"{gridV}/{uv_vars[1]}\"].sel(\n                i=ds[\"i_bdy\"][vbdy_mask], j=ds[\"j_bdy\"][vbdy_mask]\n            )\n            * ds[\"flux_dir\"][vbdy_mask]\n        )\n\n        ds = ds.assign_coords(\n            {\n                f\"{dom_prefix}glamb\": ([\"bdy\"], np.zeros(ds[\"bdy\"].size)),\n                f\"{dom_prefix}gphib\": ([\"bdy\"], np.zeros(ds[\"bdy\"].size)),\n                f\"{dom_prefix}depthb\": ((k_name, \"bdy\"), np.zeros(dim_sizes[1:])),\n            }\n        )\n\n        ds[f\"{dom_prefix}glamb\"][ubdy_mask] = self[gridU][f\"{dom_prefix}glamu\"].sel(\n            i=ds[\"i_bdy\"][ubdy_mask], j=ds[\"j_bdy\"][ubdy_mask]\n        )\n        ds[f\"{dom_prefix}glamb\"][vbdy_mask] = self[gridV][f\"{dom_prefix}glamv\"].sel(\n            i=ds[\"i_bdy\"][vbdy_mask], j=ds[\"j_bdy\"][vbdy_mask]\n        )\n\n        ds[f\"{dom_prefix}gphib\"][ubdy_mask] = self[gridU][f\"{dom_prefix}gphiu\"].sel(\n            i=ds[\"i_bdy\"][ubdy_mask], j=ds[\"j_bdy\"][ubdy_mask]\n        )\n        ds[f\"{dom_prefix}gphib\"][vbdy_mask] = self[gridV][f\"{dom_prefix}gphiv\"].sel(\n            i=ds[\"i_bdy\"][vbdy_mask], j=ds[\"j_bdy\"][vbdy_mask]\n        )\n        ds[f\"{dom_prefix}depthb\"][:, ubdy_mask] = self[gridU][f\"{dom_prefix}depthu\"]\n        ds[f\"{dom_prefix}depthb\"][:, vbdy_mask] = self[gridV][f\"{dom_prefix}depthv\"]\n\n        if vars is not None:\n            # Add scalar variables along the boundary:\n            for var in vars:\n                if var in self[gridT].data_vars:\n                    ds[var] = xr.DataArray(\n                        data=dask.array.zeros(dim_sizes),\n                        dims=[time_name, k_name, \"bdy\"],\n                    )\n                else:\n                    raise KeyError(f\"variable {var} not found in grid '{gridT}'.\")\n\n                # Linearly interpolate scalar variables onto NEMO model U/V grid points:\n                ds[var][:, :, ubdy_mask] = 0.5 * (\n                    self[f\"{gridT}/{var}\"].sel(\n                        i=ds[\"i_bdy\"][ubdy_mask] - 0.5, j=ds[\"j_bdy\"][ubdy_mask]\n                    )\n                    + self[f\"{gridT}/{var}\"].sel(\n                        i=ds[\"i_bdy\"][ubdy_mask] + 0.5, j=ds[\"j_bdy\"][ubdy_mask]\n                    )\n                )\n                ds[var][:, :, vbdy_mask] = 0.5 * (\n                    self[f\"{gridT}/{var}\"].sel(\n                        i=ds[\"i_bdy\"][vbdy_mask], j=ds[\"j_bdy\"][vbdy_mask] - 0.5\n                    )\n                    + self[f\"{gridT}/{var}\"].sel(\n                        i=ds[\"i_bdy\"][vbdy_mask], j=ds[\"j_bdy\"][vbdy_mask] + 0.5\n                    )\n                )\n\n        return ds\n\n    def extract_section(\n        self,\n        lon_section: np.ndarray,\n        lat_section: np.ndarray,\n        uv_vars: list | None = None,\n        vars: list | None = None,\n        dom: str = \".\",\n    ) -&gt; xr.Dataset:\n        \"\"\"\n        Extract hydrographic section from a NEMO model domain.\n\n        Parameters\n        ----------\n        lon_section : np.ndarray\n            Longitudes defining the section polygon.\n        lat_section : np.ndarray\n            Latitudes defining the section polygon.\n        uv_vars : list, optional\n            Names of velocity variables to extract along the boundary.\n            Default is ['uo', 'vo'].\n        vars : list, optional\n            Names of scalar variables to extract along the boundary.\n        dom : str\n            Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n            Default is '.' for the parent domain.\n\n        Returns\n        -------\n        xr.Dataset\n            Dataset containing hydrographic section extracted from NEMO model grid.\n\n        Examples\n        --------\n        Extract normal velocities and potential density along the Overturning in the Subpolar\n        North Atlantic (OSNAP) array defined by `lon_osnap` and `lat_osnap` coordinates in the\n        NEMO parent domain:\n\n        &gt;&gt;&gt; nemo.extract_section(lon_section=lon_osnap,\n        ...                      lat_section=lat_osnap,\n        ...                      uv_vars=[\"uo\", \"vo\"],\n        ...                      vars=[\"sigma0\"],\n        ...                      dom=\".\",\n        ...                      )\n\n        See Also\n        --------\n        extract_mask_boundary\n        \"\"\"\n        # -- Validate input -- #\n        if not isinstance(lon_section, np.ndarray):\n            raise TypeError(\"lon_section must be a numpy array.\")\n        if not isinstance(lat_section, np.ndarray):\n            raise TypeError(\"lat_section must be a numpy array.\")\n        if not isinstance(dom, str):\n            raise ValueError(\n                \"dom must be a string specifying prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\"\n            )\n        if uv_vars is None:\n            uv_vars = [\"uo\", \"vo\"]\n        else:\n            if not isinstance(uv_vars, list) or len(uv_vars) != 2:\n                raise ValueError(\n                    \"uv_vars must be a list of velocity variables to extract (e.g., ['u', 'v']).\"\n                )\n\n        # -- Get NEMO model grid properties -- #\n        grid_paths = self._get_grid_paths(dom=dom)\n\n        # -- Define hydrographic section using polygon -- #\n        lon_poly, lat_poly = create_section_polygon(\n            lon_sec=lon_section,\n            lat_sec=lat_section,\n        )\n\n        mask = self.mask_with_polygon(\n            grid=grid_paths[\"gridT\"], lon_poly=lon_poly, lat_poly=lat_poly\n        )\n\n        i_bdy, j_bdy, flux_type, flux_dir = get_mask_boundary(mask)\n\n        # -- Create mask boundary dataset -- #\n        ds_bdy = create_boundary_dataset(\n            nemo=self,\n            dom=dom,\n            i_bdy=i_bdy,\n            j_bdy=j_bdy,\n            flux_type=flux_type,\n            flux_dir=flux_dir,\n        )\n\n        # -- Get indexes of hydrographic section along mask boundary -- #\n        sec_indexes = get_section_indexes(\n            ds_bdy=ds_bdy,\n            nemo=self,\n            dom=dom,\n            mask_section=mask,\n            lon_section=lon_section,\n            lat_section=lat_section,\n        )\n\n        # -- Update boundary dataset with extracted section data -- #\n        ds_bdy = update_boundary_dataset(\n            ds_bdy=ds_bdy,\n            nemo=self,\n            dom=dom,\n            sec_indexes=sec_indexes,\n            uv_vars=uv_vars,\n            vars=vars,\n        )\n\n        return ds_bdy\n\n    def binned_statistic(\n        self,\n        grid: str,\n        vars: list[str],\n        values: str,\n        keep_dims: list[str] | None,\n        bins: list[list | np.ndarray],\n        statistic: str,\n        mask: xr.DataArray | None,\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Calculate binned statistic of a variable defined on a NEMO model grid.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where variables and values are stored\n            (e.g., 'gridT').\n        vars : list[str]\n            Names of variable(s) to be grouped in discrete bins.\n        values : str\n            Name of the values with which to calculate binned statistic.\n        keep_dims : list[str] | None\n            Names of dimensions in values to keep as labels in binned statistic.\n        bins : list[list | np.ndarray]\n            Bin edges used to group each of the variables in `vars`.\n        statistic : str\n            Statistic to calculate (e.g., 'count', 'sum', 'nansum', 'mean', 'nanmean',\n            'max', 'nanmax', 'min', 'nanmin'). See flox.xarray.xarray_reduce for a\n            complete list of aggregation statistics.\n        mask : xr.DataArray | None\n            Boolean mask identifying NEMO model grid points to be included (1)\n            or neglected (0) from calculation.\n\n        Returns\n        -------\n        xr.DataArray\n            Values of the selected statistic in each bin.\n\n        Examples\n        --------\n        Compute the mean depth associated with each isopycnal in discrete potential\n        density `sigma0` coordinates:\n\n        &gt;&gt;&gt; sigma0_bins = np.arange(22, 29.05, 0.05)\n\n        &gt;&gt;&gt; nemo.binned_statistic(grid=\"gridT\",\n        ...                       vars=[\"sigma0\"],\n        ...                       values=\"deptht\",\n        ...                       keep_dims=[\"time_counter\"],\n        ...                       bins=[sigma0_bins],\n        ...                       statistic=\"nanmean\",\n        ...                       )\n\n        See Also\n        --------\n        masked_statistic\n        \"\"\"\n        # -- Validate input -- #\n        grid_keys = list(dict(self.subtree_with_keys).keys())\n        if grid not in grid_keys:\n            raise KeyError(\n                f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n            )\n        if any(var not in self[grid].data_vars for var in vars):\n            raise KeyError(f\"one or more variables {vars} not found in grid '{grid}'.\")\n        if values not in self[grid].data_vars:\n            raise KeyError(f\"values '{values}' not found in grid '{grid}'.\")\n        if keep_dims is not None:\n            if any(dim not in self[grid][values].dims for dim in keep_dims):\n                raise KeyError(\n                    f\"one or more dimensions {keep_dims} not found in values '{values}'.\"\n                )\n        if not all(isinstance(bin, (list, np.ndarray)) for bin in bins):\n            raise ValueError(\"bins must be a list of lists or numpy arrays.\")\n        if statistic not in [\n            \"all\",\n            \"any\",\n            \"count\",\n            \"sum\",\n            \"nansum\",\n            \"mean\",\n            \"nanmean\",\n            \"max\",\n            \"nanmax\",\n            \"min\",\n            \"nanmin\",\n            \"argmax\",\n            \"nanargmax\",\n            \"argmin\",\n            \"nanargmin\",\n            \"quantile\",\n            \"nanquantile\",\n            \"median\",\n            \"nanmedian\",\n            \"mode\",\n            \"nanmode\",\n            \"first\",\n            \"nanfirst\",\n            \"last\",\n            \"nanlast\",\n        ]:\n            raise ValueError(f\"statistic '{statistic}' is not supported.\")\n        if mask is not None:\n            if not isinstance(mask, xr.DataArray):\n                raise ValueError(\"mask must be an xarray.DataArray.\")\n            if mask.dtype != bool:\n                raise TypeError(\"mask dtype must be boolean.\")\n            if any(dim not in self[grid].dims for dim in mask.dims):\n                raise ValueError(\n                    f\"mask must have dimensions subset from {self[grid].dims}.\"\n                )\n\n        # -- Calculate binned statistics -- #\n        values_data = self[f\"{grid}/{values}\"]\n        var_data = [self[f\"{grid}/{var}\"] for var in vars]\n\n        result = compute_binned_statistic(\n            vars=var_data,\n            values=values_data,\n            keep_dims=keep_dims,\n            bins=bins,\n            statistic=statistic,\n            mask=mask,\n        )\n\n        return result\n\n    def transform_vertical_grid(\n        self, grid: str, var: str, e3_new: xr.DataArray\n    ) -&gt; xr.Dataset:\n        \"\"\"\n        Transform variable defined on a NEMO model grid to a new vertical grid using conservative interpolation.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where variable is stored\n            (e.g., 'gridT').\n        var : str\n            Name of the variable to transform.\n        e3_new : xarray.DataArray\n            Grid cell thicknesses of the new vertical grid.\n            Must be a 1-dimensional xarray.DataArray with\n            dimension 'k_new'.\n\n        Returns\n        -------\n        tuple[xr.DataArray, xr.DataArray]\n            Values of variable defined at the centre of each vertical\n            grid cell on the new grid, and vertical grid cell\n            thicknesses adjusted for model bathymetry.\n\n        Examples\n        --------\n        Transform the conservative temperature variable `thetao_con` defined in a\n        NEMO model parent domain from it's native 75 unevenly-spaced z-levels to\n        regularly spaced z-levels at 200 m intervals:\n\n        &gt;&gt;&gt; e3t_target = xr.DataArray(np.repeat(200.0, 30), dims=['k_new'])\n\n        &gt;&gt;&gt; nemo.transform_vertical_grid(grid='gridT',\n        ...                              var='thetao_con',\n        ...                              e3_new=e3t_target\n        ...                              )\n\n        See Also\n        --------\n        transform_to\n        \"\"\"\n        # -- Validate input -- #\n        grid_keys = list(dict(self.subtree_with_keys).keys())\n        if grid not in grid_keys:\n            raise KeyError(\n                f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n            )\n        if var not in self[grid].data_vars:\n            raise KeyError(f\"Variable '{var}' not found in grid '{grid}'.\")\n        if e3_new.dims != (\"k_new\",) or (e3_new.ndim != 1):\n            raise ValueError(\n                \"e3_new must be a 1-dimensional xarray.DataArray with dimension 'k_new'.\"\n            )\n\n        # -- Get NEMO model grid properties -- #\n        dom, _, _, grid_suffix = self._get_properties(grid=grid, infer_dom=True)\n        ijk_names = self._get_ijk_names(dom=dom)\n        i_name, j_name, k_name = ijk_names[\"i\"], ijk_names[\"j\"], ijk_names[\"k\"]\n\n        # -- Define input variables -- #\n        var_in = self[f\"{grid}/{var}\"]\n        e3_in = self[f\"{grid}/e3{grid_suffix}\"]\n        if e3_new.sum(dim=\"k_new\") &lt; self[grid][f\"depth{grid_suffix}\"].max(dim=k_name):\n            raise ValueError(\n                f\"e3_new must sum to at least the maximum depth ({self[grid][f'depth{grid_suffix}'].max(dim=k_name).item()} m) of the original vertical grid.\"\n            )\n\n        # -- Transform variable to target vertical grid -- #\n        var_out, e3_out = xr.apply_ufunc(\n            transform_vertical_coords,\n            e3_in,\n            var_in,\n            e3_new.astype(e3_in.dtype),\n            input_core_dims=[[k_name], [k_name], [\"k_new\"]],\n            output_core_dims=[[\"k_new\"], [\"k_new\"]],\n            dask=\"allowed\",\n        )\n\n        # -- Create transformed variable Dataset -- #\n        t_name = var_in.dims[0]\n        var_out = var_out.transpose(t_name, \"k_new\", j_name, i_name)\n\n        ds_out = xr.Dataset(\n            data_vars={var: var_out, f\"e3{grid_suffix}_new\": e3_out},\n            coords={\n                f\"depth{grid_suffix}_new\": (\"k_new\", e3_new.cumsum(dim=\"k_new\").data)\n            },\n        )\n\n        return ds_out\n\n    def transform_to(\n        self,\n        grid: str,\n        var: str,\n        to: str,\n    ) -&gt; xr.DataArray:\n        \"\"\"\n        Transform variable defined on a NEMO model grid to a neighbouring\n        horizontal grid using linear interpolation.\n\n        For flux variables defined at U- or V-points, the specified variable\n        is first weighted by grid cell face areas prior to linear interpolation,\n        and is then normalised by the target grid cell face areas following\n        interpolation.\n\n        Parameters\n        ----------\n        grid : str\n            Path to NEMO model grid where variable is stored (e.g., 'gridT').\n        var : str\n            Name of the variable to transform.\n        to : str\n            Suffix of the neighbouring horizontal NEMO model grid to\n            transform variable to. Options are 'T', 'U', 'V', 'F'.\n\n        Returns\n        -------\n        xr.DataArray\n            Values of variable linearly interpolated onto a neighbouring\n            horizontal grid.\n\n        Examples\n        --------\n        Transform conservative temperature `thetao_con` defined on scalar T-points\n        to neighbouring V-points in a NEMO model parent domain:\n\n        &gt;&gt;&gt; nemo.transform_to(grid='gridT', var='thetao_con', to='V')\n\n        See Also\n        --------\n        transform_vertical_grid\n        \"\"\"\n        # -- Validate input -- #\n        grid_keys = list(dict(self.subtree_with_keys).keys())\n        if grid not in grid_keys:\n            raise KeyError(\n                f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n            )\n        if var not in self[grid].data_vars:\n            raise KeyError(f\"variable '{var}' not found in grid '{grid}'.\")\n        if not isinstance(to, str):\n            raise TypeError(f\"'to' must be a string, got {type(to)}.\")\n        if to not in [\"T\", \"U\", \"V\", \"F\"]:\n            raise ValueError(f\"'to' must be one of ['T', 'U', 'V', 'F'], got {to}.\")\n\n        # -- Get NEMO model grid properties -- #\n        _, dom_prefix, _, grid_suffix = self._get_properties(grid=grid, infer_dom=True)\n        ijk_names = self._get_ijk_names(grid=grid)\n        i_name, j_name, k_name = ijk_names[\"i\"], ijk_names[\"j\"], ijk_names[\"k\"]\n        iperio = self[grid].attrs.get(\"iperio\", False)\n        target_grid = f\"{grid.replace(grid[-1], to)}\"\n\n        # -- Prepare variable for linear interpolation -- #\n        if grid_suffix.upper() in [\"U\", \"V\"]:\n            weight_dims = (\n                [k_name, j_name] if grid_suffix.upper() == \"U\" else [k_name, i_name]\n            )\n            if f\"{dom_prefix}depth{grid_suffix}\" in self[grid][var].coords:\n                # 3-D variables - weight by grid cell face area:\n                weights = self._get_weights(grid=grid, dims=weight_dims, fillna=False)\n                target_weights = self._get_weights(\n                    grid=target_grid, dims=weight_dims, fillna=False\n                )\n            else:\n                # 2-D variables - weight by grid cell width:\n                weights = self._get_weights(grid=grid, dims=weight_dims[1], fillna=False)\n                target_weights = self._get_weights(\n                    grid=target_grid, dims=weight_dims[1], fillna=False\n                )\n            da = self[f\"{grid}/{var}\"] * weights\n        else:\n            # Scalar variables:\n            da = self[f\"{grid}/{var}\"]\n\n        # -- Linearly interpolate variable -- #\n        # Define source grid mask:\n        if f\"{dom_prefix}depth{grid_suffix}\" in da.coords:\n            mask = self[grid][f\"{grid_suffix}mask\"]\n        else:\n            mask = self[grid][f\"{grid_suffix}maskutil\"]\n\n        result = interpolate_grid(\n            da=da,\n            mask=mask,\n            source_grid=grid[-1],\n            target_grid=target_grid[-1],\n            iperio=iperio,\n            ijk_names=ijk_names,\n        )\n\n        # -- Update interpolated variable -- #\n        # Retain input variable name:\n        result.name = da.name\n        # Reorder dimensions (time_counter, [k], j, i):\n        new_dims = (result.dims[-1], *result.dims[:-1])\n        result = result.transpose(*new_dims)\n\n        # Update NEMO grid coords:\n        result[i_name] = self[target_grid][i_name]\n        result[j_name] = self[target_grid][j_name]\n        if k_name in result.dims:\n            result[k_name] = self[target_grid][k_name]\n\n        # Drop NEMO source grid coords:\n        drop_vars = [f\"{dom_prefix}glam{grid_suffix}\", f\"{dom_prefix}gphi{grid_suffix}\"]\n        if f\"{dom_prefix}depth{grid_suffix}\" in da.coords:\n            drop_vars.append(f\"{dom_prefix}depth{grid_suffix}\")\n        result = result.drop_vars(drop_vars)\n\n        # Normalise by target grid cell weights for flux variables:\n        if grid_suffix.upper() in [\"U\", \"V\"]:\n            result = result / target_weights\n\n        # Apply target grid mask:\n        if f\"{dom_prefix}depth{grid_suffix}\" in da.coords:\n            target_mask = f\"{to.lower()}mask\"\n        else:\n            target_mask = f\"{to.lower()}maskutil\"\n        result = result.where(self[target_grid][target_mask])\n\n        return result\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(key)\n</code></pre> <p>Access child nodes, variables, or coordinates stored in this NEMODataTree.</p> <p>Returned object will be either a DataTree or DataArray object depending on whether the key given points to a child or variable.</p> <p>Overloads the getitem() method of xarray.DataTree to apply grid masks to returned DataArrays accessed via variable paths (i.e, /grid/var).</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of variable / child within this node, or unix-like path to variable / child within another node.</p> required <p>Returns:</p> Type Description <code>NEMODataTree | DataArray</code> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def __getitem__(self, key: str) -&gt; Self | xr.DataArray:\n    \"\"\"\n    Access child nodes, variables, or coordinates stored in this NEMODataTree.\n\n    Returned object will be either a DataTree or DataArray object depending on\n    whether the key given points to a child or variable.\n\n    Overloads the __getitem__() method of xarray.DataTree to apply grid masks\n    to returned DataArrays accessed via variable paths (i.e, /grid/var).\n\n    Parameters\n    ----------\n    key : str\n        Name of variable / child within this node, or unix-like path to variable\n        / child within another node.\n\n    Returns\n    -------\n    NEMODataTree | xr.DataArray\n    \"\"\"\n    # -- Access child node or variable -- #\n    item = super().__getitem__(key=key)\n    is_gridpath = key.startswith(\"/grid\") or key.startswith(\"grid\")\n\n    if isinstance(item, xr.DataArray) &amp; is_gridpath:\n        # -- Get NEMO model grid properties -- #\n        var_name = key.split(\"/\")[-1]\n        grid = key.replace(f\"/{var_name}\", \"\")\n        _, dom_prefix, _, grid_suffix = self._get_properties(\n            grid=grid, infer_dom=True\n        )\n\n        # -- Apply NEMO model grid mask -- #\n        # Masking only non-mask variables:\n        if (var_name != f\"{grid_suffix}mask\") and (\n            var_name != f\"{grid_suffix}maskutil\"\n        ):\n            if f\"{dom_prefix}depth{grid_suffix}\" in item.coords:\n                # Get 3-dimensional t/u/v/f mask:\n                mask = self[grid][f\"{grid_suffix}mask\"]\n            else:\n                # Get 2-dimensional t/u/v/f/w mask (unique points):\n                mask = self[grid][f\"{grid_suffix}maskutil\"]\n\n            item = item.where(mask, drop=False)\n\n    return item\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.__init__","title":"__init__","text":"<pre><code>__init__(*args, **kwargs)\n</code></pre> <p>Create a single node of a NEMODataTree.</p> <p>The node may optionally contain data in the form of data and coordinate variables, stored in the same way as data is stored in an <code>xarray.Dataset</code>.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>tuple</code> <p>Positional arguments to pass to the parent class.</p> <code>()</code> <code>**kwargs</code> <code>dict</code> <p>Keyword arguments to pass to the parent class.</p> <code>{}</code> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Create a single node of a NEMODataTree.\n\n    The node may optionally contain data in the form of data\n    and coordinate variables, stored in the same way as data\n    is stored in an `xarray.Dataset`.\n\n    Parameters\n    ----------\n    *args : tuple\n        Positional arguments to pass to the parent class.\n    **kwargs : dict\n        Keyword arguments to pass to the parent class.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.add_geoindex","title":"add_geoindex","text":"<pre><code>add_geoindex(grid)\n</code></pre> <p>Add geographical index variables to a given NEMO model grid.</p> <p>This enables users to index grid variables using geographical coordinates (e.g., glamt, gphit) in addition to their (i, j, k) dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid to add geographical indexes (e.g., 'gridT').</p> required <p>Returns:</p> Type Description <code>NEMODataTree</code> <p>NEMO DataTree with geographical indexes added to specified model grid.</p> <p>Examples:</p> <p>Add glamt, gphit as geographical indexes to the T-grid of the NEMO parent domain:</p> <pre><code>&gt;&gt;&gt; nemo.add_geoindex(grid=\"gridT\")\n</code></pre> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def add_geoindex(\n    self,\n    grid: str,\n) -&gt; Self:\n    \"\"\"\n    Add geographical index variables to a given NEMO model grid.\n\n    This enables users to index grid variables using geographical\n    coordinates (e.g., glamt, gphit) in addition to their (i, j, k)\n    dimensions.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid to add geographical indexes (e.g., 'gridT').\n\n    Returns\n    -------\n    NEMODataTree\n        NEMO DataTree with geographical indexes added to specified model grid.\n\n    Examples\n    --------\n    Add glamt, gphit as geographical indexes to the T-grid of the NEMO parent domain:\n\n    &gt;&gt;&gt; nemo.add_geoindex(grid=\"gridT\")\n\n    \"\"\"\n    # -- Set geographical indexes -- #\n    _, dom_prefix, _, grid_suffix = self._get_properties(grid=grid, infer_dom=True)\n    lon_name = f\"{dom_prefix}glam{grid_suffix}\"\n    lat_name = f\"{dom_prefix}gphi{grid_suffix}\"\n    self_copy = self.copy()\n    self_copy[grid] = (\n        self_copy[grid]\n        .dataset.assign_coords(\n            {lat_name: self_copy[grid][lat_name], lon_name: self_copy[grid][lon_name]}\n        )\n        .set_xindex(\n            (lat_name, lon_name),\n            NDPointIndex,\n            tree_adapter_self=SklearnGeoBallTreeAdapter,\n        )\n    )\n\n    return self_copy\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.binned_statistic","title":"binned_statistic","text":"<pre><code>binned_statistic(grid, vars, values, keep_dims, bins, statistic, mask)\n</code></pre> <p>Calculate binned statistic of a variable defined on a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where variables and values are stored (e.g., 'gridT').</p> required <code>vars</code> <code>list[str]</code> <p>Names of variable(s) to be grouped in discrete bins.</p> required <code>values</code> <code>str</code> <p>Name of the values with which to calculate binned statistic.</p> required <code>keep_dims</code> <code>list[str] | None</code> <p>Names of dimensions in values to keep as labels in binned statistic.</p> required <code>bins</code> <code>list[list | ndarray]</code> <p>Bin edges used to group each of the variables in <code>vars</code>.</p> required <code>statistic</code> <code>str</code> <p>Statistic to calculate (e.g., 'count', 'sum', 'nansum', 'mean', 'nanmean', 'max', 'nanmax', 'min', 'nanmin'). See flox.xarray.xarray_reduce for a complete list of aggregation statistics.</p> required <code>mask</code> <code>DataArray | None</code> <p>Boolean mask identifying NEMO model grid points to be included (1) or neglected (0) from calculation.</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Values of the selected statistic in each bin.</p> <p>Examples:</p> <p>Compute the mean depth associated with each isopycnal in discrete potential density <code>sigma0</code> coordinates:</p> <pre><code>&gt;&gt;&gt; sigma0_bins = np.arange(22, 29.05, 0.05)\n</code></pre> <pre><code>&gt;&gt;&gt; nemo.binned_statistic(grid=\"gridT\",\n...                       vars=[\"sigma0\"],\n...                       values=\"deptht\",\n...                       keep_dims=[\"time_counter\"],\n...                       bins=[sigma0_bins],\n...                       statistic=\"nanmean\",\n...                       )\n</code></pre> See Also <p>masked_statistic</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def binned_statistic(\n    self,\n    grid: str,\n    vars: list[str],\n    values: str,\n    keep_dims: list[str] | None,\n    bins: list[list | np.ndarray],\n    statistic: str,\n    mask: xr.DataArray | None,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Calculate binned statistic of a variable defined on a NEMO model grid.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where variables and values are stored\n        (e.g., 'gridT').\n    vars : list[str]\n        Names of variable(s) to be grouped in discrete bins.\n    values : str\n        Name of the values with which to calculate binned statistic.\n    keep_dims : list[str] | None\n        Names of dimensions in values to keep as labels in binned statistic.\n    bins : list[list | np.ndarray]\n        Bin edges used to group each of the variables in `vars`.\n    statistic : str\n        Statistic to calculate (e.g., 'count', 'sum', 'nansum', 'mean', 'nanmean',\n        'max', 'nanmax', 'min', 'nanmin'). See flox.xarray.xarray_reduce for a\n        complete list of aggregation statistics.\n    mask : xr.DataArray | None\n        Boolean mask identifying NEMO model grid points to be included (1)\n        or neglected (0) from calculation.\n\n    Returns\n    -------\n    xr.DataArray\n        Values of the selected statistic in each bin.\n\n    Examples\n    --------\n    Compute the mean depth associated with each isopycnal in discrete potential\n    density `sigma0` coordinates:\n\n    &gt;&gt;&gt; sigma0_bins = np.arange(22, 29.05, 0.05)\n\n    &gt;&gt;&gt; nemo.binned_statistic(grid=\"gridT\",\n    ...                       vars=[\"sigma0\"],\n    ...                       values=\"deptht\",\n    ...                       keep_dims=[\"time_counter\"],\n    ...                       bins=[sigma0_bins],\n    ...                       statistic=\"nanmean\",\n    ...                       )\n\n    See Also\n    --------\n    masked_statistic\n    \"\"\"\n    # -- Validate input -- #\n    grid_keys = list(dict(self.subtree_with_keys).keys())\n    if grid not in grid_keys:\n        raise KeyError(\n            f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n        )\n    if any(var not in self[grid].data_vars for var in vars):\n        raise KeyError(f\"one or more variables {vars} not found in grid '{grid}'.\")\n    if values not in self[grid].data_vars:\n        raise KeyError(f\"values '{values}' not found in grid '{grid}'.\")\n    if keep_dims is not None:\n        if any(dim not in self[grid][values].dims for dim in keep_dims):\n            raise KeyError(\n                f\"one or more dimensions {keep_dims} not found in values '{values}'.\"\n            )\n    if not all(isinstance(bin, (list, np.ndarray)) for bin in bins):\n        raise ValueError(\"bins must be a list of lists or numpy arrays.\")\n    if statistic not in [\n        \"all\",\n        \"any\",\n        \"count\",\n        \"sum\",\n        \"nansum\",\n        \"mean\",\n        \"nanmean\",\n        \"max\",\n        \"nanmax\",\n        \"min\",\n        \"nanmin\",\n        \"argmax\",\n        \"nanargmax\",\n        \"argmin\",\n        \"nanargmin\",\n        \"quantile\",\n        \"nanquantile\",\n        \"median\",\n        \"nanmedian\",\n        \"mode\",\n        \"nanmode\",\n        \"first\",\n        \"nanfirst\",\n        \"last\",\n        \"nanlast\",\n    ]:\n        raise ValueError(f\"statistic '{statistic}' is not supported.\")\n    if mask is not None:\n        if not isinstance(mask, xr.DataArray):\n            raise ValueError(\"mask must be an xarray.DataArray.\")\n        if mask.dtype != bool:\n            raise TypeError(\"mask dtype must be boolean.\")\n        if any(dim not in self[grid].dims for dim in mask.dims):\n            raise ValueError(\n                f\"mask must have dimensions subset from {self[grid].dims}.\"\n            )\n\n    # -- Calculate binned statistics -- #\n    values_data = self[f\"{grid}/{values}\"]\n    var_data = [self[f\"{grid}/{var}\"] for var in vars]\n\n    result = compute_binned_statistic(\n        vars=var_data,\n        values=values_data,\n        keep_dims=keep_dims,\n        bins=bins,\n        statistic=statistic,\n        mask=mask,\n    )\n\n    return result\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.cell_area","title":"cell_area","text":"<pre><code>cell_area(grid, dim)\n</code></pre> <p>Calculate grid cell areas orthogonal to a given dimension of a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid from which to calculate grid cell areas (e.g., 'gridT').</p> required <code>dim</code> <code>str</code> <p>Dimension orthogonal to grid cell area to calculate (e.g., 'k' returns e1 * e2).</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Grid cell areas (m^2) for the specified NEMO model grid.</p> <p>Examples:</p> <p>Compute the volume of each grid cell centered on a V-grid point in the NEMO parent domain:</p> <pre><code>&gt;&gt;&gt; nemo.cell_area(grid=\"gridT\", dim=\"k\")\n</code></pre> <p>Note, <code>dim</code> represents the dimension orthogonal to the grid cell area to be computed.</p> See Also <p>cell_volume</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def cell_area(\n    self,\n    grid: str,\n    dim: str,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Calculate grid cell areas orthogonal to a given dimension of a NEMO model grid.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid from which to calculate grid cell areas\n        (e.g., 'gridT').\n    dim : str\n        Dimension orthogonal to grid cell area to\n        calculate (e.g., 'k' returns e1 * e2).\n\n    Returns\n    -------\n    xr.DataArray\n        Grid cell areas (m^2) for the specified NEMO model grid.\n\n    Examples\n    --------\n    Compute the volume of each grid cell centered on a V-grid point\n    in the NEMO parent domain:\n\n    &gt;&gt;&gt; nemo.cell_area(grid=\"gridT\", dim=\"k\")\n\n    Note, `dim` represents the dimension orthogonal to the grid cell\n    area to be computed.\n\n    See Also\n    --------\n    cell_volume\n    \"\"\"\n    grid_suffix = self._get_properties(grid=grid)\n\n    if dim not in [\"i\", \"j\", \"k\"]:\n        raise ValueError(f\"dim {dim} must be one of ['i', 'j', 'k'].\")\n\n    match dim:\n        case \"i\":\n            cell_area = (\n                self[f\"{grid}/e3{grid_suffix}\"] * self[f\"{grid}/e2{grid_suffix}\"]\n            )\n        case \"j\":\n            cell_area = (\n                self[f\"{grid}/e3{grid_suffix}\"] * self[f\"{grid}/e1{grid_suffix}\"]\n            )\n        case \"k\":\n            cell_area = (\n                self[f\"{grid}/e1{grid_suffix}\"] * self[f\"{grid}/e2{grid_suffix}\"]\n            )\n    cell_area.name = \"areacello\"\n\n    return cell_area\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.cell_volume","title":"cell_volume","text":"<pre><code>cell_volume(grid)\n</code></pre> <p>Calculate grid cell volumes for a given NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid to calculate grid cell volumes (e.g., 'gridT').</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Grid cell volumes for the specified NEMO model grid.</p> <p>Examples:</p> <p>Compute the volume of each grid cell centered on a V-grid point in the NEMO parent domain:</p> <pre><code>&gt;&gt;&gt; nemo.cell_volumes(grid=\"gridV\")\n</code></pre> See Also <p>cell_area</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def cell_volume(self, grid: str) -&gt; xr.DataArray:\n    \"\"\"\n    Calculate grid cell volumes for a given NEMO model grid.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid to calculate grid cell volumes\n        (e.g., 'gridT').\n\n    Returns\n    -------\n    xr.DataArray\n        Grid cell volumes for the specified NEMO model grid.\n\n    Examples\n    --------\n    Compute the volume of each grid cell centered on a V-grid point\n    in the NEMO parent domain:\n\n    &gt;&gt;&gt; nemo.cell_volumes(grid=\"gridV\")\n\n    See Also\n    --------\n    cell_area\n    \"\"\"\n    grid_suffix = self._get_properties(grid=grid)\n\n    cell_volume = (\n        self[f\"{grid}/e3{grid_suffix}\"]\n        * self[f\"{grid}/e1{grid_suffix}\"]\n        * self[f\"{grid}/e2{grid_suffix}\"]\n    )\n    cell_volume.name = \"volcello\"\n\n    return cell_volume\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.clip_domain","title":"clip_domain","text":"<pre><code>clip_domain(dom, bbox)\n</code></pre> <p>Clip a NEMO model domain to specified longitude and latitude range.</p> <p>Parameters:</p> Name Type Description Default <code>dom</code> <code>str</code> <p>Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.). Default is '.' for the parent domain.</p> required <code>bbox</code> <code>tuple</code> <p>Bounding box to clip to (lon_min, lon_max, lat_min, lat_max).</p> required <p>Returns:</p> Type Description <code>NEMODataTree</code> <p>NEMO DataTree with specified model domain clipped to bounding box.</p> <p>Examples:</p> <p>Clip all model grids in a NEMO parent domain in the bounding box (-80\u00b0E, 0\u00b0E, 40\u00b0N, 80\u00b0N):</p> <pre><code>&gt;&gt;&gt; bbox = (-80, 0, 40, 80)\n</code></pre> <pre><code>&gt;&gt;&gt; nemo.clip_domain(dom=\".\", bbox=bbox)\n</code></pre> See Also <p>clip_grid</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def clip_domain(\n    self,\n    dom: str,\n    bbox: tuple,\n) -&gt; Self:\n    \"\"\"\n    Clip a NEMO model domain to specified longitude and latitude range.\n\n    Parameters\n    ----------\n    dom : str\n        Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        Default is '.' for the parent domain.\n    bbox : tuple\n        Bounding box to clip to (lon_min, lon_max, lat_min, lat_max).\n\n    Returns\n    -------\n    NEMODataTree\n        NEMO DataTree with specified model domain clipped to bounding box.\n\n    Examples\n    --------\n    Clip all model grids in a NEMO parent domain in the bounding box\n    (-80\u00b0E, 0\u00b0E, 40\u00b0N, 80\u00b0N):\n\n    &gt;&gt;&gt; bbox = (-80, 0, 40, 80)\n\n    &gt;&gt;&gt; nemo.clip_domain(dom=\".\", bbox=bbox)\n\n    See Also\n    --------\n    clip_grid\n    \"\"\"\n    # -- Validate input -- #\n    if not isinstance(dom, str):\n        raise ValueError(\n            \"dom must be a string specifying the prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\"\n        )\n    if not isinstance(bbox, tuple) or len(bbox) != 4:\n        raise ValueError(\n            \"bounding box must be a tuple: (lon_min, lon_max, lat_min, lat_max).\"\n        )\n\n    # -- Get NEMO model grid properties -- #\n    grid_paths = self._get_grid_paths(dom=dom)\n    ijk_names = self._get_ijk_names(dom=dom)\n    i_name, j_name = ijk_names[\"i\"], ijk_names[\"j\"]\n\n    # -- Clip grids to given bounding box -- #\n    if not grid_paths:\n        raise ValueError(f\"NEMO model domain '{dom}' not found in the DataTree.\")\n    else:\n        for grid in grid_paths.values():\n            # Identify grid type:\n            grid_suffix = self._get_properties(grid=grid)\n\n            if grid_suffix == \"t\":\n                # Clip shallow copy of NEMODataTree T-grid using lon/lat bbox:\n                self_copy = self.copy().clip_grid(grid=grid, bbox=bbox)\n                # Store (i, j) coords of bbox on T-grid:\n                i_bbox = self_copy[grid][i_name]\n                j_bbox = self_copy[grid][j_name]\n\n            else:\n                # Clip adjacent horizontal grid using (i, j) coords of clipped T-grid:\n                match grid_suffix:\n                    case \"u\":\n                        grid_clipped = self[grid].dataset.sel(i=i_bbox + 0.5, j=j_bbox)\n                    case \"v\":\n                        grid_clipped = self[grid].dataset.sel(i=i_bbox, j=j_bbox + 0.5)\n                    case \"w\":\n                        grid_clipped = self[grid].dataset.sel(i=i_bbox, j=j_bbox)\n                    case \"f\":\n                        grid_clipped = self[grid].dataset.sel(i=i_bbox + 0.5, j=j_bbox + 0.5)\n\n                if bbox != (-180, 180, -90, 90):\n                    grid_clipped = grid_clipped.assign_attrs({\"iperio\": False})\n                # Update shallow copy of NEMODataTree:\n                self_copy[grid].dataset = grid_clipped\n\n    return self_copy\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.clip_grid","title":"clip_grid","text":"<pre><code>clip_grid(grid, bbox)\n</code></pre> <p>Clip a NEMO model grid to specified longitude and latitude range.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid to clip (e.g., 'gridT').</p> required <code>bbox</code> <code>tuple</code> <p>Bounding box to clip to (lon_min, lon_max, lat_min, lat_max).</p> required <p>Returns:</p> Type Description <code>NEMODataTree</code> <p>NEMO DataTree with specified model grid clipped to bounding box.</p> <p>Examples:</p> <p>Clip T-grid in a NEMO parent domain in the bounding box (-80\u00b0E, 0\u00b0E, 40\u00b0N, 80\u00b0N):</p> <pre><code>&gt;&gt;&gt; bbox = (-80, 0, 40, 80)\n</code></pre> <pre><code>&gt;&gt;&gt; nemo.clip_grid(grid=\"gridT\", bbox=bbox)\n</code></pre> See Also <p>clip_domain</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def clip_grid(\n    self,\n    grid: str,\n    bbox: tuple,\n) -&gt; Self:\n    \"\"\"\n    Clip a NEMO model grid to specified longitude and latitude range.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid to clip (e.g., 'gridT').\n    bbox : tuple\n        Bounding box to clip to (lon_min, lon_max, lat_min, lat_max).\n\n    Returns\n    -------\n    NEMODataTree\n        NEMO DataTree with specified model grid clipped to bounding box.\n\n    Examples\n    --------\n    Clip T-grid in a NEMO parent domain in the bounding box (-80\u00b0E, 0\u00b0E, 40\u00b0N, 80\u00b0N):\n\n    &gt;&gt;&gt; bbox = (-80, 0, 40, 80)\n\n    &gt;&gt;&gt; nemo.clip_grid(grid=\"gridT\", bbox=bbox)\n\n    See Also\n    --------\n    clip_domain\n    \"\"\"\n    # -- Validate input -- #\n    if not isinstance(bbox, tuple) or len(bbox) != 4:\n        raise ValueError(\n            \"bounding box must be a tuple (lon_min, lon_max, lat_min, lat_max).\"\n        )\n\n    # -- Get NEMO model grid properties -- #\n    _, dom_prefix, _, grid_suffix = self._get_properties(grid=grid, infer_dom=True)\n    hgrid_type = grid_suffix if \"w\" not in grid_suffix else \"t\"\n\n    # -- Clip the grid to given bounding box -- #\n    # Indexing with a mask requires loading coords into memory:\n    glam = self[grid][f\"{dom_prefix}glam{hgrid_type}\"].load()\n    gphi = self[grid][f\"{dom_prefix}gphi{hgrid_type}\"].load()\n\n    grid_clipped = self[grid].dataset.where(\n        (glam &gt;= bbox[0])\n        &amp; (glam &lt;= bbox[1])\n        &amp; (gphi &gt;= bbox[2])\n        &amp; (gphi &lt;= bbox[3]),\n        drop=True,\n    )\n\n    d_dtypes = {var: self[grid][var].dtype for var in self[grid].dataset.data_vars}\n    for var, dtype in d_dtypes.items():\n        if dtype in [np.int32, np.int64, bool]:\n            grid_clipped[var] = grid_clipped[var].fillna(0).astype(dtype)\n\n    if bbox != (-180, 180, -90, 90):\n        grid_clipped = grid_clipped.assign_attrs({\"iperio\": False})\n\n    # Update shallow copy of NEMODataTree:\n    self_copy = self.copy()\n    self_copy[grid].dataset = grid_clipped\n\n    return self_copy\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.curl","title":"curl","text":"<pre><code>curl(vars, dom='.')\n</code></pre> <p>Calculate the vertical (k) curl component of a vector field on a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>vars</code> <code>list[str]</code> <p>Name of the vector variables, structured as: ['u', 'v'], where 'u' and 'v' are the i and j components of the vector field, respectively.</p> required <code>dom</code> <code>str</code> <p>Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.). Default is '.' for the parent domain.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Vertical curl component of vector field defined on a NEMO model grid.</p> <p>Examples:</p> <p>Compute the vertical component of the curl of the seawater velocity field in the second NEMO nested child domain:</p> <pre><code>&gt;&gt;&gt; nemo.curl(dom=\"2\", vars=[\"uo\", \"vo\"])\n</code></pre> <p>Note, <code>vars</code> expects a list of the <code>i</code> and <code>j</code> components of the vector field, respectively.</p> See Also <p>divergence</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def curl(\n    self,\n    vars: list[str],\n    dom: str = \".\",\n) -&gt; xr.DataArray:\n    \"\"\"\n    Calculate the vertical (k) curl component of a vector field on a NEMO model grid.\n\n    Parameters\n    ----------\n    vars : list[str]\n        Name of the vector variables, structured as: ['u', 'v'], where 'u' and 'v' are\n        the i and j components of the vector field, respectively.\n    dom : str, optional\n        Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        Default is '.' for the parent domain.\n\n    Returns\n    -------\n    xr.DataArray\n        Vertical curl component of vector field defined on a NEMO model grid.\n\n    Examples\n    --------\n    Compute the vertical component of the curl of the seawater velocity field in\n    the second NEMO nested child domain:\n\n    &gt;&gt;&gt; nemo.curl(dom=\"2\", vars=[\"uo\", \"vo\"])\n\n    Note, `vars` expects a list of the `i` and `j` components of the vector field,\n    respectively.\n\n    See Also\n    --------\n    divergence\n    \"\"\"\n    # -- Validate input -- #\n    if not isinstance(vars, list) or len(vars) != 2:\n        raise ValueError(\n            \"vars must be a list of two elements structured as ['u', 'v'].\"\n        )\n    if not isinstance(dom, str):\n        raise ValueError(\n            \"dom must be a string specifying the prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\"\n        )\n\n    # -- Get NEMO model grid properties -- #\n    dom_prefix, _ = self._get_properties(dom=dom)\n    grid_paths = self._get_grid_paths(dom=dom)\n    gridU, gridV, gridF = (\n        grid_paths[\"gridU\"],\n        grid_paths[\"gridV\"],\n        grid_paths[\"gridF\"],\n    )\n    ijk_names = self._get_ijk_names(dom=dom)\n    i_name, j_name = ijk_names[\"i\"], ijk_names[\"j\"]\n\n    # -- Define i,j vector components -- #\n    var_i, var_j = vars[0], vars[1]\n    if var_i not in self[gridU].data_vars:\n        raise KeyError(f\"variable '{var_i}' not found in grid '{gridU}'.\")\n    if var_j not in self[gridV].data_vars:\n        raise KeyError(f\"variable '{var_j}' not found in grid '{gridV}'.\")\n\n    da_i = self[f\"{gridU}/{var_i}\"]\n    da_j = self[f\"{gridV}/{var_j}\"]\n\n    # -- Collect mask -- #\n    if (f\"{dom_prefix}depthu\" in da_i.coords) &amp; (\n        f\"{dom_prefix}depthv\" in da_j.coords\n    ):\n        # 3-dimensional fmask\n        fmask = self[gridF][\"fmask\"]\n    else:\n        # 2-dimensional fmask (unique points):\n        fmask = self[gridF][\"fmaskutil\"]\n\n    # -- Neglecting the final F-grid points along i, j dimensions -- #\n    e1f = self[f\"{gridF}/e1f\"].isel(\n        {i_name: slice(None, -1), j_name: slice(None, -1)}\n    )\n    e2f = self[f\"{gridF}/e2f\"].isel(\n        {i_name: slice(None, -1), j_name: slice(None, -1)}\n    )\n\n    e1u = self[f\"{gridU}/e1u\"]\n    e2v = self[f\"{gridV}/e2v\"]\n    # -- Calculate vertical curl component on F-points -- #\n    dvar_i = (e2v * da_j).diff(dim=i_name, label=\"lower\")\n    dvar_i.coords[i_name] = dvar_i.coords[i_name] + 0.5\n\n    dvar_j = (e1u * da_i).diff(dim=j_name, label=\"lower\")\n    dvar_j.coords[j_name] = dvar_j.coords[j_name] + 0.5\n\n    curl = (1 / (e1f * e2f)) * (dvar_i - dvar_j).where(fmask)\n\n    # -- Update DataArray properties -- #\n    curl.name = f\"curl_{var_i}_{var_j}\"\n    curl = curl.drop_vars(\n        [\n            f\"{dom_prefix}glamu\",\n            f\"{dom_prefix}gphiu\",\n            f\"{dom_prefix}glamv\",\n            f\"{dom_prefix}gphiv\",\n        ]\n    )\n\n    return curl\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.depth_integral","title":"depth_integral","text":"<pre><code>depth_integral(grid, var, limits)\n</code></pre> <p>Integrate a variable in depth coordinates between two limits.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where variable is stored (e.g., 'gridT').</p> required <code>var</code> <code>str</code> <p>Name of the variable to vertically integrate.</p> required <code>limits</code> <code>tuple[int | float]</code> <p>Limits of depth integration given as a tuple of the form (depth_lower, depth_upper) where depth_lower and depth_upper are the lower and upper limits of vertical integration, respectively.</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Vertical integral of chosen variable between depth surfaces (depth_lower, depth_upper).</p> <p>Examples:</p> <p>Vertically integrate the conservative temperature variable <code>thetao_con</code> defined in a NEMO model parent domain from the sea surface to 100 m depth:</p> <pre><code>&gt;&gt;&gt; nemo.depth_integral(grid='gridT',\n...                     var='thetao_con',\n...                     limits=(0, 100)\n...                              )\n</code></pre> See Also <p>integral</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def depth_integral(\n    self, grid: str, var: str, limits: tuple[int | float]\n) -&gt; xr.Dataset:\n    \"\"\"\n    Integrate a variable in depth coordinates between two limits.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where variable is stored (e.g., 'gridT').\n    var : str\n        Name of the variable to vertically integrate.\n    limits : tuple[int | float]\n        Limits of depth integration given as a tuple of the form\n        (depth_lower, depth_upper) where depth_lower and depth_upper are\n        the lower and upper limits of vertical integration, respectively.\n\n    Returns\n    -------\n    xr.DataArray\n        Vertical integral of chosen variable between depth surfaces (depth_lower, depth_upper).\n\n    Examples\n    --------\n    Vertically integrate the conservative temperature variable `thetao_con` defined in a\n    NEMO model parent domain from the sea surface to 100 m depth:\n\n    &gt;&gt;&gt; nemo.depth_integral(grid='gridT',\n    ...                     var='thetao_con',\n    ...                     limits=(0, 100)\n    ...                              )\n\n    See Also\n    --------\n    integral\n    \"\"\"\n    # -- Validate input -- #\n    grid_keys = list(dict(self.subtree_with_keys).keys())\n    if grid not in grid_keys:\n        raise KeyError(\n            f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n        )\n    if var not in self[grid].data_vars:\n        raise KeyError(f\"Variable '{var}' not found in grid '{grid}'.\")\n    if (not isinstance(limits, tuple)) | (len(limits) != 2):\n        raise TypeError(\n            \"depth limits of integration should be given by a tuple of the form (depth_lower, depth_upper)\"\n        )\n    if (limits[0] &lt; 0) | (limits[1] &lt; 0):\n        raise ValueError(\"depth limits of integration must be non-negative.\")\n    if limits[0] &gt;= limits[1]:\n        raise ValueError(\n            \"lower depth limit must be less than upper depth limit.\"\n        )\n\n    # -- Get NEMO model grid properties -- #\n    dom, _, _, grid_suffix = self._get_properties(grid=grid, infer_dom=True)\n    ijk_names = self._get_ijk_names(dom=dom)\n    i_name, j_name, k_name = ijk_names[\"i\"], ijk_names[\"j\"], ijk_names[\"k\"]\n\n    # -- Define input variables -- #\n    var_in = self[f\"{grid}/{var}\"]\n    e3_in = self[f\"{grid}/e3{grid_suffix}\"]\n\n    # -- Vertically integrate w.r.t depth -- #\n    result = xr.apply_ufunc(\n        compute_depth_integral,\n        e3_in,\n        var_in,\n        np.array([limits[1]]),\n        np.array([limits[0]]),\n        input_core_dims=[[k_name], [k_name], [None], [None]],\n        output_core_dims=[[\"k_new\"]],\n        dask=\"allowed\",\n    )\n\n    # -- Create variable integral DataArray -- #\n    t_name = var_in.dims[0]\n    result = result.transpose(t_name, \"k_new\", j_name, i_name).squeeze()\n    result.name = f\"{var}_integral\"\n\n    return result\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.divergence","title":"divergence","text":"<pre><code>divergence(vars, dom='.')\n</code></pre> <p>Calculate the horizontal divergence of a vector field defined on a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>vars</code> <code>list[str]</code> <p>Name of vector variables, structured as: ['u', 'v'], where 'u' and 'v' are the i and j components of the vector field, respectively.</p> required <code>dom</code> <code>str</code> <p>Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.). Default is '.' for the parent domain.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Horizontal divergence of vector field defined on a NEMO model grid.</p> <p>Examples:</p> <p>Compute the horizontal divergence of the seawater velocity field in the NEMO parent domain:</p> <pre><code>&gt;&gt;&gt; nemo.divergence(dom=\".\", vars=[\"uo\", \"vo\"])\n</code></pre> <p>Note, <code>vars</code> expects a list of the <code>i</code> and <code>j</code> components of the vector field, respectively.</p> See Also <p>divergence</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def divergence(\n    self,\n    vars: list[str],\n    dom: str = \".\",\n) -&gt; xr.DataArray:\n    \"\"\"\n    Calculate the horizontal divergence of a vector field defined on a NEMO model grid.\n\n    Parameters\n    ----------\n    vars : list[str]\n        Name of vector variables, structured as: ['u', 'v'], where\n        'u' and 'v' are the i and j components of the vector field,\n        respectively.\n    dom : str, optional\n        Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        Default is '.' for the parent domain.\n\n    Returns\n    -------\n    xr.DataArray\n        Horizontal divergence of vector field defined on a NEMO model grid.\n\n    Examples\n    --------\n    Compute the horizontal divergence of the seawater velocity field in the\n    NEMO parent domain:\n\n    &gt;&gt;&gt; nemo.divergence(dom=\".\", vars=[\"uo\", \"vo\"])\n\n    Note, `vars` expects a list of the `i` and `j` components of the vector\n    field, respectively.\n\n    See Also\n    --------\n    divergence\n    \"\"\"\n    # -- Validate input -- #\n    if not isinstance(vars, list) or len(vars) != 2:\n        raise ValueError(\n            \"vars must be a list of two elements structured as ['u', 'v'].\"\n        )\n    if not isinstance(dom, str):\n        raise ValueError(\n            \"dom must be a string specifying the prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\"\n        )\n\n    # -- Get NEMO model grid properties -- #\n    dom_prefix, _ = self._get_properties(dom=dom)\n    grid_paths = self._get_grid_paths(dom=dom)\n    gridT, gridU, gridV = (\n        grid_paths[\"gridT\"],\n        grid_paths[\"gridU\"],\n        grid_paths[\"gridV\"],\n    )\n    ijk_names = self._get_ijk_names(dom=dom)\n    i_name, j_name = ijk_names[\"i\"], ijk_names[\"j\"]\n\n    # -- Define i,j vector components -- #\n    var_i, var_j = vars[0], vars[1]\n    if var_i not in self[gridU].data_vars:\n        raise KeyError(f\"variable '{var_i}' not found in grid '{gridU}'.\")\n    if var_j not in self[gridV].data_vars:\n        raise KeyError(f\"variable '{var_j}' not found in grid '{gridV}'.\")\n\n    da_i = self[f\"{gridU}/{var_i}\"]\n    da_j = self[f\"{gridV}/{var_j}\"]\n\n    # -- Collect mask -- #\n    if (f\"{dom_prefix}depthu\" in da_i.coords) &amp; (\n        f\"{dom_prefix}depthv\" in da_j.coords\n    ):\n        # 3-dimensional tmask:\n        tmask = self[gridT][\"tmask\"]\n    else:\n        # 2-dimensional tmask (unique points):\n        tmask = self[gridT][\"tmaskutil\"]\n\n    # -- Neglecting the first T-grid points along i, j dimensions -- #\n    e1t = self[f\"{gridT}/e1t\"].isel({i_name: slice(1, None), j_name: slice(1, None)})\n    e2t = self[f\"{gridT}/e2t\"].isel({i_name: slice(1, None), j_name: slice(1, None)})\n    e3t = self[f\"{gridT}/e3t\"].isel({i_name: slice(1, None), j_name: slice(1, None)})\n\n    e2u, e3u = self[f\"{gridU}/e2u\"], self[f\"{gridU}/e3u\"]\n    e1v, e3v = self[f\"{gridV}/e1v\"], self[f\"{gridV}/e3v\"]\n\n    # -- Calculate divergence on T-points -- #\n    dvar_i = (e2u * e3u * da_i).diff(dim=i_name, label=\"lower\")\n    dvar_i.coords[i_name] = dvar_i.coords[i_name] + 0.5\n\n    dvar_j = (e1v * e3v * da_j).diff(dim=j_name, label=\"lower\")\n    dvar_j.coords[j_name] = dvar_j.coords[j_name] + 0.5\n\n    divergence = (1 / (e1t * e2t * e3t)) * (dvar_i + dvar_j).where(tmask)\n\n    # -- Update DataArray properties -- #\n    divergence.name = f\"div_{var_i}_{var_j}\"\n    divergence = divergence.drop_vars(\n        [\n            f\"{dom_prefix}glamu\",\n            f\"{dom_prefix}gphiu\",\n            f\"{dom_prefix}glamv\",\n            f\"{dom_prefix}gphiv\",\n            f\"{dom_prefix}depthu\",\n            f\"{dom_prefix}depthv\",\n        ]\n    )\n\n    return divergence\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.extract_mask_boundary","title":"extract_mask_boundary","text":"<pre><code>extract_mask_boundary(mask, uv_vars=None, vars=None, dom='.')\n</code></pre> <p>Extract the boundary of a masked region defined on a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>DataArray</code> <p>Boolean mask identifying NEMO model grid points which are inside the region of interest.</p> required <code>uv_vars</code> <code>list</code> <p>Names of velocity variables to extract along the boundary. Default is ['uo', 'vo'].</p> <code>None</code> <code>vars</code> <code>list</code> <p>Names of scalar variables to extract along the boundary.</p> <code>None</code> <code>dom</code> <code>str</code> <p>Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.). Default is '.' for the parent domain.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>Dataset containing variables and NEMO model coordinates extracted along the boundary of the mask.</p> <p>Examples:</p> <p>Extract normal velocities and absolute salinity along the boundary of a masked region in the NEMO parent domain:</p> <pre><code>&gt;&gt;&gt; nemo.extract_mask_boundary(mask=mask_osnap,\n...                            uv_vars=[\"uo\", \"vo\"],\n...                            vars=[\"so_abs\"],\n...                            dom=\".\",\n...                            )\n</code></pre> See Also <p>extract_section</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def extract_mask_boundary(\n    self,\n    mask: xr.DataArray,\n    uv_vars: list | None = None,\n    vars: list | None = None,\n    dom: str = \".\",\n) -&gt; xr.Dataset:\n    \"\"\"\n    Extract the boundary of a masked region defined on a NEMO model grid.\n\n    Parameters\n    ----------\n    mask : xr.DataArray\n        Boolean mask identifying NEMO model grid points which\n        are inside the region of interest.\n    uv_vars : list, optional\n        Names of velocity variables to extract along the boundary.\n        Default is ['uo', 'vo'].\n    vars : list, optional\n        Names of scalar variables to extract along the boundary.\n    dom : str, optional\n        Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        Default is '.' for the parent domain.\n\n    Returns\n    -------\n    xr.Dataset\n        Dataset containing variables and NEMO model coordinates\n        extracted along the boundary of the mask.\n\n    Examples\n    --------\n    Extract normal velocities and absolute salinity along the boundary of\n    a masked region in the NEMO parent domain:\n\n    &gt;&gt;&gt; nemo.extract_mask_boundary(mask=mask_osnap,\n    ...                            uv_vars=[\"uo\", \"vo\"],\n    ...                            vars=[\"so_abs\"],\n    ...                            dom=\".\",\n    ...                            )\n\n    See Also\n    --------\n    extract_section\n    \"\"\"\n    # -- Validate input -- #\n    if not isinstance(mask, xr.DataArray):\n        raise ValueError(\"mask must be an xarray DataArray\")\n    if not isinstance(dom, str):\n        raise ValueError(\n            \"dom must be a string specifying prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\"\n        )\n    if uv_vars is None:\n        uv_vars = [\"uo\", \"vo\"]\n    else:\n        if not isinstance(uv_vars, list) or len(uv_vars) != 2:\n            raise ValueError(\n                \"uv_vars must be a list of velocity variables to extract (e.g., ['u', 'v']).\"\n            )\n\n    # -- Get NEMO model grid properties -- #\n    dom_prefix, dom_suffix = self._get_properties(dom=dom)\n    grid_paths = self._get_grid_paths(dom=dom)\n    gridT, gridU, gridV = (\n        grid_paths[\"gridT\"],\n        grid_paths[\"gridU\"],\n        grid_paths[\"gridV\"],\n    )\n    ijk_names = self._get_ijk_names(dom=dom)\n    k_name = ijk_names[\"k\"]\n\n    # -- Extract mask boundary -- #\n    if f\"i{dom_suffix}\" not in mask.dims or f\"j{dom_suffix}\" not in mask.dims:\n        raise ValueError(\n            f\"mask must have dimensions f'i{dom_suffix}' and 'j{dom_suffix}'\"\n        )\n    i_bdy, j_bdy, flux_type, flux_dir = get_mask_boundary(mask)\n\n    # -- Construct boundary dataset -- #\n    time_name = [dim for dim in self[gridU].dims if \"time\" in dim][0]\n\n    ds = xr.Dataset(\n        data_vars={\n            \"i_bdy\": ([\"bdy\"], i_bdy[::-1]),\n            \"j_bdy\": ([\"bdy\"], j_bdy[::-1]),\n            \"flux_type\": ([\"bdy\"], flux_type[::-1]),\n            \"flux_dir\": ([\"bdy\"], flux_dir[::-1]),\n        },\n        coords={\n            time_name: self[gridU][time_name].values,\n            k_name: self[gridU][k_name].values,\n            \"bdy\": np.arange(len(i_bdy)),\n        },\n    )\n\n    # Add velocities normal to boundary:\n    if uv_vars[0] not in self[gridU].data_vars:\n        raise KeyError(f\"variable '{uv_vars[0]}' not found in grid '{gridU}'.\")\n    if uv_vars[1] not in self[gridV].data_vars:\n        raise KeyError(f\"variable '{uv_vars[1]}' not found in grid '{gridV}'.\")\n\n    ubdy_mask = ds[\"flux_type\"] == \"U\"\n    vbdy_mask = ds[\"flux_type\"] == \"V\"\n\n    dim_sizes = [\n        self[gridU][time_name].size,\n        self[gridU][k_name].size,\n        ds[\"bdy\"].size,\n    ]\n\n    ds[\"velocity\"] = xr.DataArray(\n        data=dask.array.zeros(dim_sizes), dims=[time_name, k_name, \"bdy\"]\n    )\n    ds[\"velocity\"][:, :, ubdy_mask] = (\n        self[f\"{gridU}/{uv_vars[0]}\"].sel(\n            i=ds[\"i_bdy\"][ubdy_mask], j=ds[\"j_bdy\"][ubdy_mask]\n        )\n        * ds[\"flux_dir\"][ubdy_mask]\n    )\n    ds[\"velocity\"][:, :, vbdy_mask] = (\n        self[f\"{gridV}/{uv_vars[1]}\"].sel(\n            i=ds[\"i_bdy\"][vbdy_mask], j=ds[\"j_bdy\"][vbdy_mask]\n        )\n        * ds[\"flux_dir\"][vbdy_mask]\n    )\n\n    ds = ds.assign_coords(\n        {\n            f\"{dom_prefix}glamb\": ([\"bdy\"], np.zeros(ds[\"bdy\"].size)),\n            f\"{dom_prefix}gphib\": ([\"bdy\"], np.zeros(ds[\"bdy\"].size)),\n            f\"{dom_prefix}depthb\": ((k_name, \"bdy\"), np.zeros(dim_sizes[1:])),\n        }\n    )\n\n    ds[f\"{dom_prefix}glamb\"][ubdy_mask] = self[gridU][f\"{dom_prefix}glamu\"].sel(\n        i=ds[\"i_bdy\"][ubdy_mask], j=ds[\"j_bdy\"][ubdy_mask]\n    )\n    ds[f\"{dom_prefix}glamb\"][vbdy_mask] = self[gridV][f\"{dom_prefix}glamv\"].sel(\n        i=ds[\"i_bdy\"][vbdy_mask], j=ds[\"j_bdy\"][vbdy_mask]\n    )\n\n    ds[f\"{dom_prefix}gphib\"][ubdy_mask] = self[gridU][f\"{dom_prefix}gphiu\"].sel(\n        i=ds[\"i_bdy\"][ubdy_mask], j=ds[\"j_bdy\"][ubdy_mask]\n    )\n    ds[f\"{dom_prefix}gphib\"][vbdy_mask] = self[gridV][f\"{dom_prefix}gphiv\"].sel(\n        i=ds[\"i_bdy\"][vbdy_mask], j=ds[\"j_bdy\"][vbdy_mask]\n    )\n    ds[f\"{dom_prefix}depthb\"][:, ubdy_mask] = self[gridU][f\"{dom_prefix}depthu\"]\n    ds[f\"{dom_prefix}depthb\"][:, vbdy_mask] = self[gridV][f\"{dom_prefix}depthv\"]\n\n    if vars is not None:\n        # Add scalar variables along the boundary:\n        for var in vars:\n            if var in self[gridT].data_vars:\n                ds[var] = xr.DataArray(\n                    data=dask.array.zeros(dim_sizes),\n                    dims=[time_name, k_name, \"bdy\"],\n                )\n            else:\n                raise KeyError(f\"variable {var} not found in grid '{gridT}'.\")\n\n            # Linearly interpolate scalar variables onto NEMO model U/V grid points:\n            ds[var][:, :, ubdy_mask] = 0.5 * (\n                self[f\"{gridT}/{var}\"].sel(\n                    i=ds[\"i_bdy\"][ubdy_mask] - 0.5, j=ds[\"j_bdy\"][ubdy_mask]\n                )\n                + self[f\"{gridT}/{var}\"].sel(\n                    i=ds[\"i_bdy\"][ubdy_mask] + 0.5, j=ds[\"j_bdy\"][ubdy_mask]\n                )\n            )\n            ds[var][:, :, vbdy_mask] = 0.5 * (\n                self[f\"{gridT}/{var}\"].sel(\n                    i=ds[\"i_bdy\"][vbdy_mask], j=ds[\"j_bdy\"][vbdy_mask] - 0.5\n                )\n                + self[f\"{gridT}/{var}\"].sel(\n                    i=ds[\"i_bdy\"][vbdy_mask], j=ds[\"j_bdy\"][vbdy_mask] + 0.5\n                )\n            )\n\n    return ds\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.extract_section","title":"extract_section","text":"<pre><code>extract_section(lon_section, lat_section, uv_vars=None, vars=None, dom='.')\n</code></pre> <p>Extract hydrographic section from a NEMO model domain.</p> <p>Parameters:</p> Name Type Description Default <code>lon_section</code> <code>ndarray</code> <p>Longitudes defining the section polygon.</p> required <code>lat_section</code> <code>ndarray</code> <p>Latitudes defining the section polygon.</p> required <code>uv_vars</code> <code>list</code> <p>Names of velocity variables to extract along the boundary. Default is ['uo', 'vo'].</p> <code>None</code> <code>vars</code> <code>list</code> <p>Names of scalar variables to extract along the boundary.</p> <code>None</code> <code>dom</code> <code>str</code> <p>Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.). Default is '.' for the parent domain.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>Dataset containing hydrographic section extracted from NEMO model grid.</p> <p>Examples:</p> <p>Extract normal velocities and potential density along the Overturning in the Subpolar North Atlantic (OSNAP) array defined by <code>lon_osnap</code> and <code>lat_osnap</code> coordinates in the NEMO parent domain:</p> <pre><code>&gt;&gt;&gt; nemo.extract_section(lon_section=lon_osnap,\n...                      lat_section=lat_osnap,\n...                      uv_vars=[\"uo\", \"vo\"],\n...                      vars=[\"sigma0\"],\n...                      dom=\".\",\n...                      )\n</code></pre> See Also <p>extract_mask_boundary</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def extract_section(\n    self,\n    lon_section: np.ndarray,\n    lat_section: np.ndarray,\n    uv_vars: list | None = None,\n    vars: list | None = None,\n    dom: str = \".\",\n) -&gt; xr.Dataset:\n    \"\"\"\n    Extract hydrographic section from a NEMO model domain.\n\n    Parameters\n    ----------\n    lon_section : np.ndarray\n        Longitudes defining the section polygon.\n    lat_section : np.ndarray\n        Latitudes defining the section polygon.\n    uv_vars : list, optional\n        Names of velocity variables to extract along the boundary.\n        Default is ['uo', 'vo'].\n    vars : list, optional\n        Names of scalar variables to extract along the boundary.\n    dom : str\n        Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        Default is '.' for the parent domain.\n\n    Returns\n    -------\n    xr.Dataset\n        Dataset containing hydrographic section extracted from NEMO model grid.\n\n    Examples\n    --------\n    Extract normal velocities and potential density along the Overturning in the Subpolar\n    North Atlantic (OSNAP) array defined by `lon_osnap` and `lat_osnap` coordinates in the\n    NEMO parent domain:\n\n    &gt;&gt;&gt; nemo.extract_section(lon_section=lon_osnap,\n    ...                      lat_section=lat_osnap,\n    ...                      uv_vars=[\"uo\", \"vo\"],\n    ...                      vars=[\"sigma0\"],\n    ...                      dom=\".\",\n    ...                      )\n\n    See Also\n    --------\n    extract_mask_boundary\n    \"\"\"\n    # -- Validate input -- #\n    if not isinstance(lon_section, np.ndarray):\n        raise TypeError(\"lon_section must be a numpy array.\")\n    if not isinstance(lat_section, np.ndarray):\n        raise TypeError(\"lat_section must be a numpy array.\")\n    if not isinstance(dom, str):\n        raise ValueError(\n            \"dom must be a string specifying prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\"\n        )\n    if uv_vars is None:\n        uv_vars = [\"uo\", \"vo\"]\n    else:\n        if not isinstance(uv_vars, list) or len(uv_vars) != 2:\n            raise ValueError(\n                \"uv_vars must be a list of velocity variables to extract (e.g., ['u', 'v']).\"\n            )\n\n    # -- Get NEMO model grid properties -- #\n    grid_paths = self._get_grid_paths(dom=dom)\n\n    # -- Define hydrographic section using polygon -- #\n    lon_poly, lat_poly = create_section_polygon(\n        lon_sec=lon_section,\n        lat_sec=lat_section,\n    )\n\n    mask = self.mask_with_polygon(\n        grid=grid_paths[\"gridT\"], lon_poly=lon_poly, lat_poly=lat_poly\n    )\n\n    i_bdy, j_bdy, flux_type, flux_dir = get_mask_boundary(mask)\n\n    # -- Create mask boundary dataset -- #\n    ds_bdy = create_boundary_dataset(\n        nemo=self,\n        dom=dom,\n        i_bdy=i_bdy,\n        j_bdy=j_bdy,\n        flux_type=flux_type,\n        flux_dir=flux_dir,\n    )\n\n    # -- Get indexes of hydrographic section along mask boundary -- #\n    sec_indexes = get_section_indexes(\n        ds_bdy=ds_bdy,\n        nemo=self,\n        dom=dom,\n        mask_section=mask,\n        lon_section=lon_section,\n        lat_section=lat_section,\n    )\n\n    # -- Update boundary dataset with extracted section data -- #\n    ds_bdy = update_boundary_dataset(\n        ds_bdy=ds_bdy,\n        nemo=self,\n        dom=dom,\n        sec_indexes=sec_indexes,\n        uv_vars=uv_vars,\n        vars=vars,\n    )\n\n    return ds_bdy\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.from_datasets","title":"from_datasets  <code>classmethod</code>","text":"<pre><code>from_datasets(datasets, nests=None, iperio=False, nftype=None, read_mask=False, nbghost_child=4)\n</code></pre> <p>Create a NEMODataTree from a dictionary of <code>xarray.Dataset</code> objects created from NEMO model output files, organised into a hierarchy of domains (i.e., 'parent', 'child', 'grandchild').</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>dict[str, dict[str, Dataset]]</code> <p>Dictionary containing <code>xarray.Datasets</code> created from NEMO grid files, structured as: {     'parent': {'domain': ds_domain, 'gridT': ds_gridT, ... , 'icemod': ds_icemod.nc},     'child': {'1': {'domain': ds_domain_1, 'gridT': d_gridT_1, ...}},     'grandchild': {'2': {'domain': ds_domain_2, 'gridT': ds_gridT_2, ...}} }</p> required <code>nests</code> <code>dict[str, dict[str, str]]</code> <p>Dictionary describing the properties of nested domains, structured as: {     \"1\": {         \"parent\": \"/\",         \"rx\": rx,         \"ry\": ry,         \"imin\": imin,         \"imax\": imax,         \"jmin\": jmin,         \"jmax\": jmax,         }, } where <code>rx</code> and <code>ry</code> are the horizontal refinement factors, and <code>imin</code>, <code>imax</code>, <code>jmin</code>, <code>jmax</code> define the indices of the child (grandchild) domain within the parent (child) domain.</p> <code>None</code> <code>iperio</code> <code>bool</code> <p>Zonal periodicity of the parent domain.</p> <code>False</code> <code>nftype</code> <code>str | None</code> <p>Type of north fold lateral boundary condition to apply. Options are 'T' for T-point pivot or 'F' for F-point pivot. By default, no north fold lateral boundary condition is applied (None).</p> <code>None</code> <code>read_mask</code> <code>bool</code> <p>If True, read NEMO model land/sea mask from domain files. Default is False, meaning masks are computed from top_level and bottom_level domain variables.</p> <code>False</code> <code>nbghost_child</code> <code>int = 4</code> <p>Number of ghost cells to remove from the western/southern boundaries of the (grand)child domains. Default is 4.</p> <code>4</code> <p>Returns:</p> Type Description <code>NEMODataTree</code> <p>A hierarchical data tree of NEMO model outputs.</p> <p>Examples:</p> <p>Create a <code>NEMODataTree</code> from a dictionary of xarray.Dataset objects:</p> <pre><code>&gt;&gt;&gt; import xarray as xr\n&gt;&gt;&gt; from nemo_cookbook import NEMODataTree\n</code></pre> <pre><code>&gt;&gt;&gt; ds_domain = xr.open_zarr(\"https://some_remote_data/domain_cfg.zarr\")\n&gt;&gt;&gt; ds_gridT = xr.open_zarr(\"https://some_remote_data/my_model_gridT.zarr\")\n</code></pre> <pre><code>&gt;&gt;&gt; datasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}\n</code></pre> <pre><code>&gt;&gt;&gt; nemo = NEMODataTree.from_datasets(datasets=datasets)\n</code></pre> See Also <p>from_paths</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>@classmethod\ndef from_datasets(\n    cls,\n    datasets: dict[str, dict[str, xr.Dataset]],\n    nests: dict[str, dict[str, str]] | None = None,\n    iperio: bool = False,\n    nftype: str | None = None,\n    read_mask: bool = False,\n    nbghost_child: int = 4,\n) -&gt; Self:\n    \"\"\"\n    Create a NEMODataTree from a dictionary of `xarray.Dataset` objects created from NEMO model output files,\n    organised into a hierarchy of domains (i.e., 'parent', 'child', 'grandchild').\n\n    Parameters\n    ----------\n    datasets : dict[str, dict[str, xr.Dataset]]\n        Dictionary containing `xarray.Datasets` created from NEMO grid files, structured as:\n        {\n            'parent': {'domain': ds_domain, 'gridT': ds_gridT, ... , 'icemod': ds_icemod.nc},\n            'child': {'1': {'domain': ds_domain_1, 'gridT': d_gridT_1, ...}},\n            'grandchild': {'2': {'domain': ds_domain_2, 'gridT': ds_gridT_2, ...}}\n        }\n\n    nests : dict[str, dict[str, str]], optional\n        Dictionary describing the properties of nested domains, structured as:\n        {\n            \"1\": {\n                \"parent\": \"/\",\n                \"rx\": rx,\n                \"ry\": ry,\n                \"imin\": imin,\n                \"imax\": imax,\n                \"jmin\": jmin,\n                \"jmax\": jmax,\n                },\n        }\n        where `rx` and `ry` are the horizontal refinement factors, and `imin`, `imax`, `jmin`, `jmax`\n        define the indices of the child (grandchild) domain within the parent (child) domain.\n\n    iperio: bool = False\n        Zonal periodicity of the parent domain.\n\n    nftype: str, optional\n        Type of north fold lateral boundary condition to apply. Options are 'T' for T-point pivot or 'F' for F-point\n        pivot. By default, no north fold lateral boundary condition is applied (None).\n\n    read_mask: bool = False\n        If True, read NEMO model land/sea mask from domain files. Default is False, meaning masks are computed from top_level and bottom_level domain variables.\n\n    nbghost_child : int = 4\n        Number of ghost cells to remove from the western/southern boundaries of the (grand)child domains. Default is 4.\n\n    Returns\n    -------\n    NEMODataTree\n        A hierarchical data tree of NEMO model outputs.\n\n    Examples\n    --------\n    Create a `NEMODataTree` from a dictionary of xarray.Dataset objects:\n\n    &gt;&gt;&gt; import xarray as xr\n    &gt;&gt;&gt; from nemo_cookbook import NEMODataTree\n\n    &gt;&gt;&gt; ds_domain = xr.open_zarr(\"https://some_remote_data/domain_cfg.zarr\")\n    &gt;&gt;&gt; ds_gridT = xr.open_zarr(\"https://some_remote_data/my_model_gridT.zarr\")\n\n    &gt;&gt;&gt; datasets = {\"parent\": {\"domain\": ds_domain, \"gridT\": ds_gridT}}\n\n    &gt;&gt;&gt; nemo = NEMODataTree.from_datasets(datasets=datasets)\n\n    See Also\n    --------\n    from_paths\n    \"\"\"\n    if not isinstance(datasets, dict):\n        raise TypeError(\"datasets must be a dictionary or nested dictionary.\")\n    if not isinstance(nests, (dict, type(None))):\n        raise TypeError(\"nests must be a dictionary or None.\")\n    if not isinstance(iperio, bool):\n        raise TypeError(\"zonal periodicity of parent domain must be a boolean.\")\n    if nftype is not None and nftype not in (\"T\", \"F\"):\n        raise ValueError(\n            \"north fold type of parent domain must be 'T' (T-pivot fold), 'F' (F-pivot fold), or None.\"\n        )\n    if not isinstance(read_mask, bool):\n        raise TypeError(\"read_mask must be a boolean.\")\n    if not isinstance(nbghost_child, int):\n        raise TypeError(\n            \"number of ghost cells along the western/southern boundaries must be an integer.\"\n        )\n\n    # Define parent, child, grandchild dataset collections:\n    d_child, d_grandchild = None, None\n    if \"parent\" in datasets.keys() and isinstance(datasets[\"parent\"], dict):\n        for key in datasets.keys():\n            if key not in (\"parent\", \"child\", \"grandchild\"):\n                raise KeyError(f\"Unexpected key '{key}' in datasets dictionary.\")\n            if key == \"parent\":\n                d_parent = datasets[\"parent\"]\n            elif key == \"child\":\n                d_child = datasets[\"child\"]\n            elif key == \"grandchild\":\n                d_grandchild = datasets[\"grandchild\"]\n    else:\n        raise ValueError(\n            \"Invalid datasets structure. Expected a nested dictionary defining NEMO 'parent', 'child' and 'grandchild' domains.\"\n        )\n\n    # Construct DataTree from parent / child / grandchild domains:\n    d_tree = create_datatree_dict(\n        d_parent=d_parent,\n        d_child=d_child,\n        d_grandchild=d_grandchild,\n        nests=nests,\n        iperio=iperio,\n        nftype=nftype,\n        read_mask=read_mask,\n        nbghost_child=nbghost_child,\n    )\n    datatree = super().from_dict(d_tree)\n\n    return datatree\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.from_paths","title":"from_paths  <code>classmethod</code>","text":"<pre><code>from_paths(paths, nests=None, iperio=False, nftype=None, read_mask=False, nbghost_child=4, **open_kwargs)\n</code></pre> <p>Create a NEMODataTree from a dictionary of paths to NEMO model output files, organised into a hierarchy of domains (i.e., 'parent', 'child', 'grandchild').</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>dict[str, str]</code> <p>Dictionary containing paths to NEMO grid files, structured as: {     'parent': {'domain': 'path/to/domain.nc',                'gridT': 'path/to/gridT.nc',                 , ... ,                 'icemod': 'path/to/icemod.nc',                 },     'child': {'1': {'domain': 'path/to/child_domain.nc',                     'gridT': 'path/to/child_gridT.nc',                     , ... ,                     'icemod': 'path/to/child_icemod.nc',                     },               },     'grandchild': {'2': {'domain': 'path/to/grandchild_domain.nc',                          'gridT': 'path/to/grandchild_gridT.nc',                          , ...,                          'icemod': 'path/to/grandchild_icemod.nc',                          },                    } }</p> required <code>nests</code> <code>dict[str, str]</code> <p>Dictionary describing the properties of nested domains, structured as: {     \"1\": {         \"parent\": \"/\",         \"rx\": rx,         \"ry\": ry,         \"imin\": imin,         \"imax\": imax,         \"jmin\": jmin,         \"jmax\": jmax,         \"iperio\": iperio,         }, } where <code>rx</code> and <code>ry</code> are the horizontal refinement factors, and <code>imin</code>, <code>imax</code>, <code>jmin</code>, <code>jmax</code> define the indices of the child (grandchild) domain within the parent (child) domain. Zonally periodic nested domains should be specified with <code>iperio=True</code>.</p> <code>None</code> <code>iperio</code> <code>bool</code> <p>Zonal periodicity of the parent domain. Default is False.</p> <code>False</code> <code>nftype</code> <code>str | None</code> <p>Type of north fold lateral boundary condition to apply. Options are 'T' for T-point pivot or 'F' for F-point pivot. By default, no north fold lateral boundary condition is applied (None).</p> <code>None</code> <code>read_mask</code> <code>bool</code> <p>If True, read NEMO model land/sea mask from domain files. Default is False, meaning masks are computed from top_level and bottom_level domain variables.</p> <code>False</code> <code>nbghost_child</code> <code>int = 4</code> <p>Number of ghost cells to remove from the western/southern boundaries of the (grand)child domains. Default is 4.</p> <code>4</code> <code>**open_kwargs</code> <code>dict</code> <p>Additional keyword arguments to pass to <code>xarray.open_dataset</code> or <code>xr.open_mfdataset</code> when opening NEMO model output files.</p> <code>{}</code> <p>Returns:</p> Type Description <code>NEMODataTree</code> <p>A hierarchical DataTree storing NEMO model outputs.</p> <p>Examples:</p> <p>Create a <code>NEMODataTree</code> from a dictionary of paths to local netCDF files:</p> <pre><code>&gt;&gt;&gt; from nemo_cookbook import NEMODataTree\n</code></pre> <pre><code>&gt;&gt;&gt; paths = {\"parent\": {\n...          \"domain\": \"/path/to/domain_cfg.nc\",\n...          \"gridT\": \"path/to/*_gridT.nc\",\n...          \"gridU\": \"path/to/*_gridV.nc\",\n...          \"gridV\": \"path/to/*_gridV.nc\",\n...          \"gridW\": \"path/to/*_gridW.nc\",\n...          \"icemod\": \"path/to/*_icemod.nc\",\n...          }}\n</code></pre> <pre><code>&gt;&gt;&gt; NEMODataTree.from_paths(paths, iperio=True, nftype=\"T\")\n</code></pre> See Also <p>from_datasets</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>@classmethod\ndef from_paths(\n    cls,\n    paths: dict[str, str],\n    nests: dict[str, str] | None = None,\n    iperio: bool = False,\n    nftype: str | None = None,\n    read_mask: bool = False,\n    nbghost_child: int = 4,\n    **open_kwargs: dict[str, any],\n) -&gt; Self:\n    \"\"\"\n    Create a NEMODataTree from a dictionary of paths to NEMO model output files,\n    organised into a hierarchy of domains (i.e., 'parent', 'child', 'grandchild').\n\n    Parameters\n    ----------\n    paths : dict[str, str]\n        Dictionary containing paths to NEMO grid files, structured as:\n        {\n            'parent': {'domain': 'path/to/domain.nc',\n                       'gridT': 'path/to/gridT.nc',\n                        , ... ,\n                        'icemod': 'path/to/icemod.nc',\n                        },\n            'child': {'1': {'domain': 'path/to/child_domain.nc',\n                            'gridT': 'path/to/child_gridT.nc',\n                            , ... ,\n                            'icemod': 'path/to/child_icemod.nc',\n                            },\n                      },\n            'grandchild': {'2': {'domain': 'path/to/grandchild_domain.nc',\n                                 'gridT': 'path/to/grandchild_gridT.nc',\n                                 , ...,\n                                 'icemod': 'path/to/grandchild_icemod.nc',\n                                 },\n                           }\n        }\n\n    nests : dict[str, str], optional\n        Dictionary describing the properties of nested domains, structured as:\n        {\n            \"1\": {\n                \"parent\": \"/\",\n                \"rx\": rx,\n                \"ry\": ry,\n                \"imin\": imin,\n                \"imax\": imax,\n                \"jmin\": jmin,\n                \"jmax\": jmax,\n                \"iperio\": iperio,\n                },\n        }\n        where `rx` and `ry` are the horizontal refinement factors, and `imin`, `imax`, `jmin`, `jmax`\n        define the indices of the child (grandchild) domain within the parent (child) domain. Zonally\n        periodic nested domains should be specified with `iperio=True`.\n\n    iperio: bool = False\n        Zonal periodicity of the parent domain. Default is False.\n\n    nftype: str, optional\n        Type of north fold lateral boundary condition to apply. Options are 'T' for T-point pivot or 'F' for F-point\n        pivot. By default, no north fold lateral boundary condition is applied (None).\n\n    read_mask: bool = False\n        If True, read NEMO model land/sea mask from domain files. Default is False, meaning masks are computed from top_level and bottom_level domain variables.\n\n    nbghost_child : int = 4\n        Number of ghost cells to remove from the western/southern boundaries of the (grand)child domains. Default is 4.\n\n    **open_kwargs : dict, optional\n        Additional keyword arguments to pass to `xarray.open_dataset` or `xr.open_mfdataset` when opening NEMO model output files.\n    Returns\n    -------\n    NEMODataTree\n        A hierarchical DataTree storing NEMO model outputs.\n\n    Examples\n    --------\n    Create a `NEMODataTree` from a dictionary of paths to local netCDF files:\n\n    &gt;&gt;&gt; from nemo_cookbook import NEMODataTree\n\n    &gt;&gt;&gt; paths = {\"parent\": {\n    ...          \"domain\": \"/path/to/domain_cfg.nc\",\n    ...          \"gridT\": \"path/to/*_gridT.nc\",\n    ...          \"gridU\": \"path/to/*_gridV.nc\",\n    ...          \"gridV\": \"path/to/*_gridV.nc\",\n    ...          \"gridW\": \"path/to/*_gridW.nc\",\n    ...          \"icemod\": \"path/to/*_icemod.nc\",\n    ...          }}\n\n    &gt;&gt;&gt; NEMODataTree.from_paths(paths, iperio=True, nftype=\"T\")\n\n    See Also\n    --------\n    from_datasets\n    \"\"\"\n    if not isinstance(paths, dict):\n        raise TypeError(\"paths must be a dictionary or nested dictionary.\")\n    if not isinstance(nests, (dict, type(None))):\n        raise TypeError(\"nests must be a dictionary or None.\")\n    if not isinstance(iperio, bool):\n        raise TypeError(\"zonal periodicity of parent domain must be a boolean.\")\n    if nftype is not None and nftype not in (\"T\", \"F\"):\n        raise ValueError(\n            \"north fold type of parent domain must be 'T' (T-pivot fold), 'F' (F-pivot fold), or None.\"\n        )\n    if not isinstance(read_mask, bool):\n        raise TypeError(\"read_mask must be a boolean.\")\n    if not isinstance(nbghost_child, int):\n        raise TypeError(\n            \"number of ghost cells along the western/southern boundaries must be an integer.\"\n        )\n    if not isinstance(open_kwargs, dict):\n        raise TypeError(\"open_kwargs must be a dictionary.\")\n\n    # Define parent, child, grandchild filepath collections:\n    d_child, d_grandchild = None, None\n    if \"parent\" in paths.keys() and isinstance(paths[\"parent\"], dict):\n        for key in paths.keys():\n            if key not in (\"parent\", \"child\", \"grandchild\"):\n                raise KeyError(f\"Unexpected key '{key}' in paths dictionary.\")\n            if key == \"parent\":\n                d_parent = paths[\"parent\"]\n            elif key == \"child\":\n                d_child = paths[\"child\"]\n            elif key == \"grandchild\":\n                d_grandchild = paths[\"grandchild\"]\n    else:\n        raise ValueError(\n            \"Invalid paths structure. Expected a nested dictionary defining NEMO 'parent', 'child' and 'grandchild' domains.\"\n        )\n\n    # Construct DataTree from parent / child / grandchild domains:\n    d_tree = create_datatree_dict(\n        d_parent=d_parent,\n        d_child=d_child,\n        d_grandchild=d_grandchild,\n        nests=nests,\n        iperio=iperio,\n        nftype=nftype,\n        read_mask=read_mask,\n        nbghost_child=nbghost_child,\n        open_kwargs=dict(**open_kwargs),\n    )\n\n    datatree = super().from_dict(d_tree)\n\n    return datatree\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.gradient","title":"gradient","text":"<pre><code>gradient(var, dim, dom='.')\n</code></pre> <p>Calculate the gradient of a scalar variable along one dimension (e.g., 'i', 'j', 'k') of a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>var</code> <code>str</code> <p>Name of the scalar variable.</p> required <code>dim</code> <code>str</code> <p>Dimension along which to calculate gradient (e.g., 'i', 'j', 'k').</p> required <code>dom</code> <code>str</code> <p>Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.). Default is '.' for the parent domain.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Gradient of scalar variable defined on a NEMO model grid.</p> <p>Examples:</p> <p>Compute the 'meridional' gradient of sea surface temperature <code>tos_con</code> along the NEMO parent domain <code>j</code> dimension:</p> <pre><code>&gt;&gt;&gt; nemo.gradient(dom='.', var=\"tos_con\", dim=\"j\")\n</code></pre> <p>Compute the vertical gradient of absolute salinity in the first NEMO nested child domain:</p> <pre><code>&gt;&gt;&gt; nemo.gradient(dom=\"1\", var=\"so_abs\", dim=\"k\")\n</code></pre> See Also <p>integral</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def gradient(\n    self,\n    var: str,\n    dim: str,\n    dom: str = \".\",\n) -&gt; xr.DataArray:\n    \"\"\"\n    Calculate the gradient of a scalar variable along one dimension (e.g., 'i', 'j', 'k') of a NEMO model grid.\n\n    Parameters\n    ----------\n    var : str\n        Name of the scalar variable.\n    dim : str\n        Dimension along which to calculate gradient (e.g., 'i', 'j', 'k').\n    dom : str, optional\n        Prefix of NEMO domain in the DataTree (e.g., '1', '2', '3', etc.).\n        Default is '.' for the parent domain.\n\n    Returns\n    -------\n    xr.DataArray\n        Gradient of scalar variable defined on a NEMO model grid.\n\n    Examples\n    --------\n    Compute the 'meridional' gradient of sea surface temperature `tos_con`\n    along the NEMO parent domain `j` dimension:\n\n    &gt;&gt;&gt; nemo.gradient(dom='.', var=\"tos_con\", dim=\"j\")\n\n    Compute the vertical gradient of absolute salinity in the first NEMO\n    nested child domain:\n\n    &gt;&gt;&gt; nemo.gradient(dom=\"1\", var=\"so_abs\", dim=\"k\")\n\n    See Also\n    --------\n    integral\n    \"\"\"\n    # -- Validate input -- #\n    if not isinstance(var, str):\n        raise ValueError(\n            \"var must be a string specifying name of the scalar variable.\"\n        )\n    if not isinstance(dim, str):\n        raise ValueError(\n            \"dim must be a string specifying dimension along which to calculate the gradient (e.g., 'i', 'j', 'k').\"\n        )\n    if not isinstance(dom, str):\n        raise ValueError(\n            \"dom must be a string specifying prefix of a NEMO domain (e.g., '.', '1', '2', etc.).\"\n        )\n\n    # -- Get NEMO model grid properties -- #\n    dom_prefix, dom_suffix = self._get_properties(dom=dom)\n    grid_paths = self._get_grid_paths(dom=dom)\n    gridT, gridU, gridV, gridW = (\n        grid_paths[\"gridT\"],\n        grid_paths[\"gridU\"],\n        grid_paths[\"gridV\"],\n        grid_paths[\"gridW\"],\n    )\n\n    if var not in self[gridT].data_vars:\n        raise KeyError(f\"variable '{var}' not found in grid '{gridT}'.\")\n\n    da = self[f\"{gridT}/{var}\"]\n    dim_name = f\"{dim}{dom_suffix}\"\n    if dim_name not in da.dims:\n        raise KeyError(\n            f\"dimension '{dim_name}' not found in variable '{var}'. Dimensions available: {da.dims}.\"\n        )\n\n    match dim:\n        case \"i\":\n            if f\"{dom_prefix}deptht\" in da.coords:\n                # 3-dimensional umask:\n                umask = self[gridU][\"umask\"]\n            else:\n                # 2-dimensional umask:\n                umask = self[gridU][\"umaskutil\"]\n\n            # Zonally Periodic Domain:\n            if self[gridT].attrs.get(\"iperio\", False):\n                da_end = da.isel(dim_name=0)\n                da_end[dim_name] = da[dim_name].max() + 1\n                da = xr.concat([da, da_end], dim=dim_name)\n                dvar = da.diff(dim=dim_name, label=\"lower\")\n            else:\n                # Non-Periodic: pad with NaN values after differencing:\n                dvar = da.diff(dim=dim_name, label=\"lower\").pad({dim_name: (0, 1)})\n            # Apply u-mask &amp; transform coords -&gt; calculate gradient:\n            dvar.coords[dim_name] = dvar.coords[dim_name] + 0.5\n            gradient = dvar.where(umask) / self[f\"{gridU}/e1u\"]\n\n            # Remove redundant depth coordinates:\n            if f\"{dom_prefix}deptht\" in gradient.coords:\n                gradient = gradient.drop_vars(\n                    [f\"{dom_prefix}deptht\"]\n                ).assign_coords(\n                    {f\"{dom_prefix}depthu\": self[gridU][f\"{dom_prefix}depthu\"]}\n                )\n        case \"j\":\n            # 3-dimensional vmask:\n            if f\"{dom_prefix}deptht\" in da.coords:\n                vmask = self[gridV][\"vmask\"]\n            else:\n                # 2-dimensional vmask (unique points):\n                vmask = self[gridV][\"vmaskutil\"]\n\n            # Pad with zeros after differencing (zero gradient at jmaxdom):\n            dvar = da.diff(dim=dim_name, label=\"lower\").pad(\n                {dim_name: (0, 1)}, constant_values=0\n            )\n            # Apply vmask &amp; transform coords -&gt; calculate gradient:\n            dvar.coords[dim_name] = dvar.coords[dim_name] + 0.5\n            gradient = dvar.where(vmask) / self[f\"{gridV}/e2v\"]\n\n            if f\"{dom_prefix}deptht\" in gradient.coords:\n                gradient = gradient.drop_vars(\n                    [f\"{dom_prefix}deptht\"]\n                ).assign_coords(\n                    {f\"{dom_prefix}depthv\": self[gridV][f\"{dom_prefix}depthv\"]}\n                )\n\n        case \"k\":\n            dvar = da.diff(dim=dim_name, label=\"lower\")\n            # Transform coords &amp; apply w-mask -&gt; calculate gradient:\n            dvar.coords[dim_name] = dvar.coords[dim_name] + 0.5\n            dvar = dvar.where(self[gridW][\"wmask\"].isel({dim_name: slice(1, None)}))\n            try:\n                gradient = -dvar / self[f\"{gridW}/e3w\"].isel(\n                    {dim_name: slice(1, None)}\n                )\n                gradient = gradient.drop_vars([f\"{dom_prefix}deptht\"])\n            except KeyError as e:\n                raise KeyError(\n                    f\"NEMO model grid: '{gridW}' does not contain vertical scale factor 'e3w' required to calculate gradients along the k-dimension.\"\n                ) from e\n\n    # Update DataArray properties:\n    gradient.name = f\"grad_{var}_{dim_name}\"\n    gradient = gradient.drop_vars([f\"{dom_prefix}glamt\", f\"{dom_prefix}gphit\"])\n\n    return gradient\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.integral","title":"integral","text":"<pre><code>integral(grid, var, dims, cum_dims=None, dir=None, mask=None)\n</code></pre> <p>Integrate a variable along one or more dimensions of a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where variable is stored (e.g., 'gridT').</p> required <code>var</code> <code>str</code> <p>Name of variable to integrate.</p> required <code>dims</code> <code>list</code> <p>Dimensions over which to integrate (e.g., ['i', 'k']).</p> required <code>cum_dims</code> <code>list</code> <p>Dimensions over which to cumulatively integrate (e.g., ['k']). Specified dimensions must also be included in <code>dims</code>.</p> <code>None</code> <code>dir</code> <code>str</code> <p>Direction of cumulative integration. Options are '+1' (along increasing cum_dims) or '-1' (along decreasing cum_dims).</p> <code>None</code> <code>mask</code> <code>DataArray | None</code> <p>Boolean mask identifying NEMO model grid points to be included (1) or neglected (0) from integration.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Variable integrated along specified dimensions of the NEMO model grid.</p> <p>Examples:</p> <p>Compute the integral of conservative temperature <code>thetao_con</code> along the vertical <code>k</code> dimension in the NEMO parent domain:</p> <pre><code>&gt;&gt;&gt; nemo.integral(grid=\"gridT\",\n...               var=\"thetao_con\",\n...               dims=[\"k\"]\n...               )\n</code></pre> <p>Compute the vertical meridional overturning stream function from the meridional velocity <code>vo</code> (zonally integrated meridional velocity accumulated with increasing depth):</p> <pre><code>&gt;&gt;&gt; nemo.integral(grid=\"gridV\",\n...               var=\"vo\",\n...               dims=[\"i\", \"k\"],\n...               cum_dims=[\"k\"],\n...               dir=\"+1\",\n...               )\n</code></pre> See Also <p>gradient</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def integral(\n    self,\n    grid: str,\n    var: str,\n    dims: list,\n    cum_dims: list | None = None,\n    dir: str | None = None,\n    mask: xr.DataArray | None = None,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Integrate a variable along one or more dimensions of a NEMO model grid.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where variable is stored (e.g., 'gridT').\n    var : str\n        Name of variable to integrate.\n    dims : list\n        Dimensions over which to integrate (e.g., ['i', 'k']).\n    cum_dims : list, optional\n        Dimensions over which to cumulatively integrate (e.g., ['k']).\n        Specified dimensions must also be included in `dims`.\n    dir : str, optional\n        Direction of cumulative integration. Options are '+1' (along\n        increasing cum_dims) or '-1' (along decreasing cum_dims).\n    mask: xr.DataArray, optional\n        Boolean mask identifying NEMO model grid points to be included (1)\n        or neglected (0) from integration.\n\n    Returns\n    -------\n    xr.DataArray\n        Variable integrated along specified dimensions of the NEMO model grid.\n\n\n    Examples\n    --------\n    Compute the integral of conservative temperature `thetao_con` along the vertical\n    `k` dimension in the NEMO parent domain:\n\n\n    &gt;&gt;&gt; nemo.integral(grid=\"gridT\",\n    ...               var=\"thetao_con\",\n    ...               dims=[\"k\"]\n    ...               )\n\n    Compute the vertical meridional overturning stream function from the meridional\n    velocity `vo` (zonally integrated meridional velocity accumulated with increasing\n    depth):\n\n    &gt;&gt;&gt; nemo.integral(grid=\"gridV\",\n    ...               var=\"vo\",\n    ...               dims=[\"i\", \"k\"],\n    ...               cum_dims=[\"k\"],\n    ...               dir=\"+1\",\n    ...               )\n\n    See Also\n    --------\n    gradient\n    \"\"\"\n    # -- Validate input -- #\n    grid_keys = list(dict(self.subtree_with_keys).keys())\n    if grid not in grid_keys:\n        raise KeyError(\n            f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n        )\n    if var not in self[grid].data_vars:\n        raise KeyError(f\"variable '{var}' not found in grid '{grid}'.\")\n    if cum_dims is not None:\n        for dim in cum_dims:\n            if dim not in dims:\n                raise ValueError(\n                    f\"cumulative integration dimension '{dim}' not included in `dims`.\"\n                )\n        if dir not in [\"+1\", \"-1\"]:\n            raise ValueError(\n                f\"invalid direction of cumulative integration '{dir}'. Expected '+1' or '-1'.\"\n            )\n    if mask is not None:\n        if not isinstance(mask, xr.DataArray):\n            raise ValueError(\"mask must be an xarray.DataArray.\")\n        if any(dim not in self[grid].dims for dim in mask.dims):\n            raise ValueError(\n                f\"mask must have dimensions subset from {self[grid].dims}.\"\n            )\n\n    # -- Collect variable, weights &amp; mask -- #\n    da = (\n        self[f\"{grid}/{var}\"].where(mask)\n        if mask is not None\n        else self[f\"{grid}/{var}\"]\n    )\n    weights = self._get_weights(grid=grid, dims=dims)\n\n    # -- Perform integration -- #\n    if cum_dims is not None:\n        sum_dims = [dim for dim in dims if dim not in cum_dims]\n        if dir == \"+1\":\n            # Cumulative integration along ordered dimension:\n            result = (\n                da.weighted(weights)\n                .sum(dim=sum_dims, skipna=True)\n                .cumsum(dim=cum_dims, skipna=True)\n            )\n        elif dir == \"-1\":\n            # Cumulative integration along reversed dimension:\n            result = (\n                da.weighted(weights)\n                .sum(dim=sum_dims, skipna=True)\n                .reindex({dim: self[grid][dim][::-1] for dim in cum_dims})\n                .cumsum(dim=cum_dims, skipna=True)\n            )\n    else:\n        # Integration only:\n        result = da.weighted(weights).sum(dim=dims, skipna=True)\n\n    return result\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.mask_with_polygon","title":"mask_with_polygon","text":"<pre><code>mask_with_polygon(grid, lon_poly, lat_poly)\n</code></pre> <p>Create mask of NEMO model grid points contained within a polygon.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where longitude and latitude coordinates are stored (e.g., 'gridT').</p> required <code>lon_poly</code> <code>list | ndarray</code> <p>Longitudes of closed polygon.</p> required <code>lat_poly</code> <code>list | ndarray</code> <p>Latitudes of closed polygon.</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Boolean mask identifying NEMO model grid points which are inside the polygon.</p> <p>Examples:</p> <p>Create a regional boolean mask using the geographical coordinates of a closed polygon <code>lon_poly</code> and <code>lat_poly</code> in a NEMO parent domain:</p> <pre><code>&gt;&gt;&gt; nemo.mask_with_polygon(grid=\"gridT\",\n...                        lon_poly=lon_poly,\n...                        lat_poly=lat_poly,\n...                        )\n</code></pre> See Also <p>masked_statistic</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def mask_with_polygon(\n    self,\n    grid: str,\n    lon_poly: list | np.ndarray,\n    lat_poly: list | np.ndarray,\n):\n    \"\"\"\n    Create mask of NEMO model grid points contained within a polygon.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where longitude and latitude coordinates\n        are stored (e.g., 'gridT').\n    lon_poly : list | ndarray\n        Longitudes of closed polygon.\n    lat_poly : list | ndarray\n        Latitudes of closed polygon.\n\n    Returns\n    -------\n    xr.DataArray\n        Boolean mask identifying NEMO model grid points which are inside\n        the polygon.\n\n    Examples\n    --------\n    Create a regional boolean mask using the geographical coordinates of a closed\n    polygon `lon_poly` and `lat_poly` in a NEMO parent domain:\n\n\n    &gt;&gt;&gt; nemo.mask_with_polygon(grid=\"gridT\",\n    ...                        lon_poly=lon_poly,\n    ...                        lat_poly=lat_poly,\n    ...                        )\n\n    See Also\n    --------\n    masked_statistic\n    \"\"\"\n    # -- Validate input -- #\n    if not isinstance(lon_poly, (np.ndarray, list)) or not isinstance(\n        lat_poly, (np.ndarray, list)\n    ):\n        raise TypeError(\n            \"longitude &amp; latitude coordinates of polygon must be numpy arrays or lists.\"\n        )\n    if (lon_poly[0] != lon_poly[-1]) or (lat_poly[0] != lat_poly[-1]):\n        raise ValueError(\n            \"longitude &amp; latitude coordinates must form a closed polygon.\"\n        )\n\n    # -- Get NEMO model grid properties -- #\n    dom, dom_prefix, _, grid_suffix = self._get_properties(grid=grid, infer_dom=True)\n    hgrid_type = grid_suffix if \"w\" not in grid_suffix else \"t\"\n    ijk_names = self._get_ijk_names(grid=grid)\n    i_name, j_name = ijk_names[\"i\"], ijk_names[\"j\"]\n\n    if dom == \".\":\n        lon_name = f\"glam{hgrid_type}\"\n        lat_name = f\"gphi{hgrid_type}\"\n    else:\n        lon_name = f\"{dom_prefix}glam{hgrid_type}\"\n        lat_name = f\"{dom_prefix}gphi{hgrid_type}\"\n\n    # -- Create mask using polygon coordinates -- #\n    mask = create_polygon_mask(\n        lon_grid=self[grid][lon_name],\n        lat_grid=self[grid][lat_name],\n        lon_poly=lon_poly,\n        lat_poly=lat_poly,\n        dims=(j_name, i_name),\n    )\n\n    return mask\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.masked_statistic","title":"masked_statistic","text":"<pre><code>masked_statistic(grid, var, lon_poly, lat_poly, statistic, dims)\n</code></pre> <p>Masked statistic of a variable defined on a NEMO model grid.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where variable is stored (e.g., 'gridT').</p> required <code>var</code> <code>str</code> <p>Name of the variable to compute statistic.</p> required <code>lon_poly</code> <code>list | ndarray</code> <p>Longitudes of closed polygon.</p> required <code>lat_poly</code> <code>list | ndarray</code> <p>Latitudes of closed polygon.</p> required <code>statistic</code> <code>str</code> <p>Name of the statistic to calculate (e.g., 'mean', 'weighted_mean' 'sum').</p> required <code>dims</code> <code>list</code> <p>Dimensions over which to apply statistic (e.g., ['i', 'j']).</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Masked statistic of specified variable.</p> <p>Examples:</p> <p>Compute the grid cell area-weighted mean sea surface temperature <code>tos_con</code> for a region enclosed in a polygon defined by <code>lon_poly</code> and <code>lat_poly</code> in a NEMO nested child domain:</p> <pre><code>&gt;&gt;&gt; nemo.masked_statistic(grid=\"gridT/1_gridT\",\n...                       var=\"tos_con\",\n...                       lon_poly=lon_poly,\n...                       lat_poly=lat_poly,\n...                       statistic=\"weighted_mean\",\n...                       dims=[\"i\", \"j\"]\n...                       )\n</code></pre> See Also <p>binned_statistic</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def masked_statistic(\n    self,\n    grid: str,\n    var: str,\n    lon_poly: list | np.ndarray,\n    lat_poly: list | np.ndarray,\n    statistic: str,\n    dims: list,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Masked statistic of a variable defined on a NEMO model grid.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where variable is stored (e.g., 'gridT').\n    var : str\n        Name of the variable to compute statistic.\n    lon_poly : list | np.ndarray\n        Longitudes of closed polygon.\n    lat_poly : list | np.ndarray\n        Latitudes of closed polygon.\n    statistic : str\n        Name of the statistic to calculate (e.g., 'mean', 'weighted_mean' 'sum').\n    dims : list\n        Dimensions over which to apply statistic (e.g., ['i', 'j']).\n\n    Returns\n    -------\n    xr.DataArray\n        Masked statistic of specified variable.\n\n    Examples\n    --------\n    Compute the grid cell area-weighted mean sea surface temperature `tos_con` for a\n    region enclosed in a polygon defined by `lon_poly` and `lat_poly` in a NEMO nested\n    child domain:\n\n    &gt;&gt;&gt; nemo.masked_statistic(grid=\"gridT/1_gridT\",\n    ...                       var=\"tos_con\",\n    ...                       lon_poly=lon_poly,\n    ...                       lat_poly=lat_poly,\n    ...                       statistic=\"weighted_mean\",\n    ...                       dims=[\"i\", \"j\"]\n    ...                       )\n\n    See Also\n    --------\n    binned_statistic\n    \"\"\"\n    # -- Validate input -- #\n    grid_keys = list(dict(self.subtree_with_keys).keys())\n    if grid not in grid_keys:\n        raise KeyError(\n            f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n        )\n    if var not in self[grid].data_vars:\n        raise KeyError(f\"variable '{var}' not found in grid '{grid}'.\")\n\n    # -- Create polygon mask using coordinates -- #\n    mask_poly = self.mask_with_polygon(\n        lon_poly=lon_poly, lat_poly=lat_poly, grid=grid\n    )\n\n    # -- Get NEMO model grid properties -- #\n    _, _, dom_suffix, _ = self._get_properties(grid=grid, infer_dom=True)\n\n    # -- Apply masks &amp; calculate statistic -- #\n    da = self[f\"{grid}/{var}\"].where(mask_poly)\n\n    match statistic:\n        case \"mean\":\n            result = da.mean(dim=dims, skipna=True)\n\n        case \"weighted_mean\":\n            weight_dims = [dim.replace(dom_suffix, \"\") for dim in dims]\n            weights = self._get_weights(grid=grid, dims=weight_dims)\n            result = da.weighted(weights).mean(dim=dims, skipna=True)\n\n        case \"min\":\n            result = da.min(dim=dims, skipna=True)\n\n        case \"max\":\n            result = da.max(dim=dims, skipna=True)\n\n        case \"sum\":\n            result = da.sum(dim=dims, skipna=True)\n\n        case _:\n            raise ValueError(\n                f\"Unsupported statistic '{statistic}'. Supported statistics are: 'mean', 'weighted_mean', 'min', 'max', 'sum'.\"\n            )\n\n    return result\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.transform_to","title":"transform_to","text":"<pre><code>transform_to(grid, var, to)\n</code></pre> <p>Transform variable defined on a NEMO model grid to a neighbouring horizontal grid using linear interpolation.</p> <p>For flux variables defined at U- or V-points, the specified variable is first weighted by grid cell face areas prior to linear interpolation, and is then normalised by the target grid cell face areas following interpolation.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where variable is stored (e.g., 'gridT').</p> required <code>var</code> <code>str</code> <p>Name of the variable to transform.</p> required <code>to</code> <code>str</code> <p>Suffix of the neighbouring horizontal NEMO model grid to transform variable to. Options are 'T', 'U', 'V', 'F'.</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Values of variable linearly interpolated onto a neighbouring horizontal grid.</p> <p>Examples:</p> <p>Transform conservative temperature <code>thetao_con</code> defined on scalar T-points to neighbouring V-points in a NEMO model parent domain:</p> <pre><code>&gt;&gt;&gt; nemo.transform_to(grid='gridT', var='thetao_con', to='V')\n</code></pre> See Also <p>transform_vertical_grid</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def transform_to(\n    self,\n    grid: str,\n    var: str,\n    to: str,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Transform variable defined on a NEMO model grid to a neighbouring\n    horizontal grid using linear interpolation.\n\n    For flux variables defined at U- or V-points, the specified variable\n    is first weighted by grid cell face areas prior to linear interpolation,\n    and is then normalised by the target grid cell face areas following\n    interpolation.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where variable is stored (e.g., 'gridT').\n    var : str\n        Name of the variable to transform.\n    to : str\n        Suffix of the neighbouring horizontal NEMO model grid to\n        transform variable to. Options are 'T', 'U', 'V', 'F'.\n\n    Returns\n    -------\n    xr.DataArray\n        Values of variable linearly interpolated onto a neighbouring\n        horizontal grid.\n\n    Examples\n    --------\n    Transform conservative temperature `thetao_con` defined on scalar T-points\n    to neighbouring V-points in a NEMO model parent domain:\n\n    &gt;&gt;&gt; nemo.transform_to(grid='gridT', var='thetao_con', to='V')\n\n    See Also\n    --------\n    transform_vertical_grid\n    \"\"\"\n    # -- Validate input -- #\n    grid_keys = list(dict(self.subtree_with_keys).keys())\n    if grid not in grid_keys:\n        raise KeyError(\n            f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n        )\n    if var not in self[grid].data_vars:\n        raise KeyError(f\"variable '{var}' not found in grid '{grid}'.\")\n    if not isinstance(to, str):\n        raise TypeError(f\"'to' must be a string, got {type(to)}.\")\n    if to not in [\"T\", \"U\", \"V\", \"F\"]:\n        raise ValueError(f\"'to' must be one of ['T', 'U', 'V', 'F'], got {to}.\")\n\n    # -- Get NEMO model grid properties -- #\n    _, dom_prefix, _, grid_suffix = self._get_properties(grid=grid, infer_dom=True)\n    ijk_names = self._get_ijk_names(grid=grid)\n    i_name, j_name, k_name = ijk_names[\"i\"], ijk_names[\"j\"], ijk_names[\"k\"]\n    iperio = self[grid].attrs.get(\"iperio\", False)\n    target_grid = f\"{grid.replace(grid[-1], to)}\"\n\n    # -- Prepare variable for linear interpolation -- #\n    if grid_suffix.upper() in [\"U\", \"V\"]:\n        weight_dims = (\n            [k_name, j_name] if grid_suffix.upper() == \"U\" else [k_name, i_name]\n        )\n        if f\"{dom_prefix}depth{grid_suffix}\" in self[grid][var].coords:\n            # 3-D variables - weight by grid cell face area:\n            weights = self._get_weights(grid=grid, dims=weight_dims, fillna=False)\n            target_weights = self._get_weights(\n                grid=target_grid, dims=weight_dims, fillna=False\n            )\n        else:\n            # 2-D variables - weight by grid cell width:\n            weights = self._get_weights(grid=grid, dims=weight_dims[1], fillna=False)\n            target_weights = self._get_weights(\n                grid=target_grid, dims=weight_dims[1], fillna=False\n            )\n        da = self[f\"{grid}/{var}\"] * weights\n    else:\n        # Scalar variables:\n        da = self[f\"{grid}/{var}\"]\n\n    # -- Linearly interpolate variable -- #\n    # Define source grid mask:\n    if f\"{dom_prefix}depth{grid_suffix}\" in da.coords:\n        mask = self[grid][f\"{grid_suffix}mask\"]\n    else:\n        mask = self[grid][f\"{grid_suffix}maskutil\"]\n\n    result = interpolate_grid(\n        da=da,\n        mask=mask,\n        source_grid=grid[-1],\n        target_grid=target_grid[-1],\n        iperio=iperio,\n        ijk_names=ijk_names,\n    )\n\n    # -- Update interpolated variable -- #\n    # Retain input variable name:\n    result.name = da.name\n    # Reorder dimensions (time_counter, [k], j, i):\n    new_dims = (result.dims[-1], *result.dims[:-1])\n    result = result.transpose(*new_dims)\n\n    # Update NEMO grid coords:\n    result[i_name] = self[target_grid][i_name]\n    result[j_name] = self[target_grid][j_name]\n    if k_name in result.dims:\n        result[k_name] = self[target_grid][k_name]\n\n    # Drop NEMO source grid coords:\n    drop_vars = [f\"{dom_prefix}glam{grid_suffix}\", f\"{dom_prefix}gphi{grid_suffix}\"]\n    if f\"{dom_prefix}depth{grid_suffix}\" in da.coords:\n        drop_vars.append(f\"{dom_prefix}depth{grid_suffix}\")\n    result = result.drop_vars(drop_vars)\n\n    # Normalise by target grid cell weights for flux variables:\n    if grid_suffix.upper() in [\"U\", \"V\"]:\n        result = result / target_weights\n\n    # Apply target grid mask:\n    if f\"{dom_prefix}depth{grid_suffix}\" in da.coords:\n        target_mask = f\"{to.lower()}mask\"\n    else:\n        target_mask = f\"{to.lower()}maskutil\"\n    result = result.where(self[target_grid][target_mask])\n\n    return result\n</code></pre>"},{"location":"reference/#nemo_cookbook.nemodatatree.NEMODataTree.transform_vertical_grid","title":"transform_vertical_grid","text":"<pre><code>transform_vertical_grid(grid, var, e3_new)\n</code></pre> <p>Transform variable defined on a NEMO model grid to a new vertical grid using conservative interpolation.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>str</code> <p>Path to NEMO model grid where variable is stored (e.g., 'gridT').</p> required <code>var</code> <code>str</code> <p>Name of the variable to transform.</p> required <code>e3_new</code> <code>DataArray</code> <p>Grid cell thicknesses of the new vertical grid. Must be a 1-dimensional xarray.DataArray with dimension 'k_new'.</p> required <p>Returns:</p> Type Description <code>tuple[DataArray, DataArray]</code> <p>Values of variable defined at the centre of each vertical grid cell on the new grid, and vertical grid cell thicknesses adjusted for model bathymetry.</p> <p>Examples:</p> <p>Transform the conservative temperature variable <code>thetao_con</code> defined in a NEMO model parent domain from it's native 75 unevenly-spaced z-levels to regularly spaced z-levels at 200 m intervals:</p> <pre><code>&gt;&gt;&gt; e3t_target = xr.DataArray(np.repeat(200.0, 30), dims=['k_new'])\n</code></pre> <pre><code>&gt;&gt;&gt; nemo.transform_vertical_grid(grid='gridT',\n...                              var='thetao_con',\n...                              e3_new=e3t_target\n...                              )\n</code></pre> See Also <p>transform_to</p> Source code in <code>nemo_cookbook/nemodatatree.py</code> <pre><code>def transform_vertical_grid(\n    self, grid: str, var: str, e3_new: xr.DataArray\n) -&gt; xr.Dataset:\n    \"\"\"\n    Transform variable defined on a NEMO model grid to a new vertical grid using conservative interpolation.\n\n    Parameters\n    ----------\n    grid : str\n        Path to NEMO model grid where variable is stored\n        (e.g., 'gridT').\n    var : str\n        Name of the variable to transform.\n    e3_new : xarray.DataArray\n        Grid cell thicknesses of the new vertical grid.\n        Must be a 1-dimensional xarray.DataArray with\n        dimension 'k_new'.\n\n    Returns\n    -------\n    tuple[xr.DataArray, xr.DataArray]\n        Values of variable defined at the centre of each vertical\n        grid cell on the new grid, and vertical grid cell\n        thicknesses adjusted for model bathymetry.\n\n    Examples\n    --------\n    Transform the conservative temperature variable `thetao_con` defined in a\n    NEMO model parent domain from it's native 75 unevenly-spaced z-levels to\n    regularly spaced z-levels at 200 m intervals:\n\n    &gt;&gt;&gt; e3t_target = xr.DataArray(np.repeat(200.0, 30), dims=['k_new'])\n\n    &gt;&gt;&gt; nemo.transform_vertical_grid(grid='gridT',\n    ...                              var='thetao_con',\n    ...                              e3_new=e3t_target\n    ...                              )\n\n    See Also\n    --------\n    transform_to\n    \"\"\"\n    # -- Validate input -- #\n    grid_keys = list(dict(self.subtree_with_keys).keys())\n    if grid not in grid_keys:\n        raise KeyError(\n            f\"grid '{grid}' not found in available NEMODataTree grids {grid_keys}.\"\n        )\n    if var not in self[grid].data_vars:\n        raise KeyError(f\"Variable '{var}' not found in grid '{grid}'.\")\n    if e3_new.dims != (\"k_new\",) or (e3_new.ndim != 1):\n        raise ValueError(\n            \"e3_new must be a 1-dimensional xarray.DataArray with dimension 'k_new'.\"\n        )\n\n    # -- Get NEMO model grid properties -- #\n    dom, _, _, grid_suffix = self._get_properties(grid=grid, infer_dom=True)\n    ijk_names = self._get_ijk_names(dom=dom)\n    i_name, j_name, k_name = ijk_names[\"i\"], ijk_names[\"j\"], ijk_names[\"k\"]\n\n    # -- Define input variables -- #\n    var_in = self[f\"{grid}/{var}\"]\n    e3_in = self[f\"{grid}/e3{grid_suffix}\"]\n    if e3_new.sum(dim=\"k_new\") &lt; self[grid][f\"depth{grid_suffix}\"].max(dim=k_name):\n        raise ValueError(\n            f\"e3_new must sum to at least the maximum depth ({self[grid][f'depth{grid_suffix}'].max(dim=k_name).item()} m) of the original vertical grid.\"\n        )\n\n    # -- Transform variable to target vertical grid -- #\n    var_out, e3_out = xr.apply_ufunc(\n        transform_vertical_coords,\n        e3_in,\n        var_in,\n        e3_new.astype(e3_in.dtype),\n        input_core_dims=[[k_name], [k_name], [\"k_new\"]],\n        output_core_dims=[[\"k_new\"], [\"k_new\"]],\n        dask=\"allowed\",\n    )\n\n    # -- Create transformed variable Dataset -- #\n    t_name = var_in.dims[0]\n    var_out = var_out.transpose(t_name, \"k_new\", j_name, i_name)\n\n    ds_out = xr.Dataset(\n        data_vars={var: var_out, f\"e3{grid_suffix}_new\": e3_out},\n        coords={\n            f\"depth{grid_suffix}_new\": (\"k_new\", e3_new.cumsum(dim=\"k_new\").data)\n        },\n    )\n\n    return ds_out\n</code></pre>"}]}