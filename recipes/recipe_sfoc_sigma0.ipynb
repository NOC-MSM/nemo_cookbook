{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Calculating the surface-forced overturning stream function in potential density coordinates**\n",
    "\n",
    "### **Description**\n",
    "\n",
    "Recipe showing how to calculate the surface-forced overturning stream function in potential density-coordinates using annual-mean outputs from the National Oceanography Centre Near-Present-Day global eORCA1 configuration of NEMO forced using JRA55-do from 1976-2024.\n",
    "\n",
    "For more details on this model configuration and the available outputs, users can explore the Near-Present-Day documentation [here](https://noc-msm.github.io/NOC_Near_Present_Day/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Import required Python packages -- #\n",
    "import gsw\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -- Import nemo_cookbook tools -- #\n",
    "from nemo_cookbook import compute_sfoc_sigma0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using Dask**\n",
    "\n",
    "**Optional: Connect Client to Dask Local Cluster to run analysis in parallel.**\n",
    "\n",
    "Note that, although using Dask is not strictly necessary for this simple example using eORCA1, if we wanted to generalise this recipe to eORCA025 or eORCA12 outputs, using Dask would be essential to avoid unnecessary slow calculations using only a single process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Initialise Dask Local Cluster -- #\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# Update temporarty directory for Dask workers:\n",
    "dask.config.set({'temporary_directory': '/home/otooth/work/Diagnostics/proj_NPD_diag/nemo_cookbook/recipes',\n",
    "                 'local_directory': '/home/otooth/work/Diagnostics/proj_NPD_diag/nemo_cookbook/recipes'\n",
    "                 })\n",
    "\n",
    "# Create Local Cluster:\n",
    "cluster = LocalCluster(n_workers=4, threads_per_worker=5, memory_limit='5GB')\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preparing NEMO Model Data**\n",
    "**Let's begin by loading the grid variables for our eORCA1 NEMO model from the [JASMIN Object Store](https://help.jasmin.ac.uk/docs/short-term-project-storage/using-the-jasmin-object-store/)**. \n",
    "\n",
    "**Alternatively, you can replace the ``domain_filepath`` below with a file path to your domain_cfg.nc file and read this with xarray's ``open_dataset()`` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Import eORCA1 domain data -- #\n",
    "# Define directory path to ancillary files:\n",
    "domain_filepath = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1/domain\"\n",
    "\n",
    "# Open eORCA1 model grid data:\n",
    "ds_domain = xr.open_zarr(domain_filepath, consolidated=True, chunks={})\n",
    "\n",
    "# Extract zonal grid cell widths (m):\n",
    "e1t = ds_domain['e1t'].squeeze()\n",
    "# Extract meridional grid cell widths (m):\n",
    "e2t = ds_domain['e2t'].squeeze()\n",
    "# Extract Atlantic Ocean mask:\n",
    "atl_mask = ds_domain['atlmsk'].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, we need to import surface heat and freshwater fluxes stored at T-points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Import eORCA1 tracer data -- #\n",
    "# Define directory path to model output files:\n",
    "output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1\"\n",
    "\n",
    "# Extract net downward surface heat flux (W/m2):\n",
    "thetao_con = xr.open_zarr(f\"{output_dir}/T1y/thetao_con\", consolidated=True, chunks={})['thetao_con']\n",
    "# Extract absolute salinity (g/kg):\n",
    "so_abs = xr.open_zarr(f\"{output_dir}/T1y/so_abs\", consolidated=True, chunks={})['so_abs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, we need to import the sea surface temperature and sea surface salinity stored at T-points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Import eORCA1 tracer data -- #\n",
    "# Define directory path to model output files:\n",
    "output_dir = \"https://noc-msm-o.s3-ext.jc.rl.ac.uk/npd-eorca1-jra55v1\"\n",
    "\n",
    "# Extract conservative temperature (C):\n",
    "tos_con = xr.open_zarr(f\"{output_dir}/T1y/tos_con\", consolidated=True, chunks={})['tos_con']\n",
    "# Extract absolute salinity (g/kg):\n",
    "sos_abs = xr.open_zarr(f\"{output_dir}/T1y/sos_abs\", consolidated=True, chunks={})['sos_abs']\n",
    "\n",
    "# Calculate potential density anomaly referenced to the sea surface (kg/m3):\n",
    "sigma0 = gsw.density.sigma0(CT=tos_con, SA=sos_abs)\n",
    "sigma0.name = 'sigma0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Import eORCA1 velocity data -- #\n",
    "# Extract vertical grid cell thicknesses (m):\n",
    "e3v = xr.open_zarr(f\"{output_dir}/V1y/e3v\", consolidated=True, chunks={})['e3v']\n",
    "# Extract meridional velocities (m/s):\n",
    "vo = xr.open_zarr(f\"{output_dir}/V1y/vo\", consolidated=True, chunks={})['vo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculating Surface-Forced Overturning Stream Function**\n",
    "\n",
    "**Now all our input variables are ready, let's calculate the Surface-Forced Overturning Stream Function in density-coordinates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Create Task: Compute Atlantic Meridional Overturning Circulation (MOC_sigma0) in density-coordinates -- #\n",
    "# Apply the Atlantic Ocean sector mask and accumulate from the lightest to the densest isopycnal surface:\n",
    "moc_sigma0_atl = compute_moc_tracer(vo=vo,\n",
    "                                    e1v=e1v,\n",
    "                                    e3v=e3v,\n",
    "                                    tracer=sigma0,\n",
    "                                    tracer_bins=np.arange(21, 29, 0.01),\n",
    "                                    dir = '+1',\n",
    "                                    mask=atl_mask,\n",
    "                                    )\n",
    "\n",
    "# Notice that the output is a dask array, so we haven't actually computed the MOC_sigma0 yet.\n",
    "moc_sigma0_atl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Complete Task: Compute Meridional Overturning Circulation (MOC_sigma0) in density-coordinates -- #\n",
    "moc_sigma0_atl = moc_sigma0_atl.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Plot time-mean MOC_sigma0 -- #\n",
    "moc_sigma0_atl.mean(dim='time_counter').plot(yincrease=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jlab_nemo_cookbook",
   "language": "python",
   "name": "jlab_nemo_cookbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
